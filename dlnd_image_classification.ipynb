{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1411bc7ff60>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "   \n",
    "    result = np.copy(x).astype(np.float32)\n",
    "    \n",
    "    for a in np.nditer(result, op_flags=['readwrite']):\n",
    "          a[...] =  a / 255\n",
    "           \n",
    "    return result\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "arrayOfpossibleLabelValues = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(arrayOfpossibleLabelValues)    \n",
    "    \n",
    "    return lb.transform(x)\n",
    "    \n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape = [None, *image_shape], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape = [None, n_classes] ,name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32,name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"   \n",
    "    filter_weights = tf.Variable(tf.truncated_normal([conv_ksize[0],conv_ksize[1], x_tensor.get_shape().as_list()[3],conv_num_outputs], stddev=0.05)) \n",
    "    filter_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "        \n",
    "    conv_layer = tf.nn.conv2d(x_tensor, filter_weights, strides= [1,conv_strides[0],conv_strides[1],1], padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, filter_bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    return tf.nn.max_pool(conv_layer, ksize=[1, pool_ksize[0], pool_ksize[1], 1],  strides = [1, pool_strides[0], pool_strides[1], 1], padding='SAME')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    return tf.reshape(x_tensor, [-1, np.prod(x_tensor.get_shape().as_list()[1:])])\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    weights = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs], mean=0.0, stddev=0.05))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor, weights), bias))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    weights = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs], mean=0.0, stddev=0.05))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    return tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_num_outputs = 20\n",
    "    conv_ksize = (8,8)\n",
    "    conv_strides = (2,2)\n",
    "    pool_ksize = (4,4)\n",
    "    pool_strides = (2,2)\n",
    "    num_outputs = 10\n",
    "        \n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    net = conv2d_maxpool(x, conv_num_outputs,conv_ksize,conv_strides,pool_ksize,pool_strides)\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    net = conv2d_maxpool(net, conv_num_outputs,conv_ksize,conv_strides,pool_ksize,pool_strides)\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    net = conv2d_maxpool(net, conv_num_outputs,conv_ksize,conv_strides,pool_ksize,pool_strides)\n",
    "        \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    net = flatten(net)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    net = fully_conn(net,num_outputs)\n",
    "    net = fully_conn(net,num_outputs)\n",
    "    net = fully_conn(net,num_outputs)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    return output(net,num_outputs)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer,feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    accuracy = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print(\"Loss: {}\".format(loss))\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 500\n",
    "batch_size = 256\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.3027939796447754\n",
      "Accuracy: 0.17739999294281006\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.2460203170776367\n",
      "Accuracy: 0.16920000314712524\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.2129881381988525\n",
      "Accuracy: 0.18140000104904175\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.1673593521118164\n",
      "Accuracy: 0.21459999680519104\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 2.1273841857910156\n",
      "Accuracy: 0.21819999814033508\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 2.1006507873535156\n",
      "Accuracy: 0.22659997642040253\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 2.094470500946045\n",
      "Accuracy: 0.22599998116493225\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 2.0818800926208496\n",
      "Accuracy: 0.2377999871969223\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 2.0664925575256348\n",
      "Accuracy: 0.2393999844789505\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 2.063082218170166\n",
      "Accuracy: 0.24559997022151947\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 2.063044309616089\n",
      "Accuracy: 0.2603999972343445\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 2.061556339263916\n",
      "Accuracy: 0.2655999958515167\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 2.049376964569092\n",
      "Accuracy: 0.2701999843120575\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 2.0482330322265625\n",
      "Accuracy: 0.2789999842643738\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 2.036789655685425\n",
      "Accuracy: 0.29019996523857117\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 2.0194106101989746\n",
      "Accuracy: 0.2865999639034271\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 2.006082534790039\n",
      "Accuracy: 0.29159998893737793\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.9902443885803223\n",
      "Accuracy: 0.2905999720096588\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.9789400100708008\n",
      "Accuracy: 0.29719996452331543\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.9724708795547485\n",
      "Accuracy: 0.3059999942779541\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.9711084365844727\n",
      "Accuracy: 0.29839998483657837\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.9555091857910156\n",
      "Accuracy: 0.32099997997283936\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.9300146102905273\n",
      "Accuracy: 0.3139999806880951\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.936466932296753\n",
      "Accuracy: 0.3091999590396881\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.88555109500885\n",
      "Accuracy: 0.3303999900817871\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.901562213897705\n",
      "Accuracy: 0.33299997448921204\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.8843876123428345\n",
      "Accuracy: 0.33059999346733093\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.8657722473144531\n",
      "Accuracy: 0.3343999981880188\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.8393583297729492\n",
      "Accuracy: 0.3389999568462372\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.8240159749984741\n",
      "Accuracy: 0.33899998664855957\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.7954084873199463\n",
      "Accuracy: 0.3416000008583069\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.7742133140563965\n",
      "Accuracy: 0.3489999771118164\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.770423412322998\n",
      "Accuracy: 0.34480002522468567\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.7735964059829712\n",
      "Accuracy: 0.3449999690055847\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.7252159118652344\n",
      "Accuracy: 0.35420000553131104\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.7146673202514648\n",
      "Accuracy: 0.3479999601840973\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.6803264617919922\n",
      "Accuracy: 0.3521999716758728\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.684741497039795\n",
      "Accuracy: 0.3513999581336975\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.6948885917663574\n",
      "Accuracy: 0.36159998178482056\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.6495513916015625\n",
      "Accuracy: 0.35819998383522034\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.6666638851165771\n",
      "Accuracy: 0.34579998254776\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.6150213479995728\n",
      "Accuracy: 0.3668000102043152\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.5880650281906128\n",
      "Accuracy: 0.36579999327659607\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.5937910079956055\n",
      "Accuracy: 0.3653999865055084\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.6063389778137207\n",
      "Accuracy: 0.36419999599456787\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.607138752937317\n",
      "Accuracy: 0.3523999750614166\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.5302120447158813\n",
      "Accuracy: 0.3633999824523926\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.5368425846099854\n",
      "Accuracy: 0.36800000071525574\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 1.5066721439361572\n",
      "Accuracy: 0.37459999322891235\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 1.49229896068573\n",
      "Accuracy: 0.378199964761734\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 1.471095323562622\n",
      "Accuracy: 0.38099998235702515\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 1.4977142810821533\n",
      "Accuracy: 0.3773999810218811\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 1.4703840017318726\n",
      "Accuracy: 0.38519996404647827\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 1.4651329517364502\n",
      "Accuracy: 0.37619999051094055\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 1.4543064832687378\n",
      "Accuracy: 0.38279998302459717\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 1.4266347885131836\n",
      "Accuracy: 0.3837999999523163\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 1.4093427658081055\n",
      "Accuracy: 0.3806000351905823\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 1.430079460144043\n",
      "Accuracy: 0.3773999810218811\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 1.391787052154541\n",
      "Accuracy: 0.3856000006198883\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 1.4094113111495972\n",
      "Accuracy: 0.38259994983673096\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 1.3678350448608398\n",
      "Accuracy: 0.39139997959136963\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 1.3722753524780273\n",
      "Accuracy: 0.3889999985694885\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 1.3420348167419434\n",
      "Accuracy: 0.39139997959136963\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 1.3107068538665771\n",
      "Accuracy: 0.39059996604919434\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 1.327307105064392\n",
      "Accuracy: 0.3862000107765198\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 1.344102144241333\n",
      "Accuracy: 0.3921999931335449\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 1.2956464290618896\n",
      "Accuracy: 0.39479997754096985\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 1.287572979927063\n",
      "Accuracy: 0.40199998021125793\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 1.2921738624572754\n",
      "Accuracy: 0.3977999687194824\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 1.2790066003799438\n",
      "Accuracy: 0.3917999565601349\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 1.2368407249450684\n",
      "Accuracy: 0.40139997005462646\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 1.284006953239441\n",
      "Accuracy: 0.39319995045661926\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 1.2465333938598633\n",
      "Accuracy: 0.392799973487854\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 1.2074337005615234\n",
      "Accuracy: 0.39959999918937683\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 1.2622380256652832\n",
      "Accuracy: 0.3917999863624573\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 1.2260048389434814\n",
      "Accuracy: 0.40359997749328613\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 1.2139840126037598\n",
      "Accuracy: 0.40439996123313904\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 1.242367148399353\n",
      "Accuracy: 0.40199998021125793\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 1.2130916118621826\n",
      "Accuracy: 0.39559996128082275\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 1.187178611755371\n",
      "Accuracy: 0.40860000252723694\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 1.182018518447876\n",
      "Accuracy: 0.4097999930381775\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 1.1819454431533813\n",
      "Accuracy: 0.40779995918273926\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 1.1791796684265137\n",
      "Accuracy: 0.4026000201702118\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 1.1821568012237549\n",
      "Accuracy: 0.4075999855995178\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 1.1792012453079224\n",
      "Accuracy: 0.40119996666908264\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 1.1890045404434204\n",
      "Accuracy: 0.39959996938705444\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 1.1678051948547363\n",
      "Accuracy: 0.40619996190071106\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 1.1640268564224243\n",
      "Accuracy: 0.40839993953704834\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 1.1291080713272095\n",
      "Accuracy: 0.41200000047683716\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 1.1127734184265137\n",
      "Accuracy: 0.41519999504089355\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 1.1318410634994507\n",
      "Accuracy: 0.4145999550819397\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 1.1358546018600464\n",
      "Accuracy: 0.41679996252059937\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 1.1314982175827026\n",
      "Accuracy: 0.4121999740600586\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 1.1271662712097168\n",
      "Accuracy: 0.40859997272491455\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 1.099379539489746\n",
      "Accuracy: 0.4147999584674835\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 1.1177961826324463\n",
      "Accuracy: 0.4031999707221985\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 1.1018743515014648\n",
      "Accuracy: 0.4075999855995178\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 1.1263517141342163\n",
      "Accuracy: 0.42079997062683105\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 1.106092929840088\n",
      "Accuracy: 0.4179999828338623\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 1.1277058124542236\n",
      "Accuracy: 0.4016000032424927\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss: 1.1607131958007812\n",
      "Accuracy: 0.3898000121116638\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss: 1.0769391059875488\n",
      "Accuracy: 0.40859997272491455\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss: 1.0984668731689453\n",
      "Accuracy: 0.4156000018119812\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss: 1.0684576034545898\n",
      "Accuracy: 0.4198000133037567\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss: 1.0516142845153809\n",
      "Accuracy: 0.4211999475955963\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss: 1.0384585857391357\n",
      "Accuracy: 0.4257999658584595\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss: 1.0558946132659912\n",
      "Accuracy: 0.40779995918273926\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss: 1.0324808359146118\n",
      "Accuracy: 0.4031999707221985\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss: 1.009856939315796\n",
      "Accuracy: 0.41919997334480286\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss: 1.073620080947876\n",
      "Accuracy: 0.4113999903202057\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss: 1.007555365562439\n",
      "Accuracy: 0.4163999855518341\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss: 0.9812737107276917\n",
      "Accuracy: 0.42739999294281006\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss: 0.9770926237106323\n",
      "Accuracy: 0.42159995436668396\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss: 0.9884032011032104\n",
      "Accuracy: 0.4209999740123749\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss: 0.9974534511566162\n",
      "Accuracy: 0.417199969291687\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss: 0.9698938131332397\n",
      "Accuracy: 0.42819997668266296\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss: 0.9582260847091675\n",
      "Accuracy: 0.42959997057914734\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss: 0.9569169282913208\n",
      "Accuracy: 0.4257999658584595\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss: 0.9783286452293396\n",
      "Accuracy: 0.4246000051498413\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss: 1.0172901153564453\n",
      "Accuracy: 0.41920000314712524\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss: 0.9802178144454956\n",
      "Accuracy: 0.42959997057914734\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss: 0.958937406539917\n",
      "Accuracy: 0.4349999725818634\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss: 0.9627367258071899\n",
      "Accuracy: 0.42559996247291565\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss: 0.9426969289779663\n",
      "Accuracy: 0.4333999454975128\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss: 0.9723653793334961\n",
      "Accuracy: 0.4307999610900879\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss: 0.9613831043243408\n",
      "Accuracy: 0.423799991607666\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss: 0.9304639101028442\n",
      "Accuracy: 0.4212000072002411\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss: 0.9328340291976929\n",
      "Accuracy: 0.41499996185302734\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss: 0.9298516511917114\n",
      "Accuracy: 0.4269999563694\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss: 0.9496114253997803\n",
      "Accuracy: 0.4161999821662903\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss: 0.9424394369125366\n",
      "Accuracy: 0.41899996995925903\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss: 0.9255849123001099\n",
      "Accuracy: 0.4317999482154846\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss: 0.9425198435783386\n",
      "Accuracy: 0.42239999771118164\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss: 0.9390842914581299\n",
      "Accuracy: 0.4196000099182129\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss: 0.911426305770874\n",
      "Accuracy: 0.41659998893737793\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss: 0.9563800096511841\n",
      "Accuracy: 0.43619999289512634\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss: 0.9244398474693298\n",
      "Accuracy: 0.42100000381469727\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss: 0.9126347303390503\n",
      "Accuracy: 0.4251999855041504\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss: 0.885056734085083\n",
      "Accuracy: 0.4283999800682068\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss: 0.9130671620368958\n",
      "Accuracy: 0.4301999807357788\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss: 0.9355917572975159\n",
      "Accuracy: 0.4257999658584595\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss: 0.9066340923309326\n",
      "Accuracy: 0.42379996180534363\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss: 0.9071753025054932\n",
      "Accuracy: 0.42399999499320984\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss: 0.890198826789856\n",
      "Accuracy: 0.43039995431900024\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss: 0.9107656478881836\n",
      "Accuracy: 0.42079997062683105\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss: 0.878766655921936\n",
      "Accuracy: 0.4355999827384949\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss: 0.869727373123169\n",
      "Accuracy: 0.43459996581077576\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss: 0.9245432615280151\n",
      "Accuracy: 0.4164000153541565\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss: 0.9220367670059204\n",
      "Accuracy: 0.4129999577999115\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss: 0.8925153017044067\n",
      "Accuracy: 0.42899996042251587\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss: 0.8871080875396729\n",
      "Accuracy: 0.42959997057914734\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss: 0.8652195930480957\n",
      "Accuracy: 0.43539994955062866\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss: 0.8910584449768066\n",
      "Accuracy: 0.4300000071525574\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss: 0.848589301109314\n",
      "Accuracy: 0.439799964427948\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss: 0.8444734811782837\n",
      "Accuracy: 0.4277999699115753\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss: 0.8634734153747559\n",
      "Accuracy: 0.42719995975494385\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss: 0.8880506157875061\n",
      "Accuracy: 0.42739999294281006\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss: 0.8291527032852173\n",
      "Accuracy: 0.4421999454498291\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss: 0.856521725654602\n",
      "Accuracy: 0.43379998207092285\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss: 0.871362030506134\n",
      "Accuracy: 0.43859994411468506\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss: 0.8554757833480835\n",
      "Accuracy: 0.4381999969482422\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss: 0.8340842723846436\n",
      "Accuracy: 0.4391999840736389\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss: 0.8307153582572937\n",
      "Accuracy: 0.434999942779541\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss: 0.8374922275543213\n",
      "Accuracy: 0.44019997119903564\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss: 0.8432165384292603\n",
      "Accuracy: 0.431799978017807\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss: 0.849921464920044\n",
      "Accuracy: 0.42959997057914734\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss: 0.8431156873703003\n",
      "Accuracy: 0.4236000180244446\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss: 0.8742111325263977\n",
      "Accuracy: 0.425199955701828\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss: 0.8056246042251587\n",
      "Accuracy: 0.44599997997283936\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss: 0.8575314879417419\n",
      "Accuracy: 0.4407999515533447\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss: 0.8437109589576721\n",
      "Accuracy: 0.4365999698638916\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss: 0.8406222462654114\n",
      "Accuracy: 0.4357999265193939\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss: 0.864227831363678\n",
      "Accuracy: 0.4423999786376953\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss: 0.8384284377098083\n",
      "Accuracy: 0.44259998202323914\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss: 0.8675535917282104\n",
      "Accuracy: 0.43039995431900024\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss: 0.8599553108215332\n",
      "Accuracy: 0.4485999345779419\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss: 0.8732134103775024\n",
      "Accuracy: 0.43459996581077576\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss: 0.8335527181625366\n",
      "Accuracy: 0.43619993329048157\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss: 0.8871917724609375\n",
      "Accuracy: 0.4339999854564667\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss: 0.819413959980011\n",
      "Accuracy: 0.4365999698638916\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss: 0.8487737774848938\n",
      "Accuracy: 0.43119993805885315\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss: 0.7964591979980469\n",
      "Accuracy: 0.4371999502182007\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss: 0.8144772052764893\n",
      "Accuracy: 0.43939998745918274\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss: 0.8541173934936523\n",
      "Accuracy: 0.4177999794483185\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss: 0.8175135850906372\n",
      "Accuracy: 0.4339999854564667\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss: 0.829958975315094\n",
      "Accuracy: 0.42800000309944153\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss: 0.8308651447296143\n",
      "Accuracy: 0.4541999399662018\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss: 0.8013209104537964\n",
      "Accuracy: 0.44859999418258667\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss: 0.8065704703330994\n",
      "Accuracy: 0.43879997730255127\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss: 0.8386439085006714\n",
      "Accuracy: 0.45260000228881836\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss: 0.8359524011611938\n",
      "Accuracy: 0.4373999834060669\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss: 0.7894473075866699\n",
      "Accuracy: 0.43380001187324524\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss: 0.8433938026428223\n",
      "Accuracy: 0.4367999732494354\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss: 0.7962924838066101\n",
      "Accuracy: 0.44519999623298645\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss: 0.7739284038543701\n",
      "Accuracy: 0.44759994745254517\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss: 0.7939256429672241\n",
      "Accuracy: 0.4493999779224396\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss: 0.8035022020339966\n",
      "Accuracy: 0.44579994678497314\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss: 0.7939282655715942\n",
      "Accuracy: 0.442999929189682\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss: 0.7994800209999084\n",
      "Accuracy: 0.43519994616508484\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss: 0.7774701714515686\n",
      "Accuracy: 0.4493999779224396\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss: 0.7579977512359619\n",
      "Accuracy: 0.4461999535560608\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss: 0.8001571297645569\n",
      "Accuracy: 0.4399999976158142\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss: 0.8006464242935181\n",
      "Accuracy: 0.4197999835014343\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss: 0.7799543142318726\n",
      "Accuracy: 0.44579994678497314\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss: 0.7986712455749512\n",
      "Accuracy: 0.44339999556541443\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss: 0.7690689563751221\n",
      "Accuracy: 0.44919997453689575\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss: 0.7811728715896606\n",
      "Accuracy: 0.4513999819755554\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss: 0.7569557428359985\n",
      "Accuracy: 0.4561999440193176\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss: 0.7903242111206055\n",
      "Accuracy: 0.4395999610424042\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss: 0.7472383379936218\n",
      "Accuracy: 0.44839999079704285\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss: 0.8010904788970947\n",
      "Accuracy: 0.44919997453689575\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss: 0.7734949588775635\n",
      "Accuracy: 0.45479997992515564\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss: 0.7718598246574402\n",
      "Accuracy: 0.4487999975681305\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss: 0.7598320245742798\n",
      "Accuracy: 0.4447999894618988\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss: 0.7628839015960693\n",
      "Accuracy: 0.4479999542236328\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss: 0.7855703830718994\n",
      "Accuracy: 0.44499996304512024\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss: 0.739789605140686\n",
      "Accuracy: 0.452799916267395\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss: 0.7618706226348877\n",
      "Accuracy: 0.4562000036239624\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss: 0.7567219734191895\n",
      "Accuracy: 0.4519999325275421\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss: 0.7623627185821533\n",
      "Accuracy: 0.4477999806404114\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss: 0.7870921492576599\n",
      "Accuracy: 0.453000009059906\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss: 0.7834779024124146\n",
      "Accuracy: 0.44419994950294495\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss: 0.803835928440094\n",
      "Accuracy: 0.4593999981880188\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss: 0.7593673467636108\n",
      "Accuracy: 0.4503999650478363\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss: 0.786448061466217\n",
      "Accuracy: 0.46039995551109314\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss: 0.7754690647125244\n",
      "Accuracy: 0.45419996976852417\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss: 0.7648726105690002\n",
      "Accuracy: 0.4625999629497528\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss: 0.7821111679077148\n",
      "Accuracy: 0.4561999440193176\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss: 0.8014193773269653\n",
      "Accuracy: 0.46779996156692505\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss: 0.792830228805542\n",
      "Accuracy: 0.4609999358654022\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss: 0.7510648965835571\n",
      "Accuracy: 0.4753999710083008\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss: 0.7593367099761963\n",
      "Accuracy: 0.4723999500274658\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss: 0.7835662364959717\n",
      "Accuracy: 0.47499996423721313\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss: 0.7628051042556763\n",
      "Accuracy: 0.47099995613098145\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss: 0.7421258687973022\n",
      "Accuracy: 0.46939995884895325\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss: 0.7429192662239075\n",
      "Accuracy: 0.4819999635219574\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss: 0.77836012840271\n",
      "Accuracy: 0.45159995555877686\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss: 0.757599949836731\n",
      "Accuracy: 0.4843999743461609\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss: 0.7587121725082397\n",
      "Accuracy: 0.4715999364852905\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss: 0.7080174088478088\n",
      "Accuracy: 0.4765999913215637\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss: 0.7165217995643616\n",
      "Accuracy: 0.4737999439239502\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss: 0.7425997257232666\n",
      "Accuracy: 0.4883999824523926\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss: 0.7298284769058228\n",
      "Accuracy: 0.48659998178482056\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss: 0.7508883476257324\n",
      "Accuracy: 0.4877999722957611\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss: 0.7052931189537048\n",
      "Accuracy: 0.47979995608329773\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss: 0.7103641629219055\n",
      "Accuracy: 0.47499996423721313\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss: 0.7066044211387634\n",
      "Accuracy: 0.4811999797821045\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss: 0.7493903040885925\n",
      "Accuracy: 0.472199946641922\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss: 0.7555216550827026\n",
      "Accuracy: 0.4599999785423279\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss: 0.7306777834892273\n",
      "Accuracy: 0.47999995946884155\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss: 0.7012312412261963\n",
      "Accuracy: 0.47919997572898865\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss: 0.6697176098823547\n",
      "Accuracy: 0.4785999655723572\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss: 0.7102866172790527\n",
      "Accuracy: 0.4841999411582947\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss: 0.6682559251785278\n",
      "Accuracy: 0.4811999797821045\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss: 0.6743518710136414\n",
      "Accuracy: 0.4813999533653259\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss: 0.6764510273933411\n",
      "Accuracy: 0.4955999553203583\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss: 0.6678423881530762\n",
      "Accuracy: 0.5023999214172363\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss: 0.6749464869499207\n",
      "Accuracy: 0.487199991941452\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss: 0.7161659002304077\n",
      "Accuracy: 0.4845999479293823\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss: 0.6767115592956543\n",
      "Accuracy: 0.4899999499320984\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss: 0.698202908039093\n",
      "Accuracy: 0.49540001153945923\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss: 0.7041045427322388\n",
      "Accuracy: 0.4893999695777893\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss: 0.6739208102226257\n",
      "Accuracy: 0.4933999478816986\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss: 0.6763578057289124\n",
      "Accuracy: 0.4869999885559082\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss: 0.6913812160491943\n",
      "Accuracy: 0.49359995126724243\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss: 0.7104402184486389\n",
      "Accuracy: 0.49379995465278625\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss: 0.6904126405715942\n",
      "Accuracy: 0.4907999634742737\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss: 0.6524237394332886\n",
      "Accuracy: 0.4957999587059021\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss: 0.6568760275840759\n",
      "Accuracy: 0.49599993228912354\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss: 0.6698230504989624\n",
      "Accuracy: 0.4829999804496765\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss: 0.6409267783164978\n",
      "Accuracy: 0.5038000345230103\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss: 0.6475209593772888\n",
      "Accuracy: 0.49039995670318604\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss: 0.6438766717910767\n",
      "Accuracy: 0.4957999587059021\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss: 0.6595245599746704\n",
      "Accuracy: 0.47499993443489075\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss: 0.6551611423492432\n",
      "Accuracy: 0.4967999756336212\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss: 0.6601042151451111\n",
      "Accuracy: 0.5031999349594116\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss: 0.6885236501693726\n",
      "Accuracy: 0.501800000667572\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss: 0.6444013118743896\n",
      "Accuracy: 0.49219995737075806\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss: 0.662605881690979\n",
      "Accuracy: 0.48819997906684875\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss: 0.669567346572876\n",
      "Accuracy: 0.49759992957115173\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss: 0.6337135434150696\n",
      "Accuracy: 0.49699994921684265\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss: 0.6433129906654358\n",
      "Accuracy: 0.5031999945640564\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss: 0.6301644444465637\n",
      "Accuracy: 0.49799996614456177\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss: 0.6218418478965759\n",
      "Accuracy: 0.5087999701499939\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss: 0.6404948830604553\n",
      "Accuracy: 0.4925999641418457\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss: 0.6291970610618591\n",
      "Accuracy: 0.5065999627113342\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss: 0.6258860230445862\n",
      "Accuracy: 0.504599928855896\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss: 0.6241467595100403\n",
      "Accuracy: 0.5043999552726746\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss: 0.635215163230896\n",
      "Accuracy: 0.4963999390602112\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss: 0.6175923347473145\n",
      "Accuracy: 0.49639996886253357\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss: 0.6602146029472351\n",
      "Accuracy: 0.5001999735832214\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss: 0.6380733847618103\n",
      "Accuracy: 0.4997999370098114\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss: 0.641593337059021\n",
      "Accuracy: 0.495199978351593\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss: 0.6029441952705383\n",
      "Accuracy: 0.5077999830245972\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss: 0.6314449906349182\n",
      "Accuracy: 0.5121999382972717\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss: 0.6190431714057922\n",
      "Accuracy: 0.49699997901916504\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss: 0.6250412464141846\n",
      "Accuracy: 0.5027999877929688\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss: 0.5969318151473999\n",
      "Accuracy: 0.5127999782562256\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss: 0.6010705232620239\n",
      "Accuracy: 0.5051999688148499\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss: 0.6180421113967896\n",
      "Accuracy: 0.5033999681472778\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss: 0.6133337020874023\n",
      "Accuracy: 0.5127999186515808\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss: 0.6120294332504272\n",
      "Accuracy: 0.5017999410629272\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss: 0.6277483105659485\n",
      "Accuracy: 0.5031999349594116\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss: 0.6259681582450867\n",
      "Accuracy: 0.51419997215271\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss: 0.6195976734161377\n",
      "Accuracy: 0.5063999891281128\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss: 0.603244423866272\n",
      "Accuracy: 0.5109999775886536\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss: 0.6206145286560059\n",
      "Accuracy: 0.5113999247550964\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss: 0.6022939682006836\n",
      "Accuracy: 0.5037999749183655\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss: 0.6088197231292725\n",
      "Accuracy: 0.5105999708175659\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss: 0.5938657522201538\n",
      "Accuracy: 0.4973999261856079\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss: 0.6115432977676392\n",
      "Accuracy: 0.5133999586105347\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss: 0.6204119920730591\n",
      "Accuracy: 0.5037999153137207\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss: 0.6331243515014648\n",
      "Accuracy: 0.49679991602897644\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss: 0.602232813835144\n",
      "Accuracy: 0.5057998895645142\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss: 0.5887115597724915\n",
      "Accuracy: 0.5131999254226685\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss: 0.59566330909729\n",
      "Accuracy: 0.5089999437332153\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss: 0.599420428276062\n",
      "Accuracy: 0.5115999579429626\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss: 0.601003110408783\n",
      "Accuracy: 0.5029999017715454\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss: 0.5852140188217163\n",
      "Accuracy: 0.512999951839447\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss: 0.5658585429191589\n",
      "Accuracy: 0.5121999382972717\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss: 0.5742723941802979\n",
      "Accuracy: 0.5137999653816223\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss: 0.6224880218505859\n",
      "Accuracy: 0.5135999321937561\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss: 0.5878774523735046\n",
      "Accuracy: 0.5141999125480652\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss: 0.5739021897315979\n",
      "Accuracy: 0.5113999843597412\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss: 0.570501983165741\n",
      "Accuracy: 0.5167999863624573\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss: 0.5849981307983398\n",
      "Accuracy: 0.5169999599456787\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss: 0.5875880718231201\n",
      "Accuracy: 0.5047999620437622\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss: 0.6044991612434387\n",
      "Accuracy: 0.5135999917984009\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss: 0.603498101234436\n",
      "Accuracy: 0.5031999349594116\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss: 0.6193721890449524\n",
      "Accuracy: 0.5083999633789062\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss: 0.5572911500930786\n",
      "Accuracy: 0.5237999558448792\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss: 0.5910125374794006\n",
      "Accuracy: 0.5137999653816223\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss: 0.5798901319503784\n",
      "Accuracy: 0.5217999815940857\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss: 0.5895709991455078\n",
      "Accuracy: 0.5191999077796936\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss: 0.591019868850708\n",
      "Accuracy: 0.5031999349594116\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss: 0.5636085271835327\n",
      "Accuracy: 0.5193999409675598\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss: 0.5553362369537354\n",
      "Accuracy: 0.5022000074386597\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss: 0.5918272733688354\n",
      "Accuracy: 0.5077999830245972\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss: 0.5704693794250488\n",
      "Accuracy: 0.5155999660491943\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss: 0.565406322479248\n",
      "Accuracy: 0.5199999213218689\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss: 0.5709635615348816\n",
      "Accuracy: 0.5201998949050903\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss: 0.5756280422210693\n",
      "Accuracy: 0.5067999362945557\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss: 0.5753562450408936\n",
      "Accuracy: 0.5163999199867249\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss: 0.5940418243408203\n",
      "Accuracy: 0.5209999680519104\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss: 0.5816751718521118\n",
      "Accuracy: 0.51419997215271\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss: 0.558344841003418\n",
      "Accuracy: 0.5073999762535095\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss: 0.6210039854049683\n",
      "Accuracy: 0.5157999396324158\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss: 0.5629478693008423\n",
      "Accuracy: 0.5127999782562256\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss: 0.5505092740058899\n",
      "Accuracy: 0.5197998881340027\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss: 0.5667815804481506\n",
      "Accuracy: 0.5135999321937561\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss: 0.5689556002616882\n",
      "Accuracy: 0.5191999077796936\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss: 0.5505200624465942\n",
      "Accuracy: 0.5227999687194824\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss: 0.5311238765716553\n",
      "Accuracy: 0.5191999673843384\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss: 0.5519931316375732\n",
      "Accuracy: 0.5167999863624573\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss: 0.5408886671066284\n",
      "Accuracy: 0.5051999688148499\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss: 0.568595826625824\n",
      "Accuracy: 0.5125999450683594\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss: 0.5558665990829468\n",
      "Accuracy: 0.5209999084472656\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss: 0.5504321455955505\n",
      "Accuracy: 0.5259999632835388\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss: 0.5707447528839111\n",
      "Accuracy: 0.5153999328613281\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss: 0.5894978046417236\n",
      "Accuracy: 0.5223999619483948\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss: 0.5269243717193604\n",
      "Accuracy: 0.5169999003410339\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss: 0.5619052648544312\n",
      "Accuracy: 0.5293999314308167\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss: 0.5568512678146362\n",
      "Accuracy: 0.5221999883651733\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss: 0.5386064648628235\n",
      "Accuracy: 0.5173999071121216\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss: 0.5459416508674622\n",
      "Accuracy: 0.5181999802589417\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss: 0.5262724161148071\n",
      "Accuracy: 0.5201999545097351\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss: 0.5380797386169434\n",
      "Accuracy: 0.5323998928070068\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss: 0.5474506616592407\n",
      "Accuracy: 0.511199951171875\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss: 0.5514095425605774\n",
      "Accuracy: 0.524399995803833\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss: 0.5466495752334595\n",
      "Accuracy: 0.5181999206542969\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss: 0.5440492630004883\n",
      "Accuracy: 0.5175999402999878\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss: 0.5289153456687927\n",
      "Accuracy: 0.5221999287605286\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss: 0.5374802350997925\n",
      "Accuracy: 0.5261999368667603\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss: 0.5354567766189575\n",
      "Accuracy: 0.5205999612808228\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss: 0.5439459681510925\n",
      "Accuracy: 0.5311999320983887\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss: 0.562818706035614\n",
      "Accuracy: 0.5261999368667603\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss: 0.5452241897583008\n",
      "Accuracy: 0.5267999172210693\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss: 0.5579771995544434\n",
      "Accuracy: 0.5155999064445496\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss: 0.5345741510391235\n",
      "Accuracy: 0.5235999226570129\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss: 0.5549553632736206\n",
      "Accuracy: 0.5213999152183533\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss: 0.5633454322814941\n",
      "Accuracy: 0.5261999368667603\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss: 0.5282896757125854\n",
      "Accuracy: 0.5189999341964722\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss: 0.5899007320404053\n",
      "Accuracy: 0.5097999572753906\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss: 0.5497364401817322\n",
      "Accuracy: 0.5277999639511108\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss: 0.5189325213432312\n",
      "Accuracy: 0.5285999774932861\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss: 0.5281851291656494\n",
      "Accuracy: 0.5265999436378479\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss: 0.5577226877212524\n",
      "Accuracy: 0.5199999213218689\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss: 0.5355499386787415\n",
      "Accuracy: 0.5345999598503113\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss: 0.5378628969192505\n",
      "Accuracy: 0.5263999104499817\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss: 0.5460531711578369\n",
      "Accuracy: 0.5069999694824219\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss: 0.5488811731338501\n",
      "Accuracy: 0.5343999266624451\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss: 0.5214781761169434\n",
      "Accuracy: 0.5343999266624451\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss: 0.5488049983978271\n",
      "Accuracy: 0.5275999307632446\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss: 0.5473697185516357\n",
      "Accuracy: 0.5285999774932861\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss: 0.538908839225769\n",
      "Accuracy: 0.5297999382019043\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss: 0.5374153852462769\n",
      "Accuracy: 0.5173999071121216\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss: 0.5284266471862793\n",
      "Accuracy: 0.5255999565124512\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss: 0.5263099670410156\n",
      "Accuracy: 0.5339999198913574\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss: 0.5392154455184937\n",
      "Accuracy: 0.5241999626159668\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss: 0.508782148361206\n",
      "Accuracy: 0.5229999423027039\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss: 0.5625951290130615\n",
      "Accuracy: 0.5211999416351318\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss: 0.5469592809677124\n",
      "Accuracy: 0.5255999565124512\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss: 0.5742377042770386\n",
      "Accuracy: 0.527199923992157\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss: 0.5303801894187927\n",
      "Accuracy: 0.5249999165534973\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss: 0.5472102165222168\n",
      "Accuracy: 0.5333999395370483\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss: 0.515009880065918\n",
      "Accuracy: 0.5309998989105225\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss: 0.5402556657791138\n",
      "Accuracy: 0.5273998975753784\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss: 0.5737883448600769\n",
      "Accuracy: 0.5175999999046326\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss: 0.5358240008354187\n",
      "Accuracy: 0.5131999254226685\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss: 0.5156568288803101\n",
      "Accuracy: 0.539199948310852\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss: 0.5642855763435364\n",
      "Accuracy: 0.5165999531745911\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss: 0.5681718587875366\n",
      "Accuracy: 0.5133999586105347\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss: 0.5305629372596741\n",
      "Accuracy: 0.5257999897003174\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss: 0.5183801651000977\n",
      "Accuracy: 0.5361999273300171\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss: 0.526360273361206\n",
      "Accuracy: 0.5207999348640442\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss: 0.5162913799285889\n",
      "Accuracy: 0.5360000133514404\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss: 0.5083169937133789\n",
      "Accuracy: 0.528999924659729\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss: 0.5176609754562378\n",
      "Accuracy: 0.5323999524116516\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss: 0.5467207431793213\n",
      "Accuracy: 0.5299999713897705\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss: 0.5330230593681335\n",
      "Accuracy: 0.5185999870300293\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss: 0.5153107047080994\n",
      "Accuracy: 0.5197999477386475\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss: 0.5507432222366333\n",
      "Accuracy: 0.5269999504089355\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss: 0.5708268284797668\n",
      "Accuracy: 0.539199948310852\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss: 0.5324642658233643\n",
      "Accuracy: 0.5291999578475952\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss: 0.5590097904205322\n",
      "Accuracy: 0.5081999897956848\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss: 0.5295546054840088\n",
      "Accuracy: 0.530799925327301\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss: 0.5239542722702026\n",
      "Accuracy: 0.5371999144554138\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss: 0.5144029259681702\n",
      "Accuracy: 0.5247999429702759\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss: 0.5292496681213379\n",
      "Accuracy: 0.5185999870300293\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss: 0.5722960829734802\n",
      "Accuracy: 0.5291999578475952\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss: 0.5029815435409546\n",
      "Accuracy: 0.528999924659729\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss: 0.5231903195381165\n",
      "Accuracy: 0.5347998738288879\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss: 0.5271447896957397\n",
      "Accuracy: 0.5288000106811523\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss: 0.49637848138809204\n",
      "Accuracy: 0.5333999395370483\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss: 0.4944661259651184\n",
      "Accuracy: 0.5341999530792236\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss: 0.49200165271759033\n",
      "Accuracy: 0.5323999524116516\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss: 0.5341843366622925\n",
      "Accuracy: 0.5341999530792236\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss: 0.5018699169158936\n",
      "Accuracy: 0.5307999849319458\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss: 0.5027865767478943\n",
      "Accuracy: 0.5309998989105225\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss: 0.493937611579895\n",
      "Accuracy: 0.5401999354362488\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss: 0.5395792126655579\n",
      "Accuracy: 0.5303999781608582\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss: 0.5290653109550476\n",
      "Accuracy: 0.532599925994873\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss: 0.5056892037391663\n",
      "Accuracy: 0.5371999740600586\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss: 0.5075616240501404\n",
      "Accuracy: 0.535599946975708\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss: 0.4969818890094757\n",
      "Accuracy: 0.5299999117851257\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss: 0.5040079355239868\n",
      "Accuracy: 0.532599925994873\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss: 0.525145947933197\n",
      "Accuracy: 0.531999945640564\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss: 0.5213111639022827\n",
      "Accuracy: 0.5341999530792236\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss: 0.5244148969650269\n",
      "Accuracy: 0.5323999524116516\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss: 0.5017327666282654\n",
      "Accuracy: 0.5321999788284302\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss: 0.5053578615188599\n",
      "Accuracy: 0.5379999279975891\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss: 0.511284351348877\n",
      "Accuracy: 0.5397999286651611\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss: 0.5742366313934326\n",
      "Accuracy: 0.511199951171875\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss: 0.5105745792388916\n",
      "Accuracy: 0.5345999598503113\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss: 0.5169427394866943\n",
      "Accuracy: 0.531999945640564\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss: 0.5020597577095032\n",
      "Accuracy: 0.5353999137878418\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss: 0.5217162370681763\n",
      "Accuracy: 0.5207999348640442\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss: 0.5050913691520691\n",
      "Accuracy: 0.5331999063491821\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss: 0.5165607929229736\n",
      "Accuracy: 0.512999951839447\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss: 0.5188427567481995\n",
      "Accuracy: 0.524199903011322\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss: 0.4866940975189209\n",
      "Accuracy: 0.5343999862670898\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss: 0.5063718557357788\n",
      "Accuracy: 0.5327999591827393\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss: 0.502535343170166\n",
      "Accuracy: 0.5361998677253723\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss: 0.5079675316810608\n",
      "Accuracy: 0.5345999598503113\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss: 0.5060408711433411\n",
      "Accuracy: 0.5275999307632446\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss: 0.5282152891159058\n",
      "Accuracy: 0.5295999050140381\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss: 0.5053175091743469\n",
      "Accuracy: 0.5173999667167664\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss: 0.4953305125236511\n",
      "Accuracy: 0.53739994764328\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss: 0.49311313033103943\n",
      "Accuracy: 0.5211999416351318\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss: 0.5054057836532593\n",
      "Accuracy: 0.5395999550819397\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss: 0.4816761016845703\n",
      "Accuracy: 0.5423999428749084\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss: 0.4976625442504883\n",
      "Accuracy: 0.5291999578475952\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss: 0.49440938234329224\n",
      "Accuracy: 0.5437999367713928\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss: 0.4980626404285431\n",
      "Accuracy: 0.5341999530792236\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss: 0.5051162242889404\n",
      "Accuracy: 0.5099999308586121\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss: 0.4739947021007538\n",
      "Accuracy: 0.5127999782562256\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss: 0.5403910875320435\n",
      "Accuracy: 0.5167999267578125\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss: 0.5116459727287292\n",
      "Accuracy: 0.5335999727249146\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss: 0.48391738533973694\n",
      "Accuracy: 0.5341999530792236\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss: 0.5013116598129272\n",
      "Accuracy: 0.5395998954772949\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss: 0.4884069561958313\n",
      "Accuracy: 0.5469999313354492\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss: 0.47586938738822937\n",
      "Accuracy: 0.5409999489784241\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss: 0.4970596432685852\n",
      "Accuracy: 0.5463999509811401\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss: 0.4842633306980133\n",
      "Accuracy: 0.5389999151229858\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss: 0.4894573390483856\n",
      "Accuracy: 0.5329999327659607\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss: 0.5052405595779419\n",
      "Accuracy: 0.5397999286651611\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss: 0.4693455994129181\n",
      "Accuracy: 0.5433998703956604\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss: 0.5010867118835449\n",
      "Accuracy: 0.5333999991416931\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss: 0.5014312863349915\n",
      "Accuracy: 0.5369999408721924\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss: 0.4859130382537842\n",
      "Accuracy: 0.5313999652862549\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss: 0.4769473671913147\n",
      "Accuracy: 0.5391998887062073\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss: 0.48590588569641113\n",
      "Accuracy: 0.535599946975708\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss: 0.48311448097229004\n",
      "Accuracy: 0.5357999205589294\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss: 0.4878717362880707\n",
      "Accuracy: 0.5469999313354492\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss: 0.4857126772403717\n",
      "Accuracy: 0.5377999544143677\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss: 0.5194131135940552\n",
      "Accuracy: 0.5249999761581421\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss: 0.4984918236732483\n",
      "Accuracy: 0.5327999591827393\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss: 0.501289963722229\n",
      "Accuracy: 0.517799973487854\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss: 0.46475422382354736\n",
      "Accuracy: 0.5325999855995178\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss: 0.4780990481376648\n",
      "Accuracy: 0.5447999238967896\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.2997169494628906\n",
      "Accuracy: 0.0981999859213829\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 2.2682223320007324\n",
      "Accuracy: 0.1345999836921692\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 2.065290927886963\n",
      "Accuracy: 0.18379999697208405\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 2.0957083702087402\n",
      "Accuracy: 0.17259998619556427\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 2.0852720737457275\n",
      "Accuracy: 0.20319999754428864\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.1731886863708496\n",
      "Accuracy: 0.17579999566078186\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 2.0731558799743652\n",
      "Accuracy: 0.19499999284744263\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 1.7668706178665161\n",
      "Accuracy: 0.2021999955177307\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 1.960819959640503\n",
      "Accuracy: 0.2077999860048294\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.9687719345092773\n",
      "Accuracy: 0.21639998257160187\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.11617374420166\n",
      "Accuracy: 0.2232000082731247\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 2.0252537727355957\n",
      "Accuracy: 0.23259998857975006\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 1.7030779123306274\n",
      "Accuracy: 0.22839999198913574\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 1.8864303827285767\n",
      "Accuracy: 0.2377999871969223\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.8862390518188477\n",
      "Accuracy: 0.2314000129699707\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.086077928543091\n",
      "Accuracy: 0.25019997358322144\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 1.9629358053207397\n",
      "Accuracy: 0.2635999917984009\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 1.6430896520614624\n",
      "Accuracy: 0.26259997487068176\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 1.825731635093689\n",
      "Accuracy: 0.27859997749328613\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.85475754737854\n",
      "Accuracy: 0.26239997148513794\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 2.03165602684021\n",
      "Accuracy: 0.29319998621940613\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 1.952003836631775\n",
      "Accuracy: 0.3033999800682068\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 1.542808175086975\n",
      "Accuracy: 0.29659998416900635\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.735361099243164\n",
      "Accuracy: 0.31380000710487366\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.7889677286148071\n",
      "Accuracy: 0.3041999936103821\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.9618399143218994\n",
      "Accuracy: 0.3158000111579895\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.905367374420166\n",
      "Accuracy: 0.3147999942302704\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 1.4644567966461182\n",
      "Accuracy: 0.326200008392334\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 1.6693040132522583\n",
      "Accuracy: 0.326200008392334\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.7725768089294434\n",
      "Accuracy: 0.29499998688697815\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.9122579097747803\n",
      "Accuracy: 0.3319999873638153\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.9292956590652466\n",
      "Accuracy: 0.33479997515678406\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 1.3934687376022339\n",
      "Accuracy: 0.3418000042438507\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 1.644972801208496\n",
      "Accuracy: 0.34279996156692505\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.7070742845535278\n",
      "Accuracy: 0.3149999678134918\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.8597283363342285\n",
      "Accuracy: 0.3452000021934509\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.8832318782806396\n",
      "Accuracy: 0.34859997034072876\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 1.3706518411636353\n",
      "Accuracy: 0.3545999825000763\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 1.6649982929229736\n",
      "Accuracy: 0.3545999526977539\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 1.6255931854248047\n",
      "Accuracy: 0.3399999737739563\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.7936183214187622\n",
      "Accuracy: 0.35659998655319214\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.810733437538147\n",
      "Accuracy: 0.3529999554157257\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 1.3243629932403564\n",
      "Accuracy: 0.36399996280670166\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 1.6311912536621094\n",
      "Accuracy: 0.3547999858856201\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 1.6193276643753052\n",
      "Accuracy: 0.3413999676704407\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.7645217180252075\n",
      "Accuracy: 0.36639997363090515\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 1.7898259162902832\n",
      "Accuracy: 0.36899998784065247\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 1.314745545387268\n",
      "Accuracy: 0.37219998240470886\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 1.6274467706680298\n",
      "Accuracy: 0.3611999750137329\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 1.585237741470337\n",
      "Accuracy: 0.3523999750614166\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.749132752418518\n",
      "Accuracy: 0.37860000133514404\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 1.7574925422668457\n",
      "Accuracy: 0.3716000020503998\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 1.2794203758239746\n",
      "Accuracy: 0.36799997091293335\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 1.611231803894043\n",
      "Accuracy: 0.37939998507499695\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 1.5500568151474\n",
      "Accuracy: 0.3675999343395233\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.701798915863037\n",
      "Accuracy: 0.38159996271133423\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 1.730642318725586\n",
      "Accuracy: 0.3837999701499939\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 1.2341852188110352\n",
      "Accuracy: 0.37859994173049927\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 1.5853033065795898\n",
      "Accuracy: 0.3813999593257904\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 1.5231480598449707\n",
      "Accuracy: 0.3611999750137329\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.7029240131378174\n",
      "Accuracy: 0.39259999990463257\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 1.7204816341400146\n",
      "Accuracy: 0.3837999701499939\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 1.2291532754898071\n",
      "Accuracy: 0.39139994978904724\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 1.5619921684265137\n",
      "Accuracy: 0.3797999620437622\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 1.5256458520889282\n",
      "Accuracy: 0.37359997630119324\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.6505237817764282\n",
      "Accuracy: 0.3965999484062195\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 1.6964192390441895\n",
      "Accuracy: 0.40059998631477356\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 1.2365061044692993\n",
      "Accuracy: 0.3961999714374542\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 1.5329759120941162\n",
      "Accuracy: 0.40119999647140503\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 1.5316126346588135\n",
      "Accuracy: 0.36879998445510864\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.6691410541534424\n",
      "Accuracy: 0.40060001611709595\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 1.6663322448730469\n",
      "Accuracy: 0.38659995794296265\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 1.1834990978240967\n",
      "Accuracy: 0.40519997477531433\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 1.5493592023849487\n",
      "Accuracy: 0.4121999442577362\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 1.4777462482452393\n",
      "Accuracy: 0.38399994373321533\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.5723755359649658\n",
      "Accuracy: 0.4063999652862549\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 1.635014295578003\n",
      "Accuracy: 0.40519997477531433\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 1.2135316133499146\n",
      "Accuracy: 0.4016000032424927\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 1.5879487991333008\n",
      "Accuracy: 0.41339996457099915\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 1.4828355312347412\n",
      "Accuracy: 0.39819997549057007\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.56681489944458\n",
      "Accuracy: 0.4143999516963959\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 1.5708436965942383\n",
      "Accuracy: 0.4018000066280365\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 1.1732425689697266\n",
      "Accuracy: 0.4124000072479248\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 1.5481300354003906\n",
      "Accuracy: 0.41760000586509705\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 1.451017141342163\n",
      "Accuracy: 0.3962000012397766\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.5449873208999634\n",
      "Accuracy: 0.4174000024795532\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 1.5546231269836426\n",
      "Accuracy: 0.41759997606277466\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 1.2092816829681396\n",
      "Accuracy: 0.41659998893737793\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 1.5304830074310303\n",
      "Accuracy: 0.4177999794483185\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 1.436080813407898\n",
      "Accuracy: 0.4007999897003174\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.5561668872833252\n",
      "Accuracy: 0.41919994354248047\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 1.541884183883667\n",
      "Accuracy: 0.41499996185302734\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 1.190627098083496\n",
      "Accuracy: 0.4156000018119812\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 1.5572566986083984\n",
      "Accuracy: 0.4131999611854553\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 1.436084270477295\n",
      "Accuracy: 0.4113999605178833\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.4911831617355347\n",
      "Accuracy: 0.42660000920295715\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 1.5448641777038574\n",
      "Accuracy: 0.42239996790885925\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 1.1736993789672852\n",
      "Accuracy: 0.40860000252723694\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 1.5570300817489624\n",
      "Accuracy: 0.4236000180244446\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 1.413522720336914\n",
      "Accuracy: 0.4155999720096588\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.4780551195144653\n",
      "Accuracy: 0.4147999882698059\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 1.5112122297286987\n",
      "Accuracy: 0.4177999496459961\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 1.1707273721694946\n",
      "Accuracy: 0.41739997267723083\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 1.5268726348876953\n",
      "Accuracy: 0.423399955034256\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 1.4000049829483032\n",
      "Accuracy: 0.4103999733924866\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.4967823028564453\n",
      "Accuracy: 0.4315999448299408\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 1.4831572771072388\n",
      "Accuracy: 0.4155999720096588\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 1.1564675569534302\n",
      "Accuracy: 0.42739999294281006\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 1.521024227142334\n",
      "Accuracy: 0.4269999861717224\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 1.4048649072647095\n",
      "Accuracy: 0.4156000018119812\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.417020559310913\n",
      "Accuracy: 0.4347999691963196\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 1.486411213874817\n",
      "Accuracy: 0.4275999665260315\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 1.1794254779815674\n",
      "Accuracy: 0.4267999827861786\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 1.5520246028900146\n",
      "Accuracy: 0.4333999752998352\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 1.3642431497573853\n",
      "Accuracy: 0.42479997873306274\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.4072531461715698\n",
      "Accuracy: 0.437999963760376\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 1.4590471982955933\n",
      "Accuracy: 0.4300000071525574\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 1.131388783454895\n",
      "Accuracy: 0.42719995975494385\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 1.5312235355377197\n",
      "Accuracy: 0.4333999752998352\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 1.3829889297485352\n",
      "Accuracy: 0.4147999882698059\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.3943421840667725\n",
      "Accuracy: 0.43619996309280396\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 1.4718782901763916\n",
      "Accuracy: 0.42719995975494385\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 1.1611032485961914\n",
      "Accuracy: 0.42320001125335693\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 1.5620965957641602\n",
      "Accuracy: 0.4439999461174011\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 1.362259864807129\n",
      "Accuracy: 0.4275999665260315\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.346498966217041\n",
      "Accuracy: 0.4341999590396881\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 1.459020972251892\n",
      "Accuracy: 0.43539997935295105\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 1.1406886577606201\n",
      "Accuracy: 0.42459994554519653\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 1.4973567724227905\n",
      "Accuracy: 0.43759995698928833\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 1.3576656579971313\n",
      "Accuracy: 0.43619996309280396\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.3620927333831787\n",
      "Accuracy: 0.4472000002861023\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 1.4528915882110596\n",
      "Accuracy: 0.4333999454975128\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 1.1382087469100952\n",
      "Accuracy: 0.4391999840736389\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 1.514858603477478\n",
      "Accuracy: 0.4421999752521515\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 1.3612571954727173\n",
      "Accuracy: 0.41599997878074646\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.3899483680725098\n",
      "Accuracy: 0.43880000710487366\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 1.4041370153427124\n",
      "Accuracy: 0.44199997186660767\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 1.148391842842102\n",
      "Accuracy: 0.4375999867916107\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 1.509892463684082\n",
      "Accuracy: 0.44679996371269226\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 1.3069956302642822\n",
      "Accuracy: 0.44119998812675476\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.3478163480758667\n",
      "Accuracy: 0.45219993591308594\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 1.4246586561203003\n",
      "Accuracy: 0.4291999638080597\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 1.110430121421814\n",
      "Accuracy: 0.44339996576309204\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 1.4906141757965088\n",
      "Accuracy: 0.449599951505661\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 1.3205598592758179\n",
      "Accuracy: 0.4411999583244324\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.3650825023651123\n",
      "Accuracy: 0.4577999711036682\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 1.4395322799682617\n",
      "Accuracy: 0.4411999583244324\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 1.1341371536254883\n",
      "Accuracy: 0.4471999704837799\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 1.4458348751068115\n",
      "Accuracy: 0.45959997177124023\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 1.31080961227417\n",
      "Accuracy: 0.44440001249313354\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.3203164339065552\n",
      "Accuracy: 0.45399996638298035\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 1.369307041168213\n",
      "Accuracy: 0.4479999542236328\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 1.0851550102233887\n",
      "Accuracy: 0.4503999650478363\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 1.4396648406982422\n",
      "Accuracy: 0.45259997248649597\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 1.3018091917037964\n",
      "Accuracy: 0.4403999447822571\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.3479321002960205\n",
      "Accuracy: 0.45799994468688965\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 1.4141381978988647\n",
      "Accuracy: 0.4561999440193176\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 1.063904047012329\n",
      "Accuracy: 0.4551999568939209\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 1.467969298362732\n",
      "Accuracy: 0.4615999460220337\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 1.269774079322815\n",
      "Accuracy: 0.4545999765396118\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.3267821073532104\n",
      "Accuracy: 0.4607999920845032\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 1.4074788093566895\n",
      "Accuracy: 0.4625999629497528\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 1.108332633972168\n",
      "Accuracy: 0.4497999846935272\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 1.4208523035049438\n",
      "Accuracy: 0.46119996905326843\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 1.28578782081604\n",
      "Accuracy: 0.44179999828338623\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.3152598142623901\n",
      "Accuracy: 0.4649999737739563\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 1.3588707447052002\n",
      "Accuracy: 0.446399986743927\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 1.0849469900131226\n",
      "Accuracy: 0.46139997243881226\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 1.4162178039550781\n",
      "Accuracy: 0.46939998865127563\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 1.242372751235962\n",
      "Accuracy: 0.46139997243881226\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.265805959701538\n",
      "Accuracy: 0.4829999804496765\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 1.3418488502502441\n",
      "Accuracy: 0.4633999764919281\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 1.122040033340454\n",
      "Accuracy: 0.4651999771595001\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 1.3934149742126465\n",
      "Accuracy: 0.4795999825000763\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 1.2519495487213135\n",
      "Accuracy: 0.4633999764919281\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.2791366577148438\n",
      "Accuracy: 0.4747999608516693\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 1.3143714666366577\n",
      "Accuracy: 0.4691999554634094\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 1.0882680416107178\n",
      "Accuracy: 0.4729999601840973\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 1.3783605098724365\n",
      "Accuracy: 0.47279995679855347\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 1.247305154800415\n",
      "Accuracy: 0.4659999907016754\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.2391862869262695\n",
      "Accuracy: 0.4803999364376068\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 1.2955379486083984\n",
      "Accuracy: 0.4761999845504761\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 1.0998811721801758\n",
      "Accuracy: 0.4649999737739563\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 1.360175371170044\n",
      "Accuracy: 0.48659998178482056\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 1.2421622276306152\n",
      "Accuracy: 0.4739999771118164\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.2562346458435059\n",
      "Accuracy: 0.4817999601364136\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 1.3081130981445312\n",
      "Accuracy: 0.46799999475479126\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 1.0571317672729492\n",
      "Accuracy: 0.4813999533653259\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 1.338828444480896\n",
      "Accuracy: 0.4899999499320984\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 1.2466044425964355\n",
      "Accuracy: 0.4719999432563782\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.2652796506881714\n",
      "Accuracy: 0.4893999695777893\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 1.271436333656311\n",
      "Accuracy: 0.4715999662876129\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 1.0684689283370972\n",
      "Accuracy: 0.480599969625473\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 1.3280353546142578\n",
      "Accuracy: 0.4835999608039856\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 1.2221622467041016\n",
      "Accuracy: 0.4827999472618103\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.2171154022216797\n",
      "Accuracy: 0.4947999119758606\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 1.2805957794189453\n",
      "Accuracy: 0.47979992628097534\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 1.0511842966079712\n",
      "Accuracy: 0.48399993777275085\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 1.3125606775283813\n",
      "Accuracy: 0.4975999593734741\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 1.2146155834197998\n",
      "Accuracy: 0.4827999472618103\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.236341953277588\n",
      "Accuracy: 0.4991999566555023\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 1.2866652011871338\n",
      "Accuracy: 0.48980000615119934\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 1.064955472946167\n",
      "Accuracy: 0.4833999574184418\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 1.312083125114441\n",
      "Accuracy: 0.5065999627113342\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 1.2164149284362793\n",
      "Accuracy: 0.48639994859695435\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.2014318704605103\n",
      "Accuracy: 0.5017999410629272\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 1.2510621547698975\n",
      "Accuracy: 0.4941999614238739\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 1.0606333017349243\n",
      "Accuracy: 0.4909999966621399\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 1.2664092779159546\n",
      "Accuracy: 0.5029999017715454\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 1.2122218608856201\n",
      "Accuracy: 0.49639999866485596\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.2372252941131592\n",
      "Accuracy: 0.5057999491691589\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 1.2530624866485596\n",
      "Accuracy: 0.4891999363899231\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 1.0902185440063477\n",
      "Accuracy: 0.49619993567466736\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 1.291572093963623\n",
      "Accuracy: 0.5015999674797058\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 1.1897385120391846\n",
      "Accuracy: 0.49039995670318604\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.1741689443588257\n",
      "Accuracy: 0.5217999815940857\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 1.217116355895996\n",
      "Accuracy: 0.48559993505477905\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 1.0863384008407593\n",
      "Accuracy: 0.49139997363090515\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 1.2905994653701782\n",
      "Accuracy: 0.5017999410629272\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 1.1889092922210693\n",
      "Accuracy: 0.5057999491691589\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.2102378606796265\n",
      "Accuracy: 0.5163999795913696\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 1.2397048473358154\n",
      "Accuracy: 0.5071999430656433\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 1.0758432149887085\n",
      "Accuracy: 0.4925999641418457\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 1.248692274093628\n",
      "Accuracy: 0.5085999369621277\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 1.1923506259918213\n",
      "Accuracy: 0.502799928188324\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.1383041143417358\n",
      "Accuracy: 0.5181999802589417\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 1.2206947803497314\n",
      "Accuracy: 0.5129998922348022\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 1.085312843322754\n",
      "Accuracy: 0.5003999471664429\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 1.2573096752166748\n",
      "Accuracy: 0.5083999633789062\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 1.1982101202011108\n",
      "Accuracy: 0.4957999587059021\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.1426488161087036\n",
      "Accuracy: 0.5211999416351318\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 1.2127165794372559\n",
      "Accuracy: 0.5123999714851379\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 1.0803897380828857\n",
      "Accuracy: 0.4885999858379364\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 1.2440738677978516\n",
      "Accuracy: 0.5167999267578125\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 1.1902356147766113\n",
      "Accuracy: 0.4989999234676361\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.1714811325073242\n",
      "Accuracy: 0.5217999219894409\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 1.1744126081466675\n",
      "Accuracy: 0.5169999599456787\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 1.0389084815979004\n",
      "Accuracy: 0.5037999749183655\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 1.2762541770935059\n",
      "Accuracy: 0.5091999173164368\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 1.1777715682983398\n",
      "Accuracy: 0.511199951171875\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 1.16343092918396\n",
      "Accuracy: 0.5180000066757202\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 1.1658164262771606\n",
      "Accuracy: 0.506399929523468\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 1.0350319147109985\n",
      "Accuracy: 0.514799952507019\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 1.2553337812423706\n",
      "Accuracy: 0.5203999280929565\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 1.1432344913482666\n",
      "Accuracy: 0.5173999071121216\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 1.1590933799743652\n",
      "Accuracy: 0.5293999314308167\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 1.200300931930542\n",
      "Accuracy: 0.5121999382972717\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 1.06033194065094\n",
      "Accuracy: 0.5135999917984009\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 1.2070765495300293\n",
      "Accuracy: 0.524199903011322\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 1.1315252780914307\n",
      "Accuracy: 0.5233999490737915\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 1.15073561668396\n",
      "Accuracy: 0.531999945640564\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 1.1725208759307861\n",
      "Accuracy: 0.5109999179840088\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 1.0176010131835938\n",
      "Accuracy: 0.5191999077796936\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 1.214714527130127\n",
      "Accuracy: 0.5237999558448792\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 1.1453590393066406\n",
      "Accuracy: 0.5149999856948853\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 1.1859091520309448\n",
      "Accuracy: 0.5281999111175537\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 1.220206618309021\n",
      "Accuracy: 0.5025999546051025\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 1.1183445453643799\n",
      "Accuracy: 0.5073999762535095\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 1.2070870399475098\n",
      "Accuracy: 0.514799952507019\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 1.1441618204116821\n",
      "Accuracy: 0.5181999206542969\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 1.121822714805603\n",
      "Accuracy: 0.5351999402046204\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 1.1795803308486938\n",
      "Accuracy: 0.5239999294281006\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 1.0498169660568237\n",
      "Accuracy: 0.515999972820282\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 1.1929248571395874\n",
      "Accuracy: 0.5273999571800232\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 1.14228093624115\n",
      "Accuracy: 0.5133999586105347\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 1.1305164098739624\n",
      "Accuracy: 0.5397999286651611\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 1.1925089359283447\n",
      "Accuracy: 0.5169999599456787\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 1.0401866436004639\n",
      "Accuracy: 0.5139999985694885\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 1.187026023864746\n",
      "Accuracy: 0.5309999585151672\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 1.1561311483383179\n",
      "Accuracy: 0.5243998765945435\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 1.1115713119506836\n",
      "Accuracy: 0.5393999218940735\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 1.1630464792251587\n",
      "Accuracy: 0.5167999863624573\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 1.0033787488937378\n",
      "Accuracy: 0.5217999815940857\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 1.2119499444961548\n",
      "Accuracy: 0.5227999091148376\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 1.1315877437591553\n",
      "Accuracy: 0.5163999199867249\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 1.1381518840789795\n",
      "Accuracy: 0.5449999570846558\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 1.1538331508636475\n",
      "Accuracy: 0.5094000101089478\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 1.0300976037979126\n",
      "Accuracy: 0.5313999652862549\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 1.200049877166748\n",
      "Accuracy: 0.5313999652862549\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 1.1514005661010742\n",
      "Accuracy: 0.5367999076843262\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 1.1514112949371338\n",
      "Accuracy: 0.5429999232292175\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 1.1675279140472412\n",
      "Accuracy: 0.5105999708175659\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 1.0344903469085693\n",
      "Accuracy: 0.5275999307632446\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 1.2086193561553955\n",
      "Accuracy: 0.5291999578475952\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 1.114556074142456\n",
      "Accuracy: 0.5225999355316162\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 1.1585856676101685\n",
      "Accuracy: 0.5395998954772949\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 1.1104373931884766\n",
      "Accuracy: 0.531999945640564\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.9833917021751404\n",
      "Accuracy: 0.5393999814987183\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 1.1658399105072021\n",
      "Accuracy: 0.5285999178886414\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 1.0910403728485107\n",
      "Accuracy: 0.5339999794960022\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 1.0890071392059326\n",
      "Accuracy: 0.5475999712944031\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 1.1582415103912354\n",
      "Accuracy: 0.5227999687194824\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.9924542903900146\n",
      "Accuracy: 0.5341999530792236\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 1.1768934726715088\n",
      "Accuracy: 0.542199969291687\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 1.1019091606140137\n",
      "Accuracy: 0.5395999550819397\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 1.072754979133606\n",
      "Accuracy: 0.5455999970436096\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 1.1452114582061768\n",
      "Accuracy: 0.5427998900413513\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.969933032989502\n",
      "Accuracy: 0.5407999753952026\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 1.2032675743103027\n",
      "Accuracy: 0.5293999314308167\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 1.0980167388916016\n",
      "Accuracy: 0.5307999849319458\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 1.1014502048492432\n",
      "Accuracy: 0.547999918460846\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss: 1.1158692836761475\n",
      "Accuracy: 0.5339999198913574\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss: 0.9444057941436768\n",
      "Accuracy: 0.5383999347686768\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss: 1.170322299003601\n",
      "Accuracy: 0.5411999225616455\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss: 1.1107144355773926\n",
      "Accuracy: 0.5359999537467957\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 1.0864135026931763\n",
      "Accuracy: 0.5537999272346497\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss: 1.1476861238479614\n",
      "Accuracy: 0.5359999537467957\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss: 0.9672017097473145\n",
      "Accuracy: 0.5317999720573425\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss: 1.1688545942306519\n",
      "Accuracy: 0.547999918460846\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss: 1.1090933084487915\n",
      "Accuracy: 0.5381999015808105\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 1.0602879524230957\n",
      "Accuracy: 0.5535999536514282\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss: 1.1380202770233154\n",
      "Accuracy: 0.5371999740600586\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss: 0.9742964506149292\n",
      "Accuracy: 0.5341999530792236\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss: 1.1935068368911743\n",
      "Accuracy: 0.5419999361038208\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss: 1.0836739540100098\n",
      "Accuracy: 0.5387999415397644\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 1.0405516624450684\n",
      "Accuracy: 0.5499999523162842\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss: 1.1404740810394287\n",
      "Accuracy: 0.5255999565124512\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss: 1.0046110153198242\n",
      "Accuracy: 0.5339999198913574\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss: 1.1517003774642944\n",
      "Accuracy: 0.5571999549865723\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss: 1.1023526191711426\n",
      "Accuracy: 0.5203999280929565\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 1.026308298110962\n",
      "Accuracy: 0.5527999401092529\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss: 1.1675779819488525\n",
      "Accuracy: 0.5383999347686768\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss: 0.986150324344635\n",
      "Accuracy: 0.533799946308136\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss: 1.180736780166626\n",
      "Accuracy: 0.5389999151229858\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss: 1.053784966468811\n",
      "Accuracy: 0.5393999218940735\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 1.0709608793258667\n",
      "Accuracy: 0.5505999326705933\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss: 1.0798271894454956\n",
      "Accuracy: 0.535599946975708\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss: 0.9783164858818054\n",
      "Accuracy: 0.5329999327659607\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss: 1.1325477361679077\n",
      "Accuracy: 0.5469999313354492\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss: 1.0818917751312256\n",
      "Accuracy: 0.5419999957084656\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 1.0396530628204346\n",
      "Accuracy: 0.5419999361038208\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss: 1.0982980728149414\n",
      "Accuracy: 0.5363999605178833\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss: 0.9934946894645691\n",
      "Accuracy: 0.5419999361038208\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss: 1.1590251922607422\n",
      "Accuracy: 0.5295999050140381\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss: 1.0532680749893188\n",
      "Accuracy: 0.5367999076843262\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.9822070598602295\n",
      "Accuracy: 0.5483999252319336\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss: 1.1129117012023926\n",
      "Accuracy: 0.5377998948097229\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss: 0.9518097639083862\n",
      "Accuracy: 0.5479999780654907\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss: 1.1175755262374878\n",
      "Accuracy: 0.549799919128418\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss: 1.0515410900115967\n",
      "Accuracy: 0.5385999083518982\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 1.0556919574737549\n",
      "Accuracy: 0.5399999618530273\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss: 1.0564662218093872\n",
      "Accuracy: 0.5379999876022339\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss: 1.0241317749023438\n",
      "Accuracy: 0.5303999185562134\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss: 1.154654622077942\n",
      "Accuracy: 0.5433999300003052\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss: 1.0356084108352661\n",
      "Accuracy: 0.5343999862670898\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 1.0639632940292358\n",
      "Accuracy: 0.5513999462127686\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss: 1.0809605121612549\n",
      "Accuracy: 0.5465999841690063\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss: 0.9639186859130859\n",
      "Accuracy: 0.5413999557495117\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss: 1.16325044631958\n",
      "Accuracy: 0.5595999956130981\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss: 1.0278645753860474\n",
      "Accuracy: 0.5347999334335327\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 1.0157341957092285\n",
      "Accuracy: 0.555199921131134\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss: 1.0849964618682861\n",
      "Accuracy: 0.5381999611854553\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss: 0.9663873910903931\n",
      "Accuracy: 0.5445998907089233\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss: 1.1180245876312256\n",
      "Accuracy: 0.5455999374389648\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss: 1.0413163900375366\n",
      "Accuracy: 0.5343999862670898\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 1.0235507488250732\n",
      "Accuracy: 0.5577999353408813\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss: 1.0422855615615845\n",
      "Accuracy: 0.543199896812439\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss: 0.9870376586914062\n",
      "Accuracy: 0.5443999767303467\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss: 1.115450382232666\n",
      "Accuracy: 0.5443999171257019\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss: 1.0295885801315308\n",
      "Accuracy: 0.5453999638557434\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.9965394735336304\n",
      "Accuracy: 0.5613999366760254\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss: 1.1060614585876465\n",
      "Accuracy: 0.5241999626159668\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss: 1.0191359519958496\n",
      "Accuracy: 0.5327999591827393\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss: 1.1265225410461426\n",
      "Accuracy: 0.5579999685287476\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss: 1.045940637588501\n",
      "Accuracy: 0.540399968624115\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.9431349039077759\n",
      "Accuracy: 0.5659999251365662\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss: 1.0599383115768433\n",
      "Accuracy: 0.5309999585151672\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss: 0.9982870221138\n",
      "Accuracy: 0.5419999361038208\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss: 1.090977430343628\n",
      "Accuracy: 0.5557999014854431\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss: 1.0688107013702393\n",
      "Accuracy: 0.5307999849319458\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.943470299243927\n",
      "Accuracy: 0.562999963760376\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss: 1.058077096939087\n",
      "Accuracy: 0.5443998575210571\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss: 0.9657289981842041\n",
      "Accuracy: 0.5501999855041504\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss: 1.112405776977539\n",
      "Accuracy: 0.5509999990463257\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss: 1.048351764678955\n",
      "Accuracy: 0.5505999326705933\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 1.0118155479431152\n",
      "Accuracy: 0.5589999556541443\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss: 1.082770824432373\n",
      "Accuracy: 0.5557999014854431\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss: 0.962684154510498\n",
      "Accuracy: 0.5499999523162842\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss: 1.1283506155014038\n",
      "Accuracy: 0.5545998811721802\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss: 1.0807572603225708\n",
      "Accuracy: 0.5555999279022217\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 1.0510532855987549\n",
      "Accuracy: 0.5546000003814697\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss: 1.0949440002441406\n",
      "Accuracy: 0.532599925994873\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss: 0.9891356229782104\n",
      "Accuracy: 0.5419999361038208\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss: 1.0594313144683838\n",
      "Accuracy: 0.5513999462127686\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss: 1.042572021484375\n",
      "Accuracy: 0.5511999130249023\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 1.0002559423446655\n",
      "Accuracy: 0.5575999617576599\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss: 1.057425856590271\n",
      "Accuracy: 0.5407999753952026\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss: 0.9780134558677673\n",
      "Accuracy: 0.5517999529838562\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss: 1.086308479309082\n",
      "Accuracy: 0.5597999095916748\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss: 1.0580662488937378\n",
      "Accuracy: 0.5381999611854553\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 1.0154447555541992\n",
      "Accuracy: 0.5531998872756958\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss: 1.0399291515350342\n",
      "Accuracy: 0.532599925994873\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss: 0.9731972813606262\n",
      "Accuracy: 0.5419999361038208\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss: 1.0576549768447876\n",
      "Accuracy: 0.5543999075889587\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss: 1.0160671472549438\n",
      "Accuracy: 0.5609999299049377\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.9960451722145081\n",
      "Accuracy: 0.5655999183654785\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss: 1.129888892173767\n",
      "Accuracy: 0.5393999814987183\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss: 0.9286203980445862\n",
      "Accuracy: 0.555199921131134\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss: 1.054401159286499\n",
      "Accuracy: 0.5655999183654785\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss: 0.9974714517593384\n",
      "Accuracy: 0.5401999354362488\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.9499636888504028\n",
      "Accuracy: 0.5669999718666077\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss: 1.065851092338562\n",
      "Accuracy: 0.5475999712944031\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss: 0.9220349192619324\n",
      "Accuracy: 0.5565999746322632\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss: 1.0651729106903076\n",
      "Accuracy: 0.5549999475479126\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss: 1.0094715356826782\n",
      "Accuracy: 0.5557999014854431\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.9792128801345825\n",
      "Accuracy: 0.5655999779701233\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss: 1.0667264461517334\n",
      "Accuracy: 0.5509999394416809\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss: 0.9358360171318054\n",
      "Accuracy: 0.5493999719619751\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss: 1.0887303352355957\n",
      "Accuracy: 0.5577999353408813\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss: 1.0052052736282349\n",
      "Accuracy: 0.5469999313354492\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.9578947424888611\n",
      "Accuracy: 0.5663999319076538\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss: 1.022908091545105\n",
      "Accuracy: 0.5555998682975769\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss: 0.9120188355445862\n",
      "Accuracy: 0.562999963760376\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss: 1.0703613758087158\n",
      "Accuracy: 0.5633999705314636\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss: 0.967995285987854\n",
      "Accuracy: 0.5637999773025513\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.9782246947288513\n",
      "Accuracy: 0.5673999786376953\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss: 1.0187824964523315\n",
      "Accuracy: 0.5461999773979187\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss: 0.9118380546569824\n",
      "Accuracy: 0.5585999488830566\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss: 1.059928059577942\n",
      "Accuracy: 0.5489999055862427\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss: 0.9840937852859497\n",
      "Accuracy: 0.5561999082565308\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.9531232118606567\n",
      "Accuracy: 0.5693998336791992\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss: 1.0309253931045532\n",
      "Accuracy: 0.5507999658584595\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss: 0.9112130403518677\n",
      "Accuracy: 0.5541999340057373\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss: 1.0401804447174072\n",
      "Accuracy: 0.5579999089241028\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss: 0.9927931427955627\n",
      "Accuracy: 0.5549999475479126\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.93521648645401\n",
      "Accuracy: 0.5667999386787415\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss: 1.0686163902282715\n",
      "Accuracy: 0.5395999550819397\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss: 0.9269448518753052\n",
      "Accuracy: 0.5583999752998352\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss: 1.0579555034637451\n",
      "Accuracy: 0.5719999074935913\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss: 1.0127689838409424\n",
      "Accuracy: 0.5529999136924744\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.9946011900901794\n",
      "Accuracy: 0.5661998987197876\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss: 0.9996910691261292\n",
      "Accuracy: 0.5487999320030212\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss: 0.9386105537414551\n",
      "Accuracy: 0.5543999671936035\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss: 1.0487061738967896\n",
      "Accuracy: 0.5593999624252319\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss: 0.9685763716697693\n",
      "Accuracy: 0.5611999034881592\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.9484870433807373\n",
      "Accuracy: 0.5755999684333801\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss: 1.0127983093261719\n",
      "Accuracy: 0.5529999136924744\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss: 0.9207735061645508\n",
      "Accuracy: 0.5505999326705933\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss: 1.0310336351394653\n",
      "Accuracy: 0.559999942779541\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss: 0.9817330241203308\n",
      "Accuracy: 0.5655999183654785\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.9376815557479858\n",
      "Accuracy: 0.5649999380111694\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss: 0.9905165433883667\n",
      "Accuracy: 0.5575999021530151\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss: 0.9330158233642578\n",
      "Accuracy: 0.5519999265670776\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss: 1.0375640392303467\n",
      "Accuracy: 0.5733999609947205\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss: 1.0034105777740479\n",
      "Accuracy: 0.5673999190330505\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.9431048631668091\n",
      "Accuracy: 0.5757999420166016\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss: 0.990236759185791\n",
      "Accuracy: 0.5605999827384949\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss: 0.877711832523346\n",
      "Accuracy: 0.5665999054908752\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss: 1.0369943380355835\n",
      "Accuracy: 0.5633999109268188\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss: 0.9267634749412537\n",
      "Accuracy: 0.5677999258041382\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 0.949081301689148\n",
      "Accuracy: 0.5697999596595764\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss: 1.0132761001586914\n",
      "Accuracy: 0.5585999488830566\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss: 0.8438775539398193\n",
      "Accuracy: 0.5645999312400818\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss: 1.0013339519500732\n",
      "Accuracy: 0.5747999548912048\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss: 0.9274600148200989\n",
      "Accuracy: 0.5665999054908752\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 0.9913588762283325\n",
      "Accuracy: 0.5727999210357666\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss: 1.0010526180267334\n",
      "Accuracy: 0.5715999007225037\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss: 0.8612763285636902\n",
      "Accuracy: 0.571199893951416\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss: 1.0016605854034424\n",
      "Accuracy: 0.5757998824119568\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss: 0.918218731880188\n",
      "Accuracy: 0.5703998804092407\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 0.9898669719696045\n",
      "Accuracy: 0.5721999406814575\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss: 1.0078401565551758\n",
      "Accuracy: 0.558199942111969\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss: 0.8804706335067749\n",
      "Accuracy: 0.5643999576568604\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss: 0.9861397743225098\n",
      "Accuracy: 0.5671999454498291\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss: 0.9747546315193176\n",
      "Accuracy: 0.5757998824119568\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 0.936004638671875\n",
      "Accuracy: 0.5797998905181885\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss: 0.9767434000968933\n",
      "Accuracy: 0.5633999109268188\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss: 0.9025490283966064\n",
      "Accuracy: 0.5589998960494995\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss: 1.035444736480713\n",
      "Accuracy: 0.5815999507904053\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss: 0.9469653367996216\n",
      "Accuracy: 0.5709999203681946\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 0.9321030378341675\n",
      "Accuracy: 0.577799916267395\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss: 1.0145546197891235\n",
      "Accuracy: 0.5555999279022217\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss: 0.8720602989196777\n",
      "Accuracy: 0.5627999305725098\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss: 1.0159748792648315\n",
      "Accuracy: 0.5731998682022095\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss: 0.9328806400299072\n",
      "Accuracy: 0.5659999251365662\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 0.9485599994659424\n",
      "Accuracy: 0.5845998525619507\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss: 0.9490534067153931\n",
      "Accuracy: 0.5669999122619629\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss: 0.900739312171936\n",
      "Accuracy: 0.5725998878479004\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss: 0.9772428870201111\n",
      "Accuracy: 0.5893998742103577\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss: 0.9160220623016357\n",
      "Accuracy: 0.5761999487876892\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.8999820947647095\n",
      "Accuracy: 0.5809999108314514\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss: 1.0006756782531738\n",
      "Accuracy: 0.5521999597549438\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss: 0.8745201230049133\n",
      "Accuracy: 0.5691999197006226\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss: 0.9919831156730652\n",
      "Accuracy: 0.5743998885154724\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss: 0.9282212257385254\n",
      "Accuracy: 0.5799999237060547\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.934287428855896\n",
      "Accuracy: 0.5793999433517456\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss: 0.9643758535385132\n",
      "Accuracy: 0.5699998736381531\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss: 0.821983814239502\n",
      "Accuracy: 0.5787999629974365\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss: 0.9824299812316895\n",
      "Accuracy: 0.5711999535560608\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss: 0.943516731262207\n",
      "Accuracy: 0.5785999298095703\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.9129123687744141\n",
      "Accuracy: 0.5793998837471008\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss: 0.9700117707252502\n",
      "Accuracy: 0.5699999332427979\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss: 0.8487628698348999\n",
      "Accuracy: 0.5745999813079834\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss: 0.9785196781158447\n",
      "Accuracy: 0.5847999453544617\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss: 0.9524536728858948\n",
      "Accuracy: 0.5671999454498291\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.96630859375\n",
      "Accuracy: 0.5709999799728394\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss: 1.0250866413116455\n",
      "Accuracy: 0.5697999000549316\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss: 0.8256103992462158\n",
      "Accuracy: 0.5757998824119568\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss: 0.9840961694717407\n",
      "Accuracy: 0.5789998769760132\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss: 0.9351874589920044\n",
      "Accuracy: 0.5663999319076538\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss: 0.88022780418396\n",
      "Accuracy: 0.5909999012947083\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss: 1.0265287160873413\n",
      "Accuracy: 0.5681999325752258\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss: 0.8402696847915649\n",
      "Accuracy: 0.5751999020576477\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss: 0.9240275025367737\n",
      "Accuracy: 0.5807998776435852\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss: 0.9607544541358948\n",
      "Accuracy: 0.5709999203681946\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss: 0.8717072606086731\n",
      "Accuracy: 0.591999888420105\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss: 0.9895176887512207\n",
      "Accuracy: 0.5621998906135559\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss: 0.8462182879447937\n",
      "Accuracy: 0.5739998817443848\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss: 0.9750380516052246\n",
      "Accuracy: 0.5911999940872192\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss: 0.9260730743408203\n",
      "Accuracy: 0.5857999324798584\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss: 0.8905572891235352\n",
      "Accuracy: 0.5863999128341675\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss: 0.9858810901641846\n",
      "Accuracy: 0.5703999400138855\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss: 0.8588708639144897\n",
      "Accuracy: 0.5627999305725098\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss: 0.963097095489502\n",
      "Accuracy: 0.5871999263763428\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss: 0.9358609914779663\n",
      "Accuracy: 0.5829998850822449\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss: 0.8578180074691772\n",
      "Accuracy: 0.5873998999595642\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss: 1.0023930072784424\n",
      "Accuracy: 0.5603999495506287\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss: 0.8378432989120483\n",
      "Accuracy: 0.579599916934967\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss: 0.9774942398071289\n",
      "Accuracy: 0.5837999582290649\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss: 0.9213093519210815\n",
      "Accuracy: 0.5855998992919922\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss: 0.9126176238059998\n",
      "Accuracy: 0.586199939250946\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss: 0.991367757320404\n",
      "Accuracy: 0.5689998865127563\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss: 0.8518573045730591\n",
      "Accuracy: 0.5725999474525452\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss: 0.9738885760307312\n",
      "Accuracy: 0.5783999562263489\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss: 0.9197606444358826\n",
      "Accuracy: 0.5791999697685242\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss: 0.8879836201667786\n",
      "Accuracy: 0.5903998613357544\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss: 0.9855692386627197\n",
      "Accuracy: 0.5719999074935913\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss: 0.8075898885726929\n",
      "Accuracy: 0.5813999176025391\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss: 0.9568666815757751\n",
      "Accuracy: 0.5911999344825745\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss: 0.9036425352096558\n",
      "Accuracy: 0.5851998925209045\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss: 0.8916259407997131\n",
      "Accuracy: 0.5845999717712402\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss: 0.9859357476234436\n",
      "Accuracy: 0.5727999210357666\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss: 0.8675780296325684\n",
      "Accuracy: 0.572399914264679\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss: 0.9192038178443909\n",
      "Accuracy: 0.5809999108314514\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss: 0.8700874447822571\n",
      "Accuracy: 0.5895999073982239\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss: 0.9284558296203613\n",
      "Accuracy: 0.5953999161720276\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss: 0.9981482028961182\n",
      "Accuracy: 0.5601999163627625\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss: 0.8405607342720032\n",
      "Accuracy: 0.5609999895095825\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss: 0.9119113087654114\n",
      "Accuracy: 0.5955999493598938\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss: 0.939777135848999\n",
      "Accuracy: 0.5859998464584351\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss: 0.9122352600097656\n",
      "Accuracy: 0.58899986743927\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss: 0.9778778553009033\n",
      "Accuracy: 0.5623999238014221\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss: 0.7962622046470642\n",
      "Accuracy: 0.5867999196052551\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss: 0.9062469005584717\n",
      "Accuracy: 0.5893999338150024\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss: 0.8891886472702026\n",
      "Accuracy: 0.5747998952865601\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss: 0.9463013410568237\n",
      "Accuracy: 0.5865998864173889\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss: 1.0081266164779663\n",
      "Accuracy: 0.5749999284744263\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss: 0.8224078416824341\n",
      "Accuracy: 0.5699999332427979\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss: 0.9307272434234619\n",
      "Accuracy: 0.5915999412536621\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss: 0.9218886494636536\n",
      "Accuracy: 0.5819999575614929\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss: 0.8683006763458252\n",
      "Accuracy: 0.5939999222755432\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss: 0.9943147301673889\n",
      "Accuracy: 0.5719999074935913\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss: 0.8050222396850586\n",
      "Accuracy: 0.5957999229431152\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss: 0.953707754611969\n",
      "Accuracy: 0.5811998844146729\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss: 0.9101963639259338\n",
      "Accuracy: 0.5831999182701111\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss: 0.8841999769210815\n",
      "Accuracy: 0.5881999731063843\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss: 1.0082435607910156\n",
      "Accuracy: 0.5679999589920044\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss: 0.8118285536766052\n",
      "Accuracy: 0.5823999643325806\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss: 0.9687703847885132\n",
      "Accuracy: 0.5901999473571777\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss: 0.8769979476928711\n",
      "Accuracy: 0.5961999297142029\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss: 0.875869631767273\n",
      "Accuracy: 0.6027998924255371\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss: 0.9882717132568359\n",
      "Accuracy: 0.5781999230384827\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss: 0.8009418845176697\n",
      "Accuracy: 0.5923999547958374\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss: 0.9292217493057251\n",
      "Accuracy: 0.5925998687744141\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss: 0.872065007686615\n",
      "Accuracy: 0.5903999209403992\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss: 0.840408205986023\n",
      "Accuracy: 0.5921999216079712\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss: 0.9703143835067749\n",
      "Accuracy: 0.5767999291419983\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss: 0.7997522354125977\n",
      "Accuracy: 0.5863999128341675\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss: 0.9122844934463501\n",
      "Accuracy: 0.5877999067306519\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss: 0.8773878812789917\n",
      "Accuracy: 0.5849999189376831\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss: 0.8579559326171875\n",
      "Accuracy: 0.5949999094009399\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss: 0.9927692413330078\n",
      "Accuracy: 0.5903999209403992\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss: 0.7840054035186768\n",
      "Accuracy: 0.5915999412536621\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss: 0.9222080707550049\n",
      "Accuracy: 0.5921999216079712\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss: 0.858585774898529\n",
      "Accuracy: 0.592799961566925\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss: 0.911960244178772\n",
      "Accuracy: 0.585399866104126\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss: 0.9294905662536621\n",
      "Accuracy: 0.5779999494552612\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss: 0.7948621511459351\n",
      "Accuracy: 0.5929999351501465\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss: 0.9245543479919434\n",
      "Accuracy: 0.5949999094009399\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss: 0.858067512512207\n",
      "Accuracy: 0.5865998864173889\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss: 0.8275693655014038\n",
      "Accuracy: 0.5981999635696411\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss: 0.9335939884185791\n",
      "Accuracy: 0.569399893283844\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss: 0.7853044271469116\n",
      "Accuracy: 0.5903999209403992\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss: 0.9259998798370361\n",
      "Accuracy: 0.5935999155044556\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss: 0.8657160997390747\n",
      "Accuracy: 0.5895999670028687\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss: 0.8353719711303711\n",
      "Accuracy: 0.5907999277114868\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss: 0.9379734992980957\n",
      "Accuracy: 0.5807998776435852\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss: 0.8069703578948975\n",
      "Accuracy: 0.5839999318122864\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss: 0.926893413066864\n",
      "Accuracy: 0.5933999419212341\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss: 0.8543062210083008\n",
      "Accuracy: 0.5743999481201172\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss: 0.8478738069534302\n",
      "Accuracy: 0.5949999094009399\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss: 0.9989520907402039\n",
      "Accuracy: 0.585399866104126\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss: 0.83143150806427\n",
      "Accuracy: 0.5837998390197754\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss: 0.9421044588088989\n",
      "Accuracy: 0.587399959564209\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss: 0.8365052342414856\n",
      "Accuracy: 0.5829999446868896\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss: 0.8209595084190369\n",
      "Accuracy: 0.5989999175071716\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss: 0.9845475554466248\n",
      "Accuracy: 0.5817999839782715\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss: 0.7934520840644836\n",
      "Accuracy: 0.5865999460220337\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss: 0.8853061199188232\n",
      "Accuracy: 0.5917999148368835\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss: 0.8502219915390015\n",
      "Accuracy: 0.5837998390197754\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss: 0.8519327640533447\n",
      "Accuracy: 0.5971999168395996\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss: 0.9404205083847046\n",
      "Accuracy: 0.5791999101638794\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss: 0.8287492394447327\n",
      "Accuracy: 0.5859999060630798\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss: 0.8857076168060303\n",
      "Accuracy: 0.6003998517990112\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss: 0.8519358038902283\n",
      "Accuracy: 0.5869998931884766\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss: 0.8271223306655884\n",
      "Accuracy: 0.5993999242782593\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss: 0.9529226422309875\n",
      "Accuracy: 0.575999915599823\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss: 0.7993897199630737\n",
      "Accuracy: 0.5923999547958374\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss: 0.9095261096954346\n",
      "Accuracy: 0.5917999148368835\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss: 0.8140371441841125\n",
      "Accuracy: 0.5939999222755432\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss: 0.8314111232757568\n",
      "Accuracy: 0.6019998788833618\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss: 0.9825607538223267\n",
      "Accuracy: 0.5921999216079712\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss: 0.8039633631706238\n",
      "Accuracy: 0.5891999006271362\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss: 0.9408258199691772\n",
      "Accuracy: 0.6015999913215637\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss: 0.8337509632110596\n",
      "Accuracy: 0.5821999311447144\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss: 0.8328582644462585\n",
      "Accuracy: 0.5999999046325684\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss: 0.932768702507019\n",
      "Accuracy: 0.5787999629974365\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss: 0.7870563268661499\n",
      "Accuracy: 0.5883999466896057\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss: 0.9039363861083984\n",
      "Accuracy: 0.5879998803138733\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss: 0.8307573795318604\n",
      "Accuracy: 0.5889999270439148\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss: 0.8458762168884277\n",
      "Accuracy: 0.5987998843193054\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss: 0.9741090536117554\n",
      "Accuracy: 0.5689999461174011\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss: 0.8254461884498596\n",
      "Accuracy: 0.5803999304771423\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss: 0.9135603904724121\n",
      "Accuracy: 0.6055998802185059\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss: 0.8281441926956177\n",
      "Accuracy: 0.5975998640060425\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss: 0.8070247173309326\n",
      "Accuracy: 0.5993999242782593\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss: 1.001172423362732\n",
      "Accuracy: 0.589199960231781\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss: 0.7641821503639221\n",
      "Accuracy: 0.5979999303817749\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss: 0.8413116931915283\n",
      "Accuracy: 0.592799961566925\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss: 0.8297991752624512\n",
      "Accuracy: 0.5879999399185181\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss: 0.8354174494743347\n",
      "Accuracy: 0.5979999303817749\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss: 1.0117745399475098\n",
      "Accuracy: 0.5831999182701111\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss: 0.7757610082626343\n",
      "Accuracy: 0.591999888420105\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss: 0.8716570734977722\n",
      "Accuracy: 0.6049998998641968\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss: 0.8195854425430298\n",
      "Accuracy: 0.5793999433517456\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss: 0.8285090923309326\n",
      "Accuracy: 0.595599889755249\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss: 1.0010086297988892\n",
      "Accuracy: 0.5849999189376831\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss: 0.7847362756729126\n",
      "Accuracy: 0.5977998971939087\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss: 0.8738487958908081\n",
      "Accuracy: 0.6005998849868774\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss: 0.8006420135498047\n",
      "Accuracy: 0.5933998823165894\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss: 0.832072377204895\n",
      "Accuracy: 0.6029999256134033\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss: 0.993131160736084\n",
      "Accuracy: 0.5917998552322388\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss: 0.8496406078338623\n",
      "Accuracy: 0.582599937915802\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss: 0.8613126277923584\n",
      "Accuracy: 0.590799868106842\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss: 0.7925788164138794\n",
      "Accuracy: 0.5783999562263489\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss: 0.8301047682762146\n",
      "Accuracy: 0.5941998958587646\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss: 0.9465055465698242\n",
      "Accuracy: 0.5885999202728271\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss: 0.790669322013855\n",
      "Accuracy: 0.592199981212616\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss: 0.8740124702453613\n",
      "Accuracy: 0.5957999229431152\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss: 0.8021580576896667\n",
      "Accuracy: 0.5901999473571777\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss: 0.7849292755126953\n",
      "Accuracy: 0.6057999134063721\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss: 0.9237297177314758\n",
      "Accuracy: 0.5901999473571777\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss: 0.8118531107902527\n",
      "Accuracy: 0.587199866771698\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss: 0.9031385779380798\n",
      "Accuracy: 0.5995998382568359\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss: 0.7886644601821899\n",
      "Accuracy: 0.5973999500274658\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss: 0.8144437670707703\n",
      "Accuracy: 0.6009998917579651\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss: 0.9405072927474976\n",
      "Accuracy: 0.5807998776435852\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss: 0.7976922988891602\n",
      "Accuracy: 0.5995998978614807\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss: 0.8731249570846558\n",
      "Accuracy: 0.6049998998641968\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss: 0.8199783563613892\n",
      "Accuracy: 0.5933999419212341\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss: 0.7797935605049133\n",
      "Accuracy: 0.6067999005317688\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss: 0.9308852553367615\n",
      "Accuracy: 0.578999936580658\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss: 0.8082730770111084\n",
      "Accuracy: 0.593799889087677\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss: 0.8912547826766968\n",
      "Accuracy: 0.6013999581336975\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss: 0.8537859916687012\n",
      "Accuracy: 0.5897999405860901\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss: 0.8142999410629272\n",
      "Accuracy: 0.5965999364852905\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss: 0.9741560220718384\n",
      "Accuracy: 0.5911998748779297\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss: 0.782488226890564\n",
      "Accuracy: 0.5975999236106873\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss: 0.8907977342605591\n",
      "Accuracy: 0.6055999398231506\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss: 0.8069992065429688\n",
      "Accuracy: 0.5915999412536621\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss: 0.7985438108444214\n",
      "Accuracy: 0.5965999364852905\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss: 0.9296401739120483\n",
      "Accuracy: 0.5901999473571777\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss: 0.7894766926765442\n",
      "Accuracy: 0.5893999338150024\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss: 0.8832598924636841\n",
      "Accuracy: 0.6029998660087585\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss: 0.7987267971038818\n",
      "Accuracy: 0.5987999439239502\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss: 0.7731300592422485\n",
      "Accuracy: 0.6067999005317688\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss: 0.9357661008834839\n",
      "Accuracy: 0.5845999121665955\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss: 0.7842652797698975\n",
      "Accuracy: 0.6039999127388\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss: 0.8879392147064209\n",
      "Accuracy: 0.607999861240387\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss: 0.8117706179618835\n",
      "Accuracy: 0.5957999229431152\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss: 0.8446638584136963\n",
      "Accuracy: 0.5993999242782593\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss: 0.9129071235656738\n",
      "Accuracy: 0.5865999460220337\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss: 0.7788176536560059\n",
      "Accuracy: 0.6023999452590942\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss: 0.8761722445487976\n",
      "Accuracy: 0.6017999053001404\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss: 0.7907949090003967\n",
      "Accuracy: 0.603399932384491\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss: 0.7811245322227478\n",
      "Accuracy: 0.6109998822212219\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss: 0.9216176271438599\n",
      "Accuracy: 0.5899999141693115\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss: 0.781722366809845\n",
      "Accuracy: 0.5957998633384705\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss: 0.844902515411377\n",
      "Accuracy: 0.6065998673439026\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss: 0.8014329671859741\n",
      "Accuracy: 0.6049998998641968\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss: 0.8335264921188354\n",
      "Accuracy: 0.605199933052063\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss: 0.9368401765823364\n",
      "Accuracy: 0.587199866771698\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss: 0.7887120842933655\n",
      "Accuracy: 0.5971998572349548\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss: 0.8531360030174255\n",
      "Accuracy: 0.6065998673439026\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss: 0.7932721376419067\n",
      "Accuracy: 0.6043999791145325\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss: 0.8280004858970642\n",
      "Accuracy: 0.6057999134063721\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss: 0.9063124656677246\n",
      "Accuracy: 0.5933998823165894\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss: 0.7446757555007935\n",
      "Accuracy: 0.6113999485969543\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss: 0.8963854908943176\n",
      "Accuracy: 0.6107999086380005\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss: 0.7743829488754272\n",
      "Accuracy: 0.6045998930931091\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss: 0.8125460147857666\n",
      "Accuracy: 0.6045998930931091\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss: 0.9006763100624084\n",
      "Accuracy: 0.5879999399185181\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss: 0.7287871837615967\n",
      "Accuracy: 0.6091999411582947\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss: 0.8633564710617065\n",
      "Accuracy: 0.6123998761177063\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss: 0.7966668605804443\n",
      "Accuracy: 0.598599910736084\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss: 0.7927316427230835\n",
      "Accuracy: 0.6147999167442322\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss: 0.9714116454124451\n",
      "Accuracy: 0.597399890422821\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss: 0.7286983728408813\n",
      "Accuracy: 0.6045998930931091\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss: 0.8180677890777588\n",
      "Accuracy: 0.6063998937606812\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss: 0.7994281649589539\n",
      "Accuracy: 0.6027998924255371\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss: 0.7876400351524353\n",
      "Accuracy: 0.6023998856544495\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss: 0.9444174766540527\n",
      "Accuracy: 0.5945999622344971\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss: 0.7764184474945068\n",
      "Accuracy: 0.6057999134063721\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss: 0.86161869764328\n",
      "Accuracy: 0.6047998666763306\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss: 0.8270302414894104\n",
      "Accuracy: 0.5953998565673828\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss: 0.8073928952217102\n",
      "Accuracy: 0.614599883556366\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss: 0.9563239812850952\n",
      "Accuracy: 0.6001998782157898\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss: 0.7846368551254272\n",
      "Accuracy: 0.6045999526977539\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss: 0.8456064462661743\n",
      "Accuracy: 0.6085999011993408\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss: 0.79801344871521\n",
      "Accuracy: 0.6023999452590942\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss: 0.8000982999801636\n",
      "Accuracy: 0.6085999011993408\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss: 0.9147441387176514\n",
      "Accuracy: 0.5911998748779297\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss: 0.7725800275802612\n",
      "Accuracy: 0.6071999073028564\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss: 0.8767609596252441\n",
      "Accuracy: 0.6093999147415161\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss: 0.7960554361343384\n",
      "Accuracy: 0.6039999127388\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss: 0.8003915548324585\n",
      "Accuracy: 0.6135998964309692\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss: 0.9014794826507568\n",
      "Accuracy: 0.6031998991966248\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss: 0.7433249950408936\n",
      "Accuracy: 0.6109998822212219\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss: 0.8574252128601074\n",
      "Accuracy: 0.6071999669075012\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss: 0.8310332298278809\n",
      "Accuracy: 0.5945999026298523\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss: 0.7978269457817078\n",
      "Accuracy: 0.6085999011993408\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss: 0.9829005002975464\n",
      "Accuracy: 0.5989999175071716\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss: 0.7888227105140686\n",
      "Accuracy: 0.6109998822212219\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss: 0.8179090023040771\n",
      "Accuracy: 0.6061998605728149\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss: 0.777679443359375\n",
      "Accuracy: 0.612799882888794\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss: 0.788442850112915\n",
      "Accuracy: 0.6131999492645264\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss: 0.9355742931365967\n",
      "Accuracy: 0.6055998802185059\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss: 0.7869712114334106\n",
      "Accuracy: 0.6051998734474182\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss: 0.8820640444755554\n",
      "Accuracy: 0.6011999845504761\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss: 0.7957763671875\n",
      "Accuracy: 0.5975999236106873\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss: 0.808323860168457\n",
      "Accuracy: 0.606799840927124\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss: 0.8788824677467346\n",
      "Accuracy: 0.5897998809814453\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss: 0.8241458535194397\n",
      "Accuracy: 0.596799910068512\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss: 0.8661571741104126\n",
      "Accuracy: 0.6087998747825623\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss: 0.7823697924613953\n",
      "Accuracy: 0.6035999059677124\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss: 0.7719084620475769\n",
      "Accuracy: 0.6055999994277954\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss: 0.940601110458374\n",
      "Accuracy: 0.5951999425888062\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss: 0.770231306552887\n",
      "Accuracy: 0.6053999662399292\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss: 0.8561266660690308\n",
      "Accuracy: 0.5975999236106873\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss: 0.8065592050552368\n",
      "Accuracy: 0.5975999236106873\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss: 0.7640995383262634\n",
      "Accuracy: 0.6111999750137329\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss: 0.9398604035377502\n",
      "Accuracy: 0.5993999242782593\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss: 0.7786291241645813\n",
      "Accuracy: 0.601599931716919\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss: 0.8730061650276184\n",
      "Accuracy: 0.6141998767852783\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss: 0.7738667130470276\n",
      "Accuracy: 0.6051998734474182\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss: 0.7787554264068604\n",
      "Accuracy: 0.6113999485969543\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss: 0.9212498664855957\n",
      "Accuracy: 0.5907999277114868\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss: 0.7553651332855225\n",
      "Accuracy: 0.6023998856544495\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss: 0.8396965861320496\n",
      "Accuracy: 0.6043999195098877\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss: 0.758226752281189\n",
      "Accuracy: 0.608799934387207\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss: 0.7904630303382874\n",
      "Accuracy: 0.6127999424934387\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss: 0.8821362257003784\n",
      "Accuracy: 0.596799910068512\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss: 0.7718956470489502\n",
      "Accuracy: 0.6097999215126038\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss: 0.8846623301506042\n",
      "Accuracy: 0.6119999289512634\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss: 0.7707638740539551\n",
      "Accuracy: 0.6063998937606812\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss: 0.7793661952018738\n",
      "Accuracy: 0.618399977684021\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss: 0.9046998023986816\n",
      "Accuracy: 0.6049998998641968\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss: 0.7528736591339111\n",
      "Accuracy: 0.6059998869895935\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss: 0.8428394794464111\n",
      "Accuracy: 0.606999933719635\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss: 0.7654961943626404\n",
      "Accuracy: 0.6093999147415161\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss: 0.7966291308403015\n",
      "Accuracy: 0.6107999086380005\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss: 0.8865104913711548\n",
      "Accuracy: 0.5925998687744141\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss: 0.7504472732543945\n",
      "Accuracy: 0.6091998815536499\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss: 0.8388922214508057\n",
      "Accuracy: 0.5989998579025269\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss: 0.7676974534988403\n",
      "Accuracy: 0.6043999195098877\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss: 0.7447217702865601\n",
      "Accuracy: 0.6059999465942383\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss: 0.8769176602363586\n",
      "Accuracy: 0.6031998991966248\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss: 0.7672421932220459\n",
      "Accuracy: 0.6005999445915222\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss: 0.831133246421814\n",
      "Accuracy: 0.6047998666763306\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss: 0.7653717994689941\n",
      "Accuracy: 0.6053999066352844\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss: 0.7787066102027893\n",
      "Accuracy: 0.610599935054779\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss: 0.9156436324119568\n",
      "Accuracy: 0.595599889755249\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss: 0.7615764141082764\n",
      "Accuracy: 0.6085999011993408\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss: 0.8404204249382019\n",
      "Accuracy: 0.6111999154090881\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss: 0.7742736339569092\n",
      "Accuracy: 0.6001999378204346\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss: 0.7613433003425598\n",
      "Accuracy: 0.6159998774528503\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss: 0.8728915452957153\n",
      "Accuracy: 0.606799840927124\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss: 0.776256263256073\n",
      "Accuracy: 0.606999933719635\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss: 0.8571184873580933\n",
      "Accuracy: 0.608799934387207\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss: 0.7500746846199036\n",
      "Accuracy: 0.6083999276161194\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss: 0.7454832792282104\n",
      "Accuracy: 0.6129998564720154\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss: 0.9473726749420166\n",
      "Accuracy: 0.605199933052063\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss: 0.7525901794433594\n",
      "Accuracy: 0.6063999533653259\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss: 0.8267773389816284\n",
      "Accuracy: 0.6135998368263245\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss: 0.7495278716087341\n",
      "Accuracy: 0.6083998680114746\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss: 0.8044339418411255\n",
      "Accuracy: 0.6159998178482056\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss: 0.9500261545181274\n",
      "Accuracy: 0.6055999398231506\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss: 0.7952747344970703\n",
      "Accuracy: 0.6065999269485474\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss: 0.8426003456115723\n",
      "Accuracy: 0.613399863243103\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss: 0.7510497570037842\n",
      "Accuracy: 0.6101999282836914\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss: 0.8177411556243896\n",
      "Accuracy: 0.6035999059677124\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss: 0.9113630056381226\n",
      "Accuracy: 0.5919999480247498\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss: 0.790087103843689\n",
      "Accuracy: 0.6131998300552368\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss: 0.8049028515815735\n",
      "Accuracy: 0.610599935054779\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss: 0.7734799385070801\n",
      "Accuracy: 0.6057999134063721\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss: 0.7602993249893188\n",
      "Accuracy: 0.6143999099731445\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss: 0.936277449131012\n",
      "Accuracy: 0.6055998802185059\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss: 0.7658356428146362\n",
      "Accuracy: 0.6053998470306396\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss: 0.763805091381073\n",
      "Accuracy: 0.6089999079704285\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss: 0.7589144110679626\n",
      "Accuracy: 0.6081998944282532\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss: 0.8194272518157959\n",
      "Accuracy: 0.6133999228477478\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss: 0.9375327229499817\n",
      "Accuracy: 0.5897999405860901\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss: 0.7612329125404358\n",
      "Accuracy: 0.6123999357223511\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss: 0.8015978336334229\n",
      "Accuracy: 0.6115999221801758\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss: 0.7650517821311951\n",
      "Accuracy: 0.6075998544692993\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss: 0.7754019498825073\n",
      "Accuracy: 0.6117998957633972\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss: 0.8942544460296631\n",
      "Accuracy: 0.5901999473571777\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss: 0.7971137762069702\n",
      "Accuracy: 0.6019998788833618\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss: 0.7960155606269836\n",
      "Accuracy: 0.6153998970985413\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss: 0.7332912683486938\n",
      "Accuracy: 0.6147999167442322\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss: 0.7435175180435181\n",
      "Accuracy: 0.6123999357223511\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss: 0.9659716486930847\n",
      "Accuracy: 0.5989999175071716\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss: 0.7279039025306702\n",
      "Accuracy: 0.6141999363899231\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss: 0.8635314702987671\n",
      "Accuracy: 0.610599935054779\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss: 0.732703685760498\n",
      "Accuracy: 0.6143999099731445\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss: 0.7833696603775024\n",
      "Accuracy: 0.6133999228477478\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss: 1.007249116897583\n",
      "Accuracy: 0.6073999404907227\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss: 0.7629595398902893\n",
      "Accuracy: 0.6005999445915222\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss: 0.8315658569335938\n",
      "Accuracy: 0.6217998266220093\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss: 0.7341065406799316\n",
      "Accuracy: 0.6091998815536499\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss: 0.8207378387451172\n",
      "Accuracy: 0.6075998544692993\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss: 0.933415412902832\n",
      "Accuracy: 0.6033998727798462\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss: 0.7845366597175598\n",
      "Accuracy: 0.610599935054779\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss: 0.7894726991653442\n",
      "Accuracy: 0.6139999032020569\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss: 0.7426919937133789\n",
      "Accuracy: 0.608799934387207\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss: 0.7748454213142395\n",
      "Accuracy: 0.622999906539917\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss: 0.9150357246398926\n",
      "Accuracy: 0.6027998924255371\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss: 0.7532867193222046\n",
      "Accuracy: 0.6129999160766602\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss: 0.8109025359153748\n",
      "Accuracy: 0.6125999689102173\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss: 0.7933752536773682\n",
      "Accuracy: 0.6027999520301819\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss: 0.8030012249946594\n",
      "Accuracy: 0.6097999215126038\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss: 0.9853143692016602\n",
      "Accuracy: 0.5963999032974243\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss: 0.7481884360313416\n",
      "Accuracy: 0.6107998490333557\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss: 0.803799033164978\n",
      "Accuracy: 0.615399956703186\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss: 0.7454248666763306\n",
      "Accuracy: 0.6113998889923096\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss: 0.7875130772590637\n",
      "Accuracy: 0.6107999086380005\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss: 0.9338711500167847\n",
      "Accuracy: 0.6045998930931091\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss: 0.7348259687423706\n",
      "Accuracy: 0.6155999302864075\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss: 0.8323936462402344\n",
      "Accuracy: 0.6183999180793762\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss: 0.7261526584625244\n",
      "Accuracy: 0.6091998815536499\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss: 0.7699389457702637\n",
      "Accuracy: 0.6143999099731445\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss: 0.9405001997947693\n",
      "Accuracy: 0.5969998836517334\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss: 0.7452372908592224\n",
      "Accuracy: 0.6195999383926392\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss: 0.8122779130935669\n",
      "Accuracy: 0.6187998652458191\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss: 0.7161832451820374\n",
      "Accuracy: 0.608199954032898\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss: 0.7646357417106628\n",
      "Accuracy: 0.6187999248504639\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss: 0.9127552509307861\n",
      "Accuracy: 0.5855998992919922\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss: 0.7474312782287598\n",
      "Accuracy: 0.6171998977661133\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss: 0.7830655574798584\n",
      "Accuracy: 0.613599956035614\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss: 0.7171772718429565\n",
      "Accuracy: 0.6027998924255371\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss: 0.7631950378417969\n",
      "Accuracy: 0.6177998781204224\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss: 0.9177243709564209\n",
      "Accuracy: 0.595599889755249\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss: 0.7426004409790039\n",
      "Accuracy: 0.6137999296188354\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss: 0.7789445519447327\n",
      "Accuracy: 0.6059998869895935\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss: 0.7101897597312927\n",
      "Accuracy: 0.610599935054779\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss: 0.7768908143043518\n",
      "Accuracy: 0.6261999607086182\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss: 0.9124817252159119\n",
      "Accuracy: 0.6011999249458313\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss: 0.7437475919723511\n",
      "Accuracy: 0.6187999248504639\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss: 0.7859135270118713\n",
      "Accuracy: 0.615399956703186\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss: 0.7663515210151672\n",
      "Accuracy: 0.6127999424934387\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss: 0.7692624926567078\n",
      "Accuracy: 0.6221999526023865\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss: 0.9294962286949158\n",
      "Accuracy: 0.6077998876571655\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss: 0.7388680577278137\n",
      "Accuracy: 0.619399905204773\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss: 0.7862938642501831\n",
      "Accuracy: 0.6165999174118042\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss: 0.7451506853103638\n",
      "Accuracy: 0.6131999492645264\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss: 0.7756248116493225\n",
      "Accuracy: 0.6209999322891235\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss: 0.9727722406387329\n",
      "Accuracy: 0.6151999235153198\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss: 0.7285146713256836\n",
      "Accuracy: 0.621199905872345\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss: 0.8124056458473206\n",
      "Accuracy: 0.6041998863220215\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss: 0.7228529453277588\n",
      "Accuracy: 0.6207998991012573\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss: 0.749933123588562\n",
      "Accuracy: 0.6205998659133911\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss: 0.9425389766693115\n",
      "Accuracy: 0.6169998645782471\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss: 0.7969439029693604\n",
      "Accuracy: 0.6145999431610107\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss: 0.8208674192428589\n",
      "Accuracy: 0.6141998767852783\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss: 0.7207098007202148\n",
      "Accuracy: 0.6213998794555664\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss: 0.7427759170532227\n",
      "Accuracy: 0.6175998449325562\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss: 0.9806515574455261\n",
      "Accuracy: 0.6185999512672424\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss: 0.7487556338310242\n",
      "Accuracy: 0.6145999431610107\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss: 0.874090850353241\n",
      "Accuracy: 0.6165999174118042\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss: 0.7337671518325806\n",
      "Accuracy: 0.6127999424934387\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss: 0.7729768753051758\n",
      "Accuracy: 0.6155999302864075\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss: 0.9258064031600952\n",
      "Accuracy: 0.6055998802185059\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss: 0.7358349561691284\n",
      "Accuracy: 0.6173999309539795\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss: 0.8133867979049683\n",
      "Accuracy: 0.6085999011993408\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss: 0.73775315284729\n",
      "Accuracy: 0.6077998876571655\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss: 0.7774708271026611\n",
      "Accuracy: 0.6143999099731445\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss: 0.9492236375808716\n",
      "Accuracy: 0.6011999249458313\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss: 0.7322555184364319\n",
      "Accuracy: 0.6155999302864075\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss: 0.7994519472122192\n",
      "Accuracy: 0.6111999154090881\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss: 0.7142300009727478\n",
      "Accuracy: 0.6137999296188354\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss: 0.7996147871017456\n",
      "Accuracy: 0.615399956703186\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss: 0.9143160581588745\n",
      "Accuracy: 0.6071999073028564\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss: 0.7512170672416687\n",
      "Accuracy: 0.6177998781204224\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss: 0.8029447793960571\n",
      "Accuracy: 0.619399905204773\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss: 0.7164236307144165\n",
      "Accuracy: 0.6149998903274536\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss: 0.7801228761672974\n",
      "Accuracy: 0.6153998970985413\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss: 0.8987594842910767\n",
      "Accuracy: 0.6097999215126038\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss: 0.7780177593231201\n",
      "Accuracy: 0.609799861907959\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss: 0.8693419694900513\n",
      "Accuracy: 0.6029999256134033\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss: 0.7233796119689941\n",
      "Accuracy: 0.6105998754501343\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss: 0.7838159799575806\n",
      "Accuracy: 0.6209999322891235\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss: 0.9261764287948608\n",
      "Accuracy: 0.6049998998641968\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss: 0.7427904605865479\n",
      "Accuracy: 0.6177999377250671\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss: 0.7776614427566528\n",
      "Accuracy: 0.6195998787879944\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss: 0.7426892518997192\n",
      "Accuracy: 0.6057999134063721\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss: 0.7610202431678772\n",
      "Accuracy: 0.61819988489151\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss: 0.9167025089263916\n",
      "Accuracy: 0.6079999208450317\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss: 0.7254274487495422\n",
      "Accuracy: 0.6149998903274536\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss: 0.7726974487304688\n",
      "Accuracy: 0.6171998977661133\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss: 0.7421338558197021\n",
      "Accuracy: 0.6095998883247375\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss: 0.8183684349060059\n",
      "Accuracy: 0.6073999404907227\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss: 0.8799578547477722\n",
      "Accuracy: 0.6053999066352844\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss: 0.7367534041404724\n",
      "Accuracy: 0.6231999397277832\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss: 0.8095777630805969\n",
      "Accuracy: 0.6139999032020569\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss: 0.7095059156417847\n",
      "Accuracy: 0.6179999113082886\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss: 0.767144501209259\n",
      "Accuracy: 0.619399905204773\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss: 0.9314994812011719\n",
      "Accuracy: 0.6005998849868774\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss: 0.7714053392410278\n",
      "Accuracy: 0.6195998787879944\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss: 0.7862531542778015\n",
      "Accuracy: 0.6137998700141907\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss: 0.7183345556259155\n",
      "Accuracy: 0.608199954032898\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss: 0.8012160062789917\n",
      "Accuracy: 0.6197998523712158\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss: 0.9268728494644165\n",
      "Accuracy: 0.5977998971939087\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss: 0.7423250079154968\n",
      "Accuracy: 0.6175998449325562\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss: 0.7970432639122009\n",
      "Accuracy: 0.6173999309539795\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss: 0.7351557016372681\n",
      "Accuracy: 0.6147999167442322\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss: 0.7820278406143188\n",
      "Accuracy: 0.6183998584747314\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss: 0.920647144317627\n",
      "Accuracy: 0.5993999242782593\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss: 0.7442965507507324\n",
      "Accuracy: 0.6255999207496643\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss: 0.7451618909835815\n",
      "Accuracy: 0.61819988489151\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss: 0.689789354801178\n",
      "Accuracy: 0.6143999099731445\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss: 0.7579892873764038\n",
      "Accuracy: 0.6187999248504639\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss: 0.9247933626174927\n",
      "Accuracy: 0.6127999424934387\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss: 0.7452355623245239\n",
      "Accuracy: 0.621199905872345\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss: 0.8029797077178955\n",
      "Accuracy: 0.6191998720169067\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss: 0.7059118747711182\n",
      "Accuracy: 0.6019998788833618\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss: 0.7962648868560791\n",
      "Accuracy: 0.6231998801231384\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss: 0.9112746715545654\n",
      "Accuracy: 0.6045998930931091\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss: 0.7389186024665833\n",
      "Accuracy: 0.6217999458312988\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss: 0.7623295187950134\n",
      "Accuracy: 0.612799882888794\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss: 0.6956567764282227\n",
      "Accuracy: 0.6139999032020569\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss: 0.771694540977478\n",
      "Accuracy: 0.6237999200820923\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss: 0.8984383344650269\n",
      "Accuracy: 0.5951999425888062\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss: 0.7987467050552368\n",
      "Accuracy: 0.6099998950958252\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss: 0.7682485580444336\n",
      "Accuracy: 0.6187999248504639\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss: 0.6911175847053528\n",
      "Accuracy: 0.6183998584747314\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss: 0.7849383354187012\n",
      "Accuracy: 0.6149998903274536\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss: 0.8485215306282043\n",
      "Accuracy: 0.6041998863220215\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss: 0.7358774542808533\n",
      "Accuracy: 0.6175999045372009\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss: 0.7593886852264404\n",
      "Accuracy: 0.6131998896598816\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss: 0.7106513977050781\n",
      "Accuracy: 0.6209999322891235\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss: 0.764626145362854\n",
      "Accuracy: 0.6169998645782471\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss: 0.9228413105010986\n",
      "Accuracy: 0.6127999424934387\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss: 0.7355420589447021\n",
      "Accuracy: 0.6213999390602112\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss: 0.7700216770172119\n",
      "Accuracy: 0.6197998523712158\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss: 0.7385327816009521\n",
      "Accuracy: 0.6177999377250671\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss: 0.7480567693710327\n",
      "Accuracy: 0.6183998584747314\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss: 0.9371327757835388\n",
      "Accuracy: 0.6077998876571655\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss: 0.7581325173377991\n",
      "Accuracy: 0.6159998774528503\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss: 0.758773922920227\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss: 0.717818021774292\n",
      "Accuracy: 0.6083998680114746\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss: 0.7566351890563965\n",
      "Accuracy: 0.6157999038696289\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss: 0.8873144388198853\n",
      "Accuracy: 0.6051998734474182\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss: 0.716830849647522\n",
      "Accuracy: 0.6255999803543091\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss: 0.741806149482727\n",
      "Accuracy: 0.6179998517036438\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss: 0.7034555673599243\n",
      "Accuracy: 0.6215999126434326\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss: 0.7641510963439941\n",
      "Accuracy: 0.6213999390602112\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss: 0.9448540806770325\n",
      "Accuracy: 0.5943999290466309\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss: 0.735846996307373\n",
      "Accuracy: 0.6241998672485352\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss: 0.7751437425613403\n",
      "Accuracy: 0.6173998713493347\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss: 0.7144383192062378\n",
      "Accuracy: 0.6205999255180359\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss: 0.7943899035453796\n",
      "Accuracy: 0.6175999045372009\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss: 0.9035726189613342\n",
      "Accuracy: 0.6035999059677124\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss: 0.7555509209632874\n",
      "Accuracy: 0.6167999505996704\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss: 0.7867046594619751\n",
      "Accuracy: 0.6219998598098755\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss: 0.7116366624832153\n",
      "Accuracy: 0.6149999499320984\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss: 0.7543060779571533\n",
      "Accuracy: 0.6251999139785767\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss: 0.9363994598388672\n",
      "Accuracy: 0.5999999642372131\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss: 0.7134986519813538\n",
      "Accuracy: 0.622999906539917\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss: 0.7816674709320068\n",
      "Accuracy: 0.6225998997688293\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss: 0.7366306781768799\n",
      "Accuracy: 0.6091998815536499\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss: 0.7761858701705933\n",
      "Accuracy: 0.6221999526023865\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss: 0.9202739000320435\n",
      "Accuracy: 0.6091998815536499\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss: 0.7488307952880859\n",
      "Accuracy: 0.6185998916625977\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss: 0.7560741901397705\n",
      "Accuracy: 0.6171998977661133\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss: 0.7002606391906738\n",
      "Accuracy: 0.6093998551368713\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss: 0.7917253971099854\n",
      "Accuracy: 0.6169999241828918\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss: 0.9219140410423279\n",
      "Accuracy: 0.6157999038696289\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss: 0.7327449321746826\n",
      "Accuracy: 0.6175999045372009\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss: 0.7828709483146667\n",
      "Accuracy: 0.6241999268531799\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss: 0.737102746963501\n",
      "Accuracy: 0.6203998327255249\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss: 0.7603338956832886\n",
      "Accuracy: 0.620199978351593\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss: 0.9353613257408142\n",
      "Accuracy: 0.6165999174118042\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss: 0.7565528750419617\n",
      "Accuracy: 0.6165999174118042\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss: 0.7837626934051514\n",
      "Accuracy: 0.6217999458312988\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss: 0.712450385093689\n",
      "Accuracy: 0.6131999492645264\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss: 0.7556687593460083\n",
      "Accuracy: 0.627599835395813\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss: 0.9263639450073242\n",
      "Accuracy: 0.6081998348236084\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss: 0.7592716217041016\n",
      "Accuracy: 0.6185998916625977\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss: 0.796357274055481\n",
      "Accuracy: 0.6203998923301697\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss: 0.6927411556243896\n",
      "Accuracy: 0.6201998591423035\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss: 0.7410851716995239\n",
      "Accuracy: 0.627799928188324\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss: 0.899002194404602\n",
      "Accuracy: 0.602199912071228\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss: 0.7503534555435181\n",
      "Accuracy: 0.6225998997688293\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss: 0.7747111320495605\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss: 0.7066261172294617\n",
      "Accuracy: 0.6189998984336853\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss: 0.7541931867599487\n",
      "Accuracy: 0.6285998821258545\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss: 0.9004621505737305\n",
      "Accuracy: 0.6149999499320984\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss: 0.7478557229042053\n",
      "Accuracy: 0.6169999241828918\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss: 0.7895106077194214\n",
      "Accuracy: 0.6247998476028442\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss: 0.7052234411239624\n",
      "Accuracy: 0.616399884223938\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss: 0.730004608631134\n",
      "Accuracy: 0.6231998801231384\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss: 0.9059166312217712\n",
      "Accuracy: 0.6061999201774597\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss: 0.7303177714347839\n",
      "Accuracy: 0.622999906539917\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss: 0.7992998361587524\n",
      "Accuracy: 0.6203998923301697\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss: 0.6970167756080627\n",
      "Accuracy: 0.6109998822212219\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss: 0.7844412326812744\n",
      "Accuracy: 0.6181999444961548\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss: 0.9349477291107178\n",
      "Accuracy: 0.6161998510360718\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss: 0.751807451248169\n",
      "Accuracy: 0.6233998537063599\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss: 0.7532338500022888\n",
      "Accuracy: 0.6219998598098755\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss: 0.6807893514633179\n",
      "Accuracy: 0.6213999390602112\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss: 0.7560136318206787\n",
      "Accuracy: 0.6175998449325562\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss: 0.921007513999939\n",
      "Accuracy: 0.6047998666763306\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss: 0.7442281246185303\n",
      "Accuracy: 0.6219998598098755\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss: 0.8199461102485657\n",
      "Accuracy: 0.616399884223938\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss: 0.710675835609436\n",
      "Accuracy: 0.6177998781204224\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss: 0.7756765484809875\n",
      "Accuracy: 0.6273999214172363\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss: 0.9363306760787964\n",
      "Accuracy: 0.6041999459266663\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss: 0.7273932695388794\n",
      "Accuracy: 0.621799886226654\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss: 0.81475430727005\n",
      "Accuracy: 0.6203998923301697\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss: 0.7003264427185059\n",
      "Accuracy: 0.6119998693466187\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss: 0.745512843132019\n",
      "Accuracy: 0.6289998888969421\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss: 0.9279387593269348\n",
      "Accuracy: 0.6145999431610107\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss: 0.8056082725524902\n",
      "Accuracy: 0.60999995470047\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss: 0.7724916934967041\n",
      "Accuracy: 0.6227999329566956\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss: 0.7011995911598206\n",
      "Accuracy: 0.6037999391555786\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss: 0.7214820981025696\n",
      "Accuracy: 0.6291998624801636\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss: 0.8915109634399414\n",
      "Accuracy: 0.6103999018669128\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss: 0.7483783960342407\n",
      "Accuracy: 0.6217999458312988\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss: 0.7903531193733215\n",
      "Accuracy: 0.621199905872345\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss: 0.6950027942657471\n",
      "Accuracy: 0.6179998517036438\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss: 0.7502404451370239\n",
      "Accuracy: 0.6195998787879944\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss: 0.9215190410614014\n",
      "Accuracy: 0.6165999174118042\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss: 0.7452974915504456\n",
      "Accuracy: 0.6223999261856079\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss: 0.7584132552146912\n",
      "Accuracy: 0.6253998279571533\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss: 0.7093533277511597\n",
      "Accuracy: 0.6127999424934387\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss: 0.761961042881012\n",
      "Accuracy: 0.6203999519348145\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss: 0.8735442757606506\n",
      "Accuracy: 0.6107999086380005\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss: 0.7115540504455566\n",
      "Accuracy: 0.6247999668121338\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss: 0.7741276025772095\n",
      "Accuracy: 0.6215999126434326\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss: 0.6856712102890015\n",
      "Accuracy: 0.6173999309539795\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss: 0.708100438117981\n",
      "Accuracy: 0.6173999309539795\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss: 0.8878006935119629\n",
      "Accuracy: 0.6103999018669128\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss: 0.7338109016418457\n",
      "Accuracy: 0.6233999133110046\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss: 0.8130455017089844\n",
      "Accuracy: 0.6249998807907104\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss: 0.6947416663169861\n",
      "Accuracy: 0.616399884223938\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss: 0.7520089149475098\n",
      "Accuracy: 0.6187999248504639\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss: 0.8754416704177856\n",
      "Accuracy: 0.5987999439239502\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss: 0.7371319532394409\n",
      "Accuracy: 0.6233999729156494\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss: 0.8226948380470276\n",
      "Accuracy: 0.6119999289512634\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss: 0.6900372505187988\n",
      "Accuracy: 0.608199954032898\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss: 0.7279350757598877\n",
      "Accuracy: 0.6241999268531799\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss: 0.8551241755485535\n",
      "Accuracy: 0.6055998802185059\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss: 0.7177777290344238\n",
      "Accuracy: 0.6257998943328857\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss: 0.7766985893249512\n",
      "Accuracy: 0.6273998618125916\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss: 0.6778724193572998\n",
      "Accuracy: 0.6131999492645264\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss: 0.7830621004104614\n",
      "Accuracy: 0.6189998984336853\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss: 0.9373646378517151\n",
      "Accuracy: 0.5989999175071716\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss: 0.780790388584137\n",
      "Accuracy: 0.6105998754501343\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss: 0.7820881605148315\n",
      "Accuracy: 0.6221998929977417\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss: 0.6570111513137817\n",
      "Accuracy: 0.6137999296188354\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss: 0.7324327230453491\n",
      "Accuracy: 0.6197999119758606\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss: 0.8714566230773926\n",
      "Accuracy: 0.6109998822212219\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss: 0.7828226685523987\n",
      "Accuracy: 0.6243999004364014\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss: 0.7601665258407593\n",
      "Accuracy: 0.625999927520752\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss: 0.7015392780303955\n",
      "Accuracy: 0.6235998868942261\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss: 0.7309433221817017\n",
      "Accuracy: 0.6237998604774475\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss: 0.8981784582138062\n",
      "Accuracy: 0.6097999215126038\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss: 0.7299631237983704\n",
      "Accuracy: 0.6237999200820923\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss: 0.7844583988189697\n",
      "Accuracy: 0.6209999322891235\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss: 0.660609245300293\n",
      "Accuracy: 0.6201999187469482\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss: 0.7304505109786987\n",
      "Accuracy: 0.6273998618125916\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss: 0.8908560872077942\n",
      "Accuracy: 0.619399905204773\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss: 0.7652649879455566\n",
      "Accuracy: 0.6267998814582825\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss: 0.7494618892669678\n",
      "Accuracy: 0.627799928188324\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss: 0.7211729288101196\n",
      "Accuracy: 0.6053999066352844\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss: 0.7232168912887573\n",
      "Accuracy: 0.6209999322891235\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss: 0.9449498653411865\n",
      "Accuracy: 0.6161999106407166\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss: 0.7343286871910095\n",
      "Accuracy: 0.6191998720169067\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss: 0.7596142292022705\n",
      "Accuracy: 0.6177999377250671\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss: 0.6835448741912842\n",
      "Accuracy: 0.6207998991012573\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss: 0.7609926462173462\n",
      "Accuracy: 0.6263999342918396\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss: 0.9304683208465576\n",
      "Accuracy: 0.6091998815536499\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss: 0.7949185371398926\n",
      "Accuracy: 0.6095998883247375\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss: 0.7698483467102051\n",
      "Accuracy: 0.6309998631477356\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss: 0.6660271286964417\n",
      "Accuracy: 0.6219999194145203\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss: 0.7090715169906616\n",
      "Accuracy: 0.6225999593734741\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss: 0.9213241338729858\n",
      "Accuracy: 0.606999933719635\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss: 0.7637649774551392\n",
      "Accuracy: 0.6269999146461487\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss: 0.7617664337158203\n",
      "Accuracy: 0.609799861907959\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss: 0.709373414516449\n",
      "Accuracy: 0.6171998977661133\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss: 0.7871733903884888\n",
      "Accuracy: 0.6225998997688293\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss: 0.8909940123558044\n",
      "Accuracy: 0.6107999086380005\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss: 0.7652326822280884\n",
      "Accuracy: 0.6255998611450195\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss: 0.739264726638794\n",
      "Accuracy: 0.6233999133110046\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss: 0.6694071292877197\n",
      "Accuracy: 0.6231999397277832\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss: 0.7415130734443665\n",
      "Accuracy: 0.6237999200820923\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss: 0.8674207925796509\n",
      "Accuracy: 0.621199905872345\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss: 0.7669776678085327\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss: 0.7967591881752014\n",
      "Accuracy: 0.6207998991012573\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss: 0.6634573936462402\n",
      "Accuracy: 0.6167998909950256\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss: 0.7547672986984253\n",
      "Accuracy: 0.6215999126434326\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss: 0.8281731605529785\n",
      "Accuracy: 0.6103999018669128\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss: 0.748630166053772\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss: 0.7220162153244019\n",
      "Accuracy: 0.6215999126434326\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss: 0.6885043382644653\n",
      "Accuracy: 0.6195999383926392\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss: 0.7296254634857178\n",
      "Accuracy: 0.6223998665809631\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss: 0.8696653842926025\n",
      "Accuracy: 0.6119999289512634\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss: 0.75911945104599\n",
      "Accuracy: 0.6255998611450195\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss: 0.7473941445350647\n",
      "Accuracy: 0.6215998530387878\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss: 0.690744161605835\n",
      "Accuracy: 0.6201999187469482\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss: 0.7127489447593689\n",
      "Accuracy: 0.6207998991012573\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss: 0.9005987644195557\n",
      "Accuracy: 0.6159998774528503\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss: 0.7982008457183838\n",
      "Accuracy: 0.6127999424934387\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss: 0.7498967051506042\n",
      "Accuracy: 0.6291999220848083\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss: 0.6879356503486633\n",
      "Accuracy: 0.614599883556366\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss: 0.7326258420944214\n",
      "Accuracy: 0.6301999092102051\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss: 0.8542554974555969\n",
      "Accuracy: 0.6113999485969543\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss: 0.761517345905304\n",
      "Accuracy: 0.619399905204773\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss: 0.7424356341362\n",
      "Accuracy: 0.6203998923301697\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss: 0.6803371906280518\n",
      "Accuracy: 0.6189999580383301\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss: 0.6983492970466614\n",
      "Accuracy: 0.6221998929977417\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss: 0.8690718412399292\n",
      "Accuracy: 0.6139999628067017\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss: 0.7566460967063904\n",
      "Accuracy: 0.6273998618125916\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss: 0.734383761882782\n",
      "Accuracy: 0.6177998781204224\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss: 0.6734428405761719\n",
      "Accuracy: 0.6197998523712158\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss: 0.7002530097961426\n",
      "Accuracy: 0.6281999349594116\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss: 0.8997104167938232\n",
      "Accuracy: 0.6205999255180359\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss: 0.7353782653808594\n",
      "Accuracy: 0.6317999362945557\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss: 0.7411139011383057\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss: 0.6869809627532959\n",
      "Accuracy: 0.6175999045372009\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss: 0.7251942157745361\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss: 0.8960594534873962\n",
      "Accuracy: 0.6117998957633972\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss: 0.7640860080718994\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss: 0.7082352042198181\n",
      "Accuracy: 0.6281998753547668\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss: 0.6933908462524414\n",
      "Accuracy: 0.6291999220848083\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss: 0.7740362882614136\n",
      "Accuracy: 0.6203999519348145\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss: 0.8748663663864136\n",
      "Accuracy: 0.6179999709129333\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss: 0.7574056386947632\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss: 0.749229907989502\n",
      "Accuracy: 0.6241998672485352\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss: 0.6850989460945129\n",
      "Accuracy: 0.6237999200820923\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss: 0.7488176822662354\n",
      "Accuracy: 0.621799886226654\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss: 0.8670659065246582\n",
      "Accuracy: 0.612799882888794\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss: 0.7217072248458862\n",
      "Accuracy: 0.6273999214172363\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss: 0.7170687317848206\n",
      "Accuracy: 0.6303998827934265\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss: 0.683911144733429\n",
      "Accuracy: 0.6275999546051025\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss: 0.7232414484024048\n",
      "Accuracy: 0.6283999085426331\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss: 0.8381950259208679\n",
      "Accuracy: 0.6131998896598816\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss: 0.7533100843429565\n",
      "Accuracy: 0.627799928188324\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss: 0.714025616645813\n",
      "Accuracy: 0.6225998997688293\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss: 0.6734027862548828\n",
      "Accuracy: 0.6171998977661133\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss: 0.7098053097724915\n",
      "Accuracy: 0.6267999410629272\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss: 0.8842017650604248\n",
      "Accuracy: 0.6223998665809631\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss: 0.7421127557754517\n",
      "Accuracy: 0.619399905204773\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss: 0.7542935609817505\n",
      "Accuracy: 0.6269999146461487\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss: 0.6799017190933228\n",
      "Accuracy: 0.6207998991012573\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss: 0.7193863987922668\n",
      "Accuracy: 0.6237998604774475\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss: 0.8679021000862122\n",
      "Accuracy: 0.6225998401641846\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss: 0.7317482233047485\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss: 0.7477365732192993\n",
      "Accuracy: 0.6275998950004578\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss: 0.6895806789398193\n",
      "Accuracy: 0.622999906539917\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss: 0.7326719760894775\n",
      "Accuracy: 0.6275998950004578\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss: 0.8800477981567383\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss: 0.7618560791015625\n",
      "Accuracy: 0.6255999207496643\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss: 0.779631495475769\n",
      "Accuracy: 0.6231999397277832\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss: 0.6628905534744263\n",
      "Accuracy: 0.6183999180793762\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss: 0.7224253416061401\n",
      "Accuracy: 0.6243999004364014\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss: 0.8539202213287354\n",
      "Accuracy: 0.6243998408317566\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss: 0.7331688404083252\n",
      "Accuracy: 0.6269999146461487\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss: 0.7305766344070435\n",
      "Accuracy: 0.6281998753547668\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss: 0.6527128219604492\n",
      "Accuracy: 0.621199905872345\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss: 0.7472729086875916\n",
      "Accuracy: 0.6261999011039734\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss: 0.9258354902267456\n",
      "Accuracy: 0.6179999709129333\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss: 0.7281056046485901\n",
      "Accuracy: 0.6305999159812927\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss: 0.7254898548126221\n",
      "Accuracy: 0.6303999423980713\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss: 0.6616518497467041\n",
      "Accuracy: 0.6107999086380005\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss: 0.7393724918365479\n",
      "Accuracy: 0.6295998692512512\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss: 0.8470487594604492\n",
      "Accuracy: 0.6195998191833496\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss: 0.7571846842765808\n",
      "Accuracy: 0.6297999024391174\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss: 0.7496400475502014\n",
      "Accuracy: 0.6249998807907104\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss: 0.6935932040214539\n",
      "Accuracy: 0.6253999471664429\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss: 0.7205737233161926\n",
      "Accuracy: 0.6309998631477356\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss: 0.8513001799583435\n",
      "Accuracy: 0.6297999024391174\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss: 0.7788861989974976\n",
      "Accuracy: 0.6275998950004578\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss: 0.7194705605506897\n",
      "Accuracy: 0.6279999017715454\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss: 0.6797512769699097\n",
      "Accuracy: 0.6237998604774475\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss: 0.7369240522384644\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss: 0.8635155558586121\n",
      "Accuracy: 0.6283998489379883\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss: 0.7328319549560547\n",
      "Accuracy: 0.6225998997688293\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss: 0.7510762810707092\n",
      "Accuracy: 0.6261999011039734\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss: 0.6976184844970703\n",
      "Accuracy: 0.6225999593734741\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss: 0.764876127243042\n",
      "Accuracy: 0.6235999464988708\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss: 0.899964451789856\n",
      "Accuracy: 0.6155999302864075\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss: 0.7411715984344482\n",
      "Accuracy: 0.6289998292922974\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss: 0.716206431388855\n",
      "Accuracy: 0.6317999362945557\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss: 0.7001651525497437\n",
      "Accuracy: 0.6167999505996704\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss: 0.7251589298248291\n",
      "Accuracy: 0.6291999816894531\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss: 0.860138475894928\n",
      "Accuracy: 0.6187999248504639\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss: 0.7392557859420776\n",
      "Accuracy: 0.6221999526023865\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss: 0.7043591141700745\n",
      "Accuracy: 0.6251999139785767\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss: 0.685616135597229\n",
      "Accuracy: 0.6245998740196228\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss: 0.7461001873016357\n",
      "Accuracy: 0.6221998929977417\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss: 0.9452523589134216\n",
      "Accuracy: 0.6145999431610107\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss: 0.7372947335243225\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss: 0.7321141362190247\n",
      "Accuracy: 0.6333998441696167\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss: 0.6690407395362854\n",
      "Accuracy: 0.6273999214172363\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss: 0.7087988257408142\n",
      "Accuracy: 0.6283999085426331\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss: 0.891373872756958\n",
      "Accuracy: 0.6139999628067017\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss: 0.7414683103561401\n",
      "Accuracy: 0.625999927520752\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss: 0.7323186993598938\n",
      "Accuracy: 0.6261999607086182\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss: 0.7069693803787231\n",
      "Accuracy: 0.6147999167442322\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss: 0.7225674986839294\n",
      "Accuracy: 0.6263998746871948\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss: 0.9068822860717773\n",
      "Accuracy: 0.6189998388290405\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss: 0.7566448450088501\n",
      "Accuracy: 0.6235998868942261\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss: 0.7246197462081909\n",
      "Accuracy: 0.6281999349594116\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss: 0.6993225812911987\n",
      "Accuracy: 0.625999927520752\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss: 0.7494339942932129\n",
      "Accuracy: 0.6237998604774475\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss: 0.8877812027931213\n",
      "Accuracy: 0.6071999669075012\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss: 0.747650146484375\n",
      "Accuracy: 0.6203998923301697\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss: 0.7206330895423889\n",
      "Accuracy: 0.619999885559082\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss: 0.7048133015632629\n",
      "Accuracy: 0.6157999038696289\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss: 0.7464708685874939\n",
      "Accuracy: 0.6261999011039734\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss: 0.8867223858833313\n",
      "Accuracy: 0.616399884223938\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss: 0.727455735206604\n",
      "Accuracy: 0.6299998760223389\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss: 0.7264994382858276\n",
      "Accuracy: 0.6289998888969421\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss: 0.6644015312194824\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss: 0.7002370357513428\n",
      "Accuracy: 0.6285998821258545\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss: 0.8709392547607422\n",
      "Accuracy: 0.6279999017715454\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss: 0.7466320991516113\n",
      "Accuracy: 0.6241999268531799\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss: 0.6909494400024414\n",
      "Accuracy: 0.6269998550415039\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss: 0.678577721118927\n",
      "Accuracy: 0.6225999593734741\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss: 0.7150223851203918\n",
      "Accuracy: 0.6297999024391174\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss: 0.8726542592048645\n",
      "Accuracy: 0.6135998964309692\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss: 0.7687917351722717\n",
      "Accuracy: 0.6277998685836792\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss: 0.7179436683654785\n",
      "Accuracy: 0.6321998834609985\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss: 0.6735411882400513\n",
      "Accuracy: 0.6349998712539673\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss: 0.7527074813842773\n",
      "Accuracy: 0.6339999437332153\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss: 0.8529087901115417\n",
      "Accuracy: 0.6253998875617981\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss: 0.7417743802070618\n",
      "Accuracy: 0.6323999166488647\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss: 0.7336548566818237\n",
      "Accuracy: 0.634399950504303\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss: 0.660284698009491\n",
      "Accuracy: 0.6233999729156494\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss: 0.7197917103767395\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss: 0.9010583162307739\n",
      "Accuracy: 0.6231999397277832\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss: 0.7350150346755981\n",
      "Accuracy: 0.6321999430656433\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss: 0.7053589224815369\n",
      "Accuracy: 0.6255999207496643\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss: 0.6493957042694092\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss: 0.755416214466095\n",
      "Accuracy: 0.6227998733520508\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss: 0.8556782007217407\n",
      "Accuracy: 0.6255999207496643\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss: 0.7442632913589478\n",
      "Accuracy: 0.629599928855896\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss: 0.6964787244796753\n",
      "Accuracy: 0.6347998976707458\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss: 0.6357675790786743\n",
      "Accuracy: 0.6279998421669006\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss: 0.7291196584701538\n",
      "Accuracy: 0.6293999552726746\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss: 0.8511459827423096\n",
      "Accuracy: 0.6199999451637268\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss: 0.7410504221916199\n",
      "Accuracy: 0.6335998773574829\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss: 0.7147128582000732\n",
      "Accuracy: 0.6231998801231384\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss: 0.6525355577468872\n",
      "Accuracy: 0.6279999017715454\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss: 0.7395726442337036\n",
      "Accuracy: 0.6357998847961426\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss: 0.8443307876586914\n",
      "Accuracy: 0.6159998774528503\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss: 0.7542515397071838\n",
      "Accuracy: 0.6269998550415039\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss: 0.7079819440841675\n",
      "Accuracy: 0.6239999532699585\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss: 0.656865656375885\n",
      "Accuracy: 0.6169998645782471\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss: 0.7290480732917786\n",
      "Accuracy: 0.6305999159812927\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss: 0.8044920563697815\n",
      "Accuracy: 0.6107999086380005\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss: 0.7560644149780273\n",
      "Accuracy: 0.6345998644828796\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss: 0.7398905754089355\n",
      "Accuracy: 0.6207998991012573\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss: 0.6432420611381531\n",
      "Accuracy: 0.6287999153137207\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss: 0.7344683408737183\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss: 0.8464474081993103\n",
      "Accuracy: 0.6185999512672424\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss: 0.7364019155502319\n",
      "Accuracy: 0.6331998109817505\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss: 0.6934731006622314\n",
      "Accuracy: 0.6299998760223389\n",
      "Epoch 258, CIFAR-10 Batch 5:  Loss: 0.6570255160331726\n",
      "Accuracy: 0.6273999214172363\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss: 0.7836768627166748\n",
      "Accuracy: 0.6189998984336853\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss: 0.8111327290534973\n",
      "Accuracy: 0.6175999045372009\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss: 0.7284150123596191\n",
      "Accuracy: 0.6275998950004578\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss: 0.7845342755317688\n",
      "Accuracy: 0.6321998834609985\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss: 0.6690786480903625\n",
      "Accuracy: 0.6241998672485352\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss: 0.7392607927322388\n",
      "Accuracy: 0.631399929523468\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss: 0.7982140183448792\n",
      "Accuracy: 0.6245999336242676\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss: 0.7464661002159119\n",
      "Accuracy: 0.6353998780250549\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss: 0.6959123015403748\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss: 0.6815075874328613\n",
      "Accuracy: 0.6243999004364014\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss: 0.7045235633850098\n",
      "Accuracy: 0.630599856376648\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss: 0.7932537198066711\n",
      "Accuracy: 0.6119998693466187\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss: 0.7211495637893677\n",
      "Accuracy: 0.6285999417304993\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss: 0.7002424001693726\n",
      "Accuracy: 0.625999927520752\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss: 0.636570394039154\n",
      "Accuracy: 0.622999906539917\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss: 0.7117190361022949\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss: 0.8171995878219604\n",
      "Accuracy: 0.6223999261856079\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss: 0.7568024396896362\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss: 0.708088755607605\n",
      "Accuracy: 0.632599949836731\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss: 0.6630715131759644\n",
      "Accuracy: 0.6265998482704163\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss: 0.7357679009437561\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss: 0.7851981520652771\n",
      "Accuracy: 0.6185999512672424\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss: 0.7840605974197388\n",
      "Accuracy: 0.6271998882293701\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss: 0.7227010726928711\n",
      "Accuracy: 0.6243999004364014\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss: 0.6793529391288757\n",
      "Accuracy: 0.6243999004364014\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss: 0.7180445790290833\n",
      "Accuracy: 0.6283999085426331\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss: 0.7922408580780029\n",
      "Accuracy: 0.6253999471664429\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss: 0.7372706532478333\n",
      "Accuracy: 0.6325998902320862\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss: 0.734183669090271\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss: 0.6614668965339661\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss: 0.766525149345398\n",
      "Accuracy: 0.6213998794555664\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss: 0.83542799949646\n",
      "Accuracy: 0.6219998598098755\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss: 0.7590279579162598\n",
      "Accuracy: 0.6283998489379883\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss: 0.7249321341514587\n",
      "Accuracy: 0.6355998516082764\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss: 0.6458178758621216\n",
      "Accuracy: 0.6285998821258545\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss: 0.7425400614738464\n",
      "Accuracy: 0.6269998550415039\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss: 0.8270521759986877\n",
      "Accuracy: 0.6261999011039734\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss: 0.7551625370979309\n",
      "Accuracy: 0.6359999775886536\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss: 0.7655043005943298\n",
      "Accuracy: 0.6315999031066895\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss: 0.6589746475219727\n",
      "Accuracy: 0.6303999423980713\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss: 0.7354781627655029\n",
      "Accuracy: 0.6287999153137207\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss: 0.8198801279067993\n",
      "Accuracy: 0.612799882888794\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss: 0.7599342465400696\n",
      "Accuracy: 0.6263998746871948\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss: 0.703241229057312\n",
      "Accuracy: 0.634199857711792\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss: 0.6072659492492676\n",
      "Accuracy: 0.6351999044418335\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss: 0.7271400690078735\n",
      "Accuracy: 0.6311998963356018\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss: 0.8845195770263672\n",
      "Accuracy: 0.6279999017715454\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss: 0.7379570007324219\n",
      "Accuracy: 0.63319993019104\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss: 0.711338460445404\n",
      "Accuracy: 0.6345999240875244\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss: 0.638719379901886\n",
      "Accuracy: 0.6307999491691589\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss: 0.7078346014022827\n",
      "Accuracy: 0.6329998970031738\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss: 0.8876231908798218\n",
      "Accuracy: 0.6179999113082886\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss: 0.765056848526001\n",
      "Accuracy: 0.6273998618125916\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss: 0.7167988419532776\n",
      "Accuracy: 0.6317999362945557\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss: 0.6526023149490356\n",
      "Accuracy: 0.6225998997688293\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss: 0.7191294431686401\n",
      "Accuracy: 0.6271998882293701\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss: 0.7823652029037476\n",
      "Accuracy: 0.6183998584747314\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss: 0.7375119924545288\n",
      "Accuracy: 0.6317998766899109\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss: 0.7568791508674622\n",
      "Accuracy: 0.6231999397277832\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss: 0.6370991468429565\n",
      "Accuracy: 0.6243999004364014\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss: 0.7354487180709839\n",
      "Accuracy: 0.6309999227523804\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss: 0.8221672773361206\n",
      "Accuracy: 0.6179998517036438\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss: 0.7697000503540039\n",
      "Accuracy: 0.63239985704422\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss: 0.7445752620697021\n",
      "Accuracy: 0.6363999247550964\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss: 0.6442385911941528\n",
      "Accuracy: 0.6207998991012573\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss: 0.7496161460876465\n",
      "Accuracy: 0.6283998489379883\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss: 0.8202964663505554\n",
      "Accuracy: 0.6243999004364014\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss: 0.7798852920532227\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss: 0.7148222327232361\n",
      "Accuracy: 0.625999927520752\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss: 0.6298942565917969\n",
      "Accuracy: 0.6151999235153198\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss: 0.7288211584091187\n",
      "Accuracy: 0.6311998963356018\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss: 0.8070166110992432\n",
      "Accuracy: 0.6151999235153198\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss: 0.7835610508918762\n",
      "Accuracy: 0.6339998245239258\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss: 0.7283751964569092\n",
      "Accuracy: 0.6315999031066895\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss: 0.6693594455718994\n",
      "Accuracy: 0.6167999505996704\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss: 0.7332394123077393\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss: 0.8073831796646118\n",
      "Accuracy: 0.6235998272895813\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss: 0.7519674301147461\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss: 0.7345545291900635\n",
      "Accuracy: 0.6367999315261841\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss: 0.6243522763252258\n",
      "Accuracy: 0.6327998638153076\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss: 0.6869605779647827\n",
      "Accuracy: 0.6305999755859375\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss: 0.8222529888153076\n",
      "Accuracy: 0.6249998807907104\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss: 0.7491455078125\n",
      "Accuracy: 0.6289999485015869\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss: 0.7656100988388062\n",
      "Accuracy: 0.6243999004364014\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss: 0.663699209690094\n",
      "Accuracy: 0.6243998408317566\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss: 0.6867552995681763\n",
      "Accuracy: 0.6275999546051025\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss: 0.8163008689880371\n",
      "Accuracy: 0.623999834060669\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss: 0.7752556800842285\n",
      "Accuracy: 0.6279999017715454\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss: 0.7302728891372681\n",
      "Accuracy: 0.6295998692512512\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss: 0.6475352048873901\n",
      "Accuracy: 0.6185998916625977\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss: 0.7455620169639587\n",
      "Accuracy: 0.6275998950004578\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss: 0.8796212673187256\n",
      "Accuracy: 0.625999927520752\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss: 0.7643808126449585\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss: 0.7135951519012451\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss: 0.6351895928382874\n",
      "Accuracy: 0.6237999200820923\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss: 0.7139244675636292\n",
      "Accuracy: 0.6321998834609985\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss: 0.8443506956100464\n",
      "Accuracy: 0.6275998950004578\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss: 0.7374025583267212\n",
      "Accuracy: 0.6321998834609985\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss: 0.7181293368339539\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss: 0.6424728035926819\n",
      "Accuracy: 0.6187999248504639\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss: 0.741441547870636\n",
      "Accuracy: 0.6277998685836792\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss: 0.8451521992683411\n",
      "Accuracy: 0.6175999045372009\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss: 0.7489168643951416\n",
      "Accuracy: 0.6335998773574829\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss: 0.7242728471755981\n",
      "Accuracy: 0.6383998990058899\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss: 0.6445732712745667\n",
      "Accuracy: 0.6307998895645142\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss: 0.7355342507362366\n",
      "Accuracy: 0.6349998712539673\n",
      "Epoch 280, CIFAR-10 Batch 2:  Loss: 0.8240054249763489\n",
      "Accuracy: 0.6221998929977417\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss: 0.7513712644577026\n",
      "Accuracy: 0.63239985704422\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss: 0.7059927582740784\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss: 0.6216816306114197\n",
      "Accuracy: 0.6309999227523804\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss: 0.7204315662384033\n",
      "Accuracy: 0.6327999234199524\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss: 0.8481186032295227\n",
      "Accuracy: 0.6233998537063599\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss: 0.7476944923400879\n",
      "Accuracy: 0.634199857711792\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss: 0.7018229365348816\n",
      "Accuracy: 0.6375999450683594\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss: 0.6252416372299194\n",
      "Accuracy: 0.6245998740196228\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss: 0.7244445085525513\n",
      "Accuracy: 0.6317998766899109\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss: 0.8127369284629822\n",
      "Accuracy: 0.6323999166488647\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss: 0.7741862535476685\n",
      "Accuracy: 0.6303998827934265\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss: 0.7085475325584412\n",
      "Accuracy: 0.6339999437332153\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss: 0.645672082901001\n",
      "Accuracy: 0.6209999322891235\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss: 0.7030482888221741\n",
      "Accuracy: 0.6223999261856079\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss: 0.8533015847206116\n",
      "Accuracy: 0.6141998767852783\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss: 0.7252624034881592\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss: 0.712713360786438\n",
      "Accuracy: 0.6327999234199524\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss: 0.6401036977767944\n",
      "Accuracy: 0.6249999403953552\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss: 0.7170709371566772\n",
      "Accuracy: 0.6289998888969421\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss: 0.8378371000289917\n",
      "Accuracy: 0.6175999045372009\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss: 0.7390642166137695\n",
      "Accuracy: 0.6347998380661011\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss: 0.7154393196105957\n",
      "Accuracy: 0.6381998658180237\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss: 0.6505232453346252\n",
      "Accuracy: 0.6267999410629272\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss: 0.7011617422103882\n",
      "Accuracy: 0.6315999031066895\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss: 0.8409959077835083\n",
      "Accuracy: 0.6109999418258667\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss: 0.7614032626152039\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss: 0.7207672595977783\n",
      "Accuracy: 0.6345998644828796\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss: 0.6737935543060303\n",
      "Accuracy: 0.6331998705863953\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss: 0.7057820558547974\n",
      "Accuracy: 0.63319993019104\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss: 0.8004253506660461\n",
      "Accuracy: 0.6197999119758606\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss: 0.7145093679428101\n",
      "Accuracy: 0.6329998970031738\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss: 0.7054633498191833\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss: 0.6475135684013367\n",
      "Accuracy: 0.6261999011039734\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss: 0.7193042039871216\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss: 0.80060875415802\n",
      "Accuracy: 0.6141998767852783\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss: 0.7188374996185303\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss: 0.7420802116394043\n",
      "Accuracy: 0.6299998760223389\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss: 0.6537806987762451\n",
      "Accuracy: 0.6233999133110046\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss: 0.7041987776756287\n",
      "Accuracy: 0.634199857711792\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss: 0.8154857754707336\n",
      "Accuracy: 0.6311998963356018\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss: 0.7484970092773438\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss: 0.7420682311058044\n",
      "Accuracy: 0.6379998922348022\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss: 0.663349449634552\n",
      "Accuracy: 0.6209999322891235\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss: 0.7115577459335327\n",
      "Accuracy: 0.6339999437332153\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss: 0.7951332330703735\n",
      "Accuracy: 0.6147999167442322\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss: 0.7364875674247742\n",
      "Accuracy: 0.6345998644828796\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss: 0.7038147449493408\n",
      "Accuracy: 0.6269999146461487\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss: 0.6315203309059143\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss: 0.7246968746185303\n",
      "Accuracy: 0.6339998841285706\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss: 0.803297221660614\n",
      "Accuracy: 0.6239998936653137\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss: 0.7188814282417297\n",
      "Accuracy: 0.6319999098777771\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss: 0.7012780904769897\n",
      "Accuracy: 0.6351999044418335\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss: 0.6492101550102234\n",
      "Accuracy: 0.6301999092102051\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss: 0.7063522338867188\n",
      "Accuracy: 0.6373998522758484\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss: 0.8428236842155457\n",
      "Accuracy: 0.6177998781204224\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss: 0.710358202457428\n",
      "Accuracy: 0.6395999193191528\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss: 0.7016937732696533\n",
      "Accuracy: 0.6301999092102051\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss: 0.6332565546035767\n",
      "Accuracy: 0.6261999607086182\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss: 0.746187686920166\n",
      "Accuracy: 0.6375998854637146\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss: 0.7954209446907043\n",
      "Accuracy: 0.6239998936653137\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss: 0.7227287292480469\n",
      "Accuracy: 0.6323999166488647\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss: 0.7108299732208252\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss: 0.6227155923843384\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss: 0.7442713975906372\n",
      "Accuracy: 0.6321998834609985\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss: 0.7929524183273315\n",
      "Accuracy: 0.6231999397277832\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss: 0.701494038105011\n",
      "Accuracy: 0.6347998976707458\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss: 0.6827476024627686\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss: 0.6288121938705444\n",
      "Accuracy: 0.6317999362945557\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss: 0.7223844528198242\n",
      "Accuracy: 0.6339999437332153\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss: 0.8522469997406006\n",
      "Accuracy: 0.6137998700141907\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss: 0.7458165884017944\n",
      "Accuracy: 0.6385999321937561\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss: 0.7119199633598328\n",
      "Accuracy: 0.6369999647140503\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss: 0.6341701149940491\n",
      "Accuracy: 0.621799886226654\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss: 0.7200215458869934\n",
      "Accuracy: 0.6351999044418335\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss: 0.7965555191040039\n",
      "Accuracy: 0.6245999336242676\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss: 0.7259057760238647\n",
      "Accuracy: 0.6351999044418335\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss: 0.6920900344848633\n",
      "Accuracy: 0.63319993019104\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss: 0.6441093683242798\n",
      "Accuracy: 0.625999927520752\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss: 0.726130485534668\n",
      "Accuracy: 0.6339998245239258\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss: 0.7978359460830688\n",
      "Accuracy: 0.6323999166488647\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss: 0.7200060486793518\n",
      "Accuracy: 0.6349999308586121\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss: 0.7077946662902832\n",
      "Accuracy: 0.6335998773574829\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss: 0.658467173576355\n",
      "Accuracy: 0.6295998692512512\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss: 0.7361735105514526\n",
      "Accuracy: 0.6315999031066895\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss: 0.7701061367988586\n",
      "Accuracy: 0.6221998929977417\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss: 0.7086613178253174\n",
      "Accuracy: 0.6367998123168945\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss: 0.6769293546676636\n",
      "Accuracy: 0.6373998522758484\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss: 0.6471517086029053\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss: 0.7231780886650085\n",
      "Accuracy: 0.6401998996734619\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss: 0.7772203087806702\n",
      "Accuracy: 0.6227998733520508\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss: 0.7368432283401489\n",
      "Accuracy: 0.6353999376296997\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss: 0.6861695647239685\n",
      "Accuracy: 0.6311998963356018\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss: 0.6679493188858032\n",
      "Accuracy: 0.6339998841285706\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss: 0.7209658622741699\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss: 0.8279002904891968\n",
      "Accuracy: 0.6259998679161072\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss: 0.7435321807861328\n",
      "Accuracy: 0.6353998780250549\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss: 0.691038191318512\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss: 0.6242276430130005\n",
      "Accuracy: 0.6349998712539673\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss: 0.7252453565597534\n",
      "Accuracy: 0.6379998922348022\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss: 0.7876567840576172\n",
      "Accuracy: 0.6239999532699585\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss: 0.7279700636863708\n",
      "Accuracy: 0.6343998908996582\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss: 0.700560450553894\n",
      "Accuracy: 0.6363999247550964\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss: 0.646354615688324\n",
      "Accuracy: 0.625999927520752\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss: 0.7086474299430847\n",
      "Accuracy: 0.635999858379364\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss: 0.8577983379364014\n",
      "Accuracy: 0.6281998753547668\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss: 0.7004607915878296\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 301, CIFAR-10 Batch 4:  Loss: 0.688035786151886\n",
      "Accuracy: 0.6321998834609985\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss: 0.6311314105987549\n",
      "Accuracy: 0.6317998766899109\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss: 0.7293765544891357\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss: 0.7449253797531128\n",
      "Accuracy: 0.6241998672485352\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss: 0.6980891227722168\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss: 0.6906333565711975\n",
      "Accuracy: 0.63319993019104\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss: 0.642597496509552\n",
      "Accuracy: 0.6273999214172363\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss: 0.7351498603820801\n",
      "Accuracy: 0.6351999044418335\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss: 0.7871312499046326\n",
      "Accuracy: 0.6301999092102051\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss: 0.7444192171096802\n",
      "Accuracy: 0.6327998638153076\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss: 0.7216449975967407\n",
      "Accuracy: 0.6363998651504517\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss: 0.6275207996368408\n",
      "Accuracy: 0.6283999085426331\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss: 0.7371070384979248\n",
      "Accuracy: 0.6261999011039734\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss: 0.7981323003768921\n",
      "Accuracy: 0.6283999681472778\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss: 0.7196131944656372\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss: 0.7007967829704285\n",
      "Accuracy: 0.6273998618125916\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss: 0.6359348893165588\n",
      "Accuracy: 0.6299998760223389\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss: 0.7888617515563965\n",
      "Accuracy: 0.6341999173164368\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss: 0.8181667327880859\n",
      "Accuracy: 0.619399905204773\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss: 0.7352043390274048\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss: 0.6632611751556396\n",
      "Accuracy: 0.6339998841285706\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss: 0.658478856086731\n",
      "Accuracy: 0.6307998895645142\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss: 0.7683053016662598\n",
      "Accuracy: 0.63319993019104\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss: 0.8319433331489563\n",
      "Accuracy: 0.6257998943328857\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss: 0.7220788598060608\n",
      "Accuracy: 0.6353999376296997\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss: 0.6875550150871277\n",
      "Accuracy: 0.631199836730957\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss: 0.6488924622535706\n",
      "Accuracy: 0.6321998834609985\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss: 0.7228102684020996\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss: 0.8001477122306824\n",
      "Accuracy: 0.6245999336242676\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss: 0.7107312679290771\n",
      "Accuracy: 0.629599928855896\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss: 0.7041523456573486\n",
      "Accuracy: 0.6329998970031738\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss: 0.6499801874160767\n",
      "Accuracy: 0.63319993019104\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss: 0.7394471168518066\n",
      "Accuracy: 0.6387998461723328\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss: 0.811655580997467\n",
      "Accuracy: 0.6233998537063599\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss: 0.734799861907959\n",
      "Accuracy: 0.6339998841285706\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss: 0.7001351714134216\n",
      "Accuracy: 0.6335998773574829\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss: 0.6427383422851562\n",
      "Accuracy: 0.6319998502731323\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss: 0.7677584290504456\n",
      "Accuracy: 0.6345999240875244\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss: 0.819095253944397\n",
      "Accuracy: 0.6179999113082886\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss: 0.7018674612045288\n",
      "Accuracy: 0.6353998780250549\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss: 0.7211494445800781\n",
      "Accuracy: 0.6291998624801636\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss: 0.6348117589950562\n",
      "Accuracy: 0.6301999092102051\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss: 0.754643440246582\n",
      "Accuracy: 0.6281999349594116\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss: 0.7903795838356018\n",
      "Accuracy: 0.6357999444007874\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss: 0.7373586297035217\n",
      "Accuracy: 0.6273998618125916\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss: 0.7109293341636658\n",
      "Accuracy: 0.6367998719215393\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss: 0.6408409476280212\n",
      "Accuracy: 0.6259998679161072\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss: 0.7404286861419678\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss: 0.8156499862670898\n",
      "Accuracy: 0.6231999397277832\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss: 0.7169036865234375\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss: 0.6999670267105103\n",
      "Accuracy: 0.6343998908996582\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss: 0.6416662931442261\n",
      "Accuracy: 0.6267998814582825\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss: 0.7746332883834839\n",
      "Accuracy: 0.6253998875617981\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss: 0.8745157718658447\n",
      "Accuracy: 0.6157999038696289\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss: 0.7383086681365967\n",
      "Accuracy: 0.6395999193191528\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss: 0.6986963152885437\n",
      "Accuracy: 0.6281998157501221\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss: 0.6619443297386169\n",
      "Accuracy: 0.6291999220848083\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss: 0.7430235743522644\n",
      "Accuracy: 0.6363998651504517\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss: 0.786668062210083\n",
      "Accuracy: 0.6353998780250549\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss: 0.7151021957397461\n",
      "Accuracy: 0.6363999247550964\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss: 0.7294960021972656\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss: 0.6628844738006592\n",
      "Accuracy: 0.6273999214172363\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss: 0.7488681077957153\n",
      "Accuracy: 0.6297999024391174\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss: 0.8226580023765564\n",
      "Accuracy: 0.616399884223938\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss: 0.7530068755149841\n",
      "Accuracy: 0.6301999092102051\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss: 0.7053644061088562\n",
      "Accuracy: 0.6355999112129211\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss: 0.6493692398071289\n",
      "Accuracy: 0.6261999607086182\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss: 0.7804358005523682\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss: 0.8063854575157166\n",
      "Accuracy: 0.6255998611450195\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss: 0.7055162191390991\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss: 0.7251409292221069\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss: 0.650990903377533\n",
      "Accuracy: 0.6269999742507935\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss: 0.7444919347763062\n",
      "Accuracy: 0.6361998319625854\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss: 0.8149040937423706\n",
      "Accuracy: 0.6225999593734741\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss: 0.701541543006897\n",
      "Accuracy: 0.6363999247550964\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss: 0.7275220155715942\n",
      "Accuracy: 0.6375998854637146\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss: 0.6400035619735718\n",
      "Accuracy: 0.6307998895645142\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss: 0.7844788432121277\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss: 0.762861430644989\n",
      "Accuracy: 0.624799907207489\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss: 0.7047882080078125\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss: 0.7184964418411255\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss: 0.669690728187561\n",
      "Accuracy: 0.6353998780250549\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss: 0.7579011917114258\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss: 0.8387887477874756\n",
      "Accuracy: 0.6263998746871948\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss: 0.7288370132446289\n",
      "Accuracy: 0.6339999437332153\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss: 0.6618589758872986\n",
      "Accuracy: 0.6305999159812927\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss: 0.6455472707748413\n",
      "Accuracy: 0.6283999681472778\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss: 0.7588856220245361\n",
      "Accuracy: 0.6367999315261841\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss: 0.7946516871452332\n",
      "Accuracy: 0.6283998489379883\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss: 0.7031396627426147\n",
      "Accuracy: 0.6361998319625854\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss: 0.7142860293388367\n",
      "Accuracy: 0.6291998624801636\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss: 0.6358188390731812\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss: 0.7405996918678284\n",
      "Accuracy: 0.6373998522758484\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss: 0.8183591961860657\n",
      "Accuracy: 0.6309999227523804\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss: 0.7766802310943604\n",
      "Accuracy: 0.6287998557090759\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss: 0.7131843566894531\n",
      "Accuracy: 0.6355998516082764\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss: 0.6850031614303589\n",
      "Accuracy: 0.6305999159812927\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss: 0.7260311245918274\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss: 0.8051231503486633\n",
      "Accuracy: 0.6249998807907104\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss: 0.7483124732971191\n",
      "Accuracy: 0.634199857711792\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss: 0.6777006387710571\n",
      "Accuracy: 0.6305999159812927\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss: 0.6553869843482971\n",
      "Accuracy: 0.6317999362945557\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss: 0.7177857160568237\n",
      "Accuracy: 0.6349999308586121\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss: 0.8070489764213562\n",
      "Accuracy: 0.6261999607086182\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss: 0.7364513874053955\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss: 0.7304303646087646\n",
      "Accuracy: 0.6339998841285706\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss: 0.6484307050704956\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss: 0.7206868529319763\n",
      "Accuracy: 0.6349998712539673\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss: 0.8220427632331848\n",
      "Accuracy: 0.6277998685836792\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss: 0.6899868249893188\n",
      "Accuracy: 0.6403999328613281\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss: 0.7124789953231812\n",
      "Accuracy: 0.6339999437332153\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss: 0.6502721905708313\n",
      "Accuracy: 0.6335998773574829\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss: 0.7244440317153931\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss: 0.8161604404449463\n",
      "Accuracy: 0.6271998882293701\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss: 0.7047443389892578\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss: 0.6865279078483582\n",
      "Accuracy: 0.6329998970031738\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss: 0.6699439287185669\n",
      "Accuracy: 0.6253999471664429\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss: 0.7339080572128296\n",
      "Accuracy: 0.6275998950004578\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss: 0.7878340482711792\n",
      "Accuracy: 0.619999885559082\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss: 0.7449672222137451\n",
      "Accuracy: 0.6343998908996582\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss: 0.7202689051628113\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss: 0.6218169927597046\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss: 0.7378894090652466\n",
      "Accuracy: 0.6351999044418335\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss: 0.8110193610191345\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss: 0.7236776947975159\n",
      "Accuracy: 0.6383998990058899\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss: 0.7114899158477783\n",
      "Accuracy: 0.6433998942375183\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss: 0.6844341158866882\n",
      "Accuracy: 0.6349998712539673\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss: 0.702675998210907\n",
      "Accuracy: 0.6391999125480652\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss: 0.8528605103492737\n",
      "Accuracy: 0.6309999227523804\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss: 0.722525954246521\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss: 0.695782482624054\n",
      "Accuracy: 0.6377999186515808\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss: 0.6740890741348267\n",
      "Accuracy: 0.6309999823570251\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss: 0.7230550646781921\n",
      "Accuracy: 0.63319993019104\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss: 0.8262628316879272\n",
      "Accuracy: 0.6315999031066895\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss: 0.7003952264785767\n",
      "Accuracy: 0.6367999315261841\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss: 0.6628384590148926\n",
      "Accuracy: 0.6321998834609985\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss: 0.6362344026565552\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss: 0.6912865042686462\n",
      "Accuracy: 0.6345999240875244\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss: 0.7647036910057068\n",
      "Accuracy: 0.6227998733520508\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss: 0.7255937457084656\n",
      "Accuracy: 0.6345998644828796\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss: 0.6983767151832581\n",
      "Accuracy: 0.6349999308586121\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss: 0.6656694412231445\n",
      "Accuracy: 0.6343998908996582\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss: 0.7502148151397705\n",
      "Accuracy: 0.6311999559402466\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss: 0.8300207257270813\n",
      "Accuracy: 0.629599928855896\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss: 0.7268655300140381\n",
      "Accuracy: 0.6395998597145081\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss: 0.6780343055725098\n",
      "Accuracy: 0.6345999240875244\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss: 0.6734201908111572\n",
      "Accuracy: 0.6281998753547668\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss: 0.7287601828575134\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss: 0.7994496822357178\n",
      "Accuracy: 0.6289998888969421\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss: 0.710807204246521\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss: 0.6823590993881226\n",
      "Accuracy: 0.6357998847961426\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss: 0.6526755690574646\n",
      "Accuracy: 0.6359999179840088\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss: 0.7149828672409058\n",
      "Accuracy: 0.6353999376296997\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss: 0.8130813837051392\n",
      "Accuracy: 0.6257998943328857\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss: 0.7188600301742554\n",
      "Accuracy: 0.6421998739242554\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss: 0.6913249492645264\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss: 0.6534287929534912\n",
      "Accuracy: 0.6363998651504517\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss: 0.7398871183395386\n",
      "Accuracy: 0.6327998638153076\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss: 0.7904536724090576\n",
      "Accuracy: 0.6263998746871948\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss: 0.7175431251525879\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss: 0.705870509147644\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss: 0.6654423475265503\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss: 0.721189022064209\n",
      "Accuracy: 0.640799880027771\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss: 0.7259857654571533\n",
      "Accuracy: 0.6217999458312988\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss: 0.6939132213592529\n",
      "Accuracy: 0.6377999186515808\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss: 0.7029927372932434\n",
      "Accuracy: 0.642599880695343\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss: 0.666732668876648\n",
      "Accuracy: 0.6311998963356018\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss: 0.7438968420028687\n",
      "Accuracy: 0.6349998712539673\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss: 0.8023200035095215\n",
      "Accuracy: 0.6263998746871948\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss: 0.7087620496749878\n",
      "Accuracy: 0.6367998719215393\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss: 0.7171948552131653\n",
      "Accuracy: 0.6421998739242554\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss: 0.6647685766220093\n",
      "Accuracy: 0.634199857711792\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss: 0.7267168164253235\n",
      "Accuracy: 0.6345998644828796\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss: 0.7842955589294434\n",
      "Accuracy: 0.6191998720169067\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss: 0.7430999875068665\n",
      "Accuracy: 0.6359999179840088\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss: 0.6483103632926941\n",
      "Accuracy: 0.6355999112129211\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss: 0.6475933194160461\n",
      "Accuracy: 0.6319999098777771\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss: 0.7942675352096558\n",
      "Accuracy: 0.6333998441696167\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss: 0.7688772082328796\n",
      "Accuracy: 0.6261999011039734\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss: 0.7367135286331177\n",
      "Accuracy: 0.6395999193191528\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss: 0.6602715253829956\n",
      "Accuracy: 0.6309998631477356\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss: 0.6392979621887207\n",
      "Accuracy: 0.6279999017715454\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss: 0.7095289826393127\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss: 0.7889487743377686\n",
      "Accuracy: 0.6223999261856079\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss: 0.7221696972846985\n",
      "Accuracy: 0.6383998394012451\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss: 0.6501981616020203\n",
      "Accuracy: 0.6357998847961426\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss: 0.6737911701202393\n",
      "Accuracy: 0.6257998943328857\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss: 0.7726219892501831\n",
      "Accuracy: 0.63319993019104\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss: 0.7730487585067749\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss: 0.6826013326644897\n",
      "Accuracy: 0.6381998658180237\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss: 0.6418095827102661\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss: 0.6778684854507446\n",
      "Accuracy: 0.6367998719215393\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss: 0.7065002918243408\n",
      "Accuracy: 0.6399998664855957\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss: 0.7767365574836731\n",
      "Accuracy: 0.6233999133110046\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss: 0.7505587339401245\n",
      "Accuracy: 0.6337998509407043\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss: 0.7007007598876953\n",
      "Accuracy: 0.6347998976707458\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss: 0.6273958086967468\n",
      "Accuracy: 0.6347998976707458\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss: 0.7189130783081055\n",
      "Accuracy: 0.6367999315261841\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss: 0.7778735160827637\n",
      "Accuracy: 0.6261999011039734\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss: 0.6930426359176636\n",
      "Accuracy: 0.6379998922348022\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss: 0.6893923878669739\n",
      "Accuracy: 0.6421999335289001\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss: 0.63871169090271\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss: 0.761407732963562\n",
      "Accuracy: 0.6335999369621277\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss: 0.765973687171936\n",
      "Accuracy: 0.6221998929977417\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss: 0.7115288972854614\n",
      "Accuracy: 0.6373998522758484\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss: 0.6971933841705322\n",
      "Accuracy: 0.6365999579429626\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss: 0.6496446132659912\n",
      "Accuracy: 0.6343998908996582\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss: 0.7533053755760193\n",
      "Accuracy: 0.6301998496055603\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss: 0.770297646522522\n",
      "Accuracy: 0.6335998773574829\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss: 0.7143707871437073\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss: 0.6764143705368042\n",
      "Accuracy: 0.642599880695343\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss: 0.6739201545715332\n",
      "Accuracy: 0.6185999512672424\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss: 0.738634467124939\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss: 0.8367948532104492\n",
      "Accuracy: 0.6157998442649841\n",
      "Epoch 344, CIFAR-10 Batch 3:  Loss: 0.706623911857605\n",
      "Accuracy: 0.6359999179840088\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss: 0.7025890350341797\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss: 0.626882791519165\n",
      "Accuracy: 0.6287998557090759\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss: 0.731747031211853\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss: 0.7616259455680847\n",
      "Accuracy: 0.630599856376648\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss: 0.6946709156036377\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss: 0.6685211062431335\n",
      "Accuracy: 0.6387998461723328\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss: 0.6625220775604248\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss: 0.7429096698760986\n",
      "Accuracy: 0.6349999308586121\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss: 0.8216327428817749\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss: 0.6779961585998535\n",
      "Accuracy: 0.6395999193191528\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss: 0.7037168145179749\n",
      "Accuracy: 0.6359999179840088\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss: 0.6275646686553955\n",
      "Accuracy: 0.6345998644828796\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss: 0.722704291343689\n",
      "Accuracy: 0.6331998705863953\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss: 0.7590814828872681\n",
      "Accuracy: 0.6285998821258545\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss: 0.7081440091133118\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss: 0.7027149200439453\n",
      "Accuracy: 0.6391998529434204\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss: 0.655726432800293\n",
      "Accuracy: 0.6345998644828796\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss: 0.7735035419464111\n",
      "Accuracy: 0.6287997961044312\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss: 0.7471979856491089\n",
      "Accuracy: 0.627799928188324\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss: 0.7459195852279663\n",
      "Accuracy: 0.6363998651504517\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss: 0.7173780798912048\n",
      "Accuracy: 0.6339998841285706\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss: 0.6648144721984863\n",
      "Accuracy: 0.6309999227523804\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss: 0.7101553082466125\n",
      "Accuracy: 0.6401998996734619\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss: 0.8011248111724854\n",
      "Accuracy: 0.6331998705863953\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss: 0.7498528957366943\n",
      "Accuracy: 0.6405998468399048\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss: 0.7211628556251526\n",
      "Accuracy: 0.6349999308586121\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss: 0.6344982981681824\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss: 0.7394731044769287\n",
      "Accuracy: 0.6315999031066895\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss: 0.8111569881439209\n",
      "Accuracy: 0.6305999159812927\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss: 0.7241637706756592\n",
      "Accuracy: 0.63319993019104\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss: 0.706249475479126\n",
      "Accuracy: 0.6349998712539673\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss: 0.6611202359199524\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss: 0.7429531812667847\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss: 0.8348037004470825\n",
      "Accuracy: 0.6269998550415039\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss: 0.735985279083252\n",
      "Accuracy: 0.6315998435020447\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss: 0.6955418586730957\n",
      "Accuracy: 0.6409998536109924\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss: 0.6467326879501343\n",
      "Accuracy: 0.6347998976707458\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss: 0.7748165130615234\n",
      "Accuracy: 0.635999858379364\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss: 0.7295132279396057\n",
      "Accuracy: 0.6297999024391174\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss: 0.6885201930999756\n",
      "Accuracy: 0.6413998603820801\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss: 0.7278979420661926\n",
      "Accuracy: 0.6383998394012451\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss: 0.6611524820327759\n",
      "Accuracy: 0.6379998922348022\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss: 0.7130300998687744\n",
      "Accuracy: 0.63239985704422\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss: 0.7314589023590088\n",
      "Accuracy: 0.6285998821258545\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss: 0.673358142375946\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss: 0.7068227529525757\n",
      "Accuracy: 0.6387998461723328\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss: 0.6510342359542847\n",
      "Accuracy: 0.6273998618125916\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss: 0.7338517308235168\n",
      "Accuracy: 0.6371999382972717\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss: 0.7672824263572693\n",
      "Accuracy: 0.6285999417304993\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss: 0.7106447219848633\n",
      "Accuracy: 0.6353998780250549\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss: 0.7112942934036255\n",
      "Accuracy: 0.6333998441696167\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss: 0.6490737795829773\n",
      "Accuracy: 0.6339998841285706\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss: 0.7568368911743164\n",
      "Accuracy: 0.6347998976707458\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss: 0.8106176257133484\n",
      "Accuracy: 0.630599856376648\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss: 0.7089403867721558\n",
      "Accuracy: 0.6409999132156372\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss: 0.724141001701355\n",
      "Accuracy: 0.6357998847961426\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss: 0.6622430682182312\n",
      "Accuracy: 0.6345998644828796\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss: 0.7493852972984314\n",
      "Accuracy: 0.6339998841285706\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss: 0.7476710081100464\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss: 0.7090023159980774\n",
      "Accuracy: 0.6357998847961426\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss: 0.7081618309020996\n",
      "Accuracy: 0.6421998739242554\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss: 0.6494152545928955\n",
      "Accuracy: 0.6427999138832092\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss: 0.7124358415603638\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss: 0.7354638576507568\n",
      "Accuracy: 0.6305999159812927\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss: 0.6742603778839111\n",
      "Accuracy: 0.6427999138832092\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss: 0.7351747751235962\n",
      "Accuracy: 0.6411998867988586\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss: 0.6473309993743896\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss: 0.7322791814804077\n",
      "Accuracy: 0.635999858379364\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss: 0.7983188629150391\n",
      "Accuracy: 0.6309999227523804\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss: 0.6915609240531921\n",
      "Accuracy: 0.6409998536109924\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss: 0.6748778223991394\n",
      "Accuracy: 0.640799880027771\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss: 0.6390726566314697\n",
      "Accuracy: 0.6303998827934265\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss: 0.7726895213127136\n",
      "Accuracy: 0.6377999186515808\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss: 0.7908505797386169\n",
      "Accuracy: 0.6335999369621277\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss: 0.7116245031356812\n",
      "Accuracy: 0.6367998719215393\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss: 0.6953245401382446\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss: 0.6490596532821655\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss: 0.7184567451477051\n",
      "Accuracy: 0.6291998624801636\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss: 0.7926536798477173\n",
      "Accuracy: 0.6353998780250549\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss: 0.7025648951530457\n",
      "Accuracy: 0.6447998881340027\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss: 0.6999629735946655\n",
      "Accuracy: 0.6317998766899109\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss: 0.6397261023521423\n",
      "Accuracy: 0.6375998854637146\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss: 0.7323639392852783\n",
      "Accuracy: 0.6373998522758484\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss: 0.7617447376251221\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss: 0.7127774953842163\n",
      "Accuracy: 0.6375999450683594\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss: 0.7367939352989197\n",
      "Accuracy: 0.6359999179840088\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss: 0.6783776879310608\n",
      "Accuracy: 0.6327998638153076\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss: 0.7119501829147339\n",
      "Accuracy: 0.6341999173164368\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss: 0.7700248956680298\n",
      "Accuracy: 0.6315999031066895\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss: 0.7119721174240112\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss: 0.6915603876113892\n",
      "Accuracy: 0.6461999416351318\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss: 0.6846281886100769\n",
      "Accuracy: 0.6375999450683594\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss: 0.7064781188964844\n",
      "Accuracy: 0.6429998874664307\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss: 0.7525551319122314\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss: 0.6844078898429871\n",
      "Accuracy: 0.6423999071121216\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss: 0.6628371477127075\n",
      "Accuracy: 0.6323999166488647\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss: 0.6601853370666504\n",
      "Accuracy: 0.6277998685836792\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss: 0.7035374641418457\n",
      "Accuracy: 0.6323999166488647\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss: 0.7684133052825928\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss: 0.6818594336509705\n",
      "Accuracy: 0.6383998990058899\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss: 0.72592693567276\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss: 0.6663617491722107\n",
      "Accuracy: 0.6343998312950134\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss: 0.6902980804443359\n",
      "Accuracy: 0.6461999416351318\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss: 0.7847169041633606\n",
      "Accuracy: 0.6223998665809631\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss: 0.6846798658370972\n",
      "Accuracy: 0.6379998326301575\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss: 0.711811900138855\n",
      "Accuracy: 0.6439999341964722\n",
      "Epoch 365, CIFAR-10 Batch 5:  Loss: 0.661184549331665\n",
      "Accuracy: 0.6301999092102051\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss: 0.7389565110206604\n",
      "Accuracy: 0.6267999410629272\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss: 0.7368499636650085\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss: 0.7041140794754028\n",
      "Accuracy: 0.6427999138832092\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss: 0.7145702242851257\n",
      "Accuracy: 0.6407999396324158\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss: 0.6782464981079102\n",
      "Accuracy: 0.6299999356269836\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss: 0.713381290435791\n",
      "Accuracy: 0.6279999017715454\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss: 0.7614536881446838\n",
      "Accuracy: 0.627599835395813\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss: 0.6995229721069336\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss: 0.6862589120864868\n",
      "Accuracy: 0.6391998529434204\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss: 0.6703561544418335\n",
      "Accuracy: 0.6327998638153076\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss: 0.7232463955879211\n",
      "Accuracy: 0.6409998536109924\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss: 0.7503762245178223\n",
      "Accuracy: 0.6271998882293701\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss: 0.7266285419464111\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss: 0.6908389329910278\n",
      "Accuracy: 0.6405999064445496\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss: 0.6760234236717224\n",
      "Accuracy: 0.6309998631477356\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss: 0.732253909111023\n",
      "Accuracy: 0.6357999444007874\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss: 0.7552776336669922\n",
      "Accuracy: 0.6289998888969421\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss: 0.7226503491401672\n",
      "Accuracy: 0.6303999423980713\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss: 0.6919638514518738\n",
      "Accuracy: 0.6435999870300293\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss: 0.6647192239761353\n",
      "Accuracy: 0.6273999214172363\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss: 0.7115267515182495\n",
      "Accuracy: 0.6383998990058899\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss: 0.7306976318359375\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss: 0.7648059129714966\n",
      "Accuracy: 0.6397998929023743\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss: 0.6944987773895264\n",
      "Accuracy: 0.6475998163223267\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss: 0.646759033203125\n",
      "Accuracy: 0.6291999220848083\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss: 0.7029857635498047\n",
      "Accuracy: 0.6369999051094055\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss: 0.7342435717582703\n",
      "Accuracy: 0.6225998401641846\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss: 0.7075486183166504\n",
      "Accuracy: 0.6421998739242554\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss: 0.6805586218833923\n",
      "Accuracy: 0.6475999355316162\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss: 0.6512243151664734\n",
      "Accuracy: 0.6305999159812927\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss: 0.7570559978485107\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss: 0.7500584721565247\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss: 0.7209382653236389\n",
      "Accuracy: 0.6453999280929565\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss: 0.7016092538833618\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss: 0.6391531825065613\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss: 0.7776973247528076\n",
      "Accuracy: 0.632599949836731\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss: 0.7328278422355652\n",
      "Accuracy: 0.6355999708175659\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss: 0.6704956293106079\n",
      "Accuracy: 0.6427998542785645\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss: 0.6888121366500854\n",
      "Accuracy: 0.6445998549461365\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss: 0.6487148404121399\n",
      "Accuracy: 0.6373998522758484\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss: 0.7685539722442627\n",
      "Accuracy: 0.6445999145507812\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss: 0.7088664770126343\n",
      "Accuracy: 0.6253999471664429\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss: 0.7153487205505371\n",
      "Accuracy: 0.6431999206542969\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss: 0.7158640623092651\n",
      "Accuracy: 0.6429998278617859\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss: 0.6267071962356567\n",
      "Accuracy: 0.6387998461723328\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss: 0.750111997127533\n",
      "Accuracy: 0.6415999531745911\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss: 0.7045605778694153\n",
      "Accuracy: 0.6325998902320862\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss: 0.6957117915153503\n",
      "Accuracy: 0.6369999051094055\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss: 0.6902862787246704\n",
      "Accuracy: 0.645599901676178\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss: 0.6772955060005188\n",
      "Accuracy: 0.6363999247550964\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss: 0.7190011739730835\n",
      "Accuracy: 0.635999858379364\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss: 0.7579965591430664\n",
      "Accuracy: 0.6301999092102051\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss: 0.688401997089386\n",
      "Accuracy: 0.6461999416351318\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss: 0.7187737226486206\n",
      "Accuracy: 0.6405998468399048\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss: 0.6704274415969849\n",
      "Accuracy: 0.6329998970031738\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss: 0.7405846118927002\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss: 0.7085117101669312\n",
      "Accuracy: 0.632599949836731\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss: 0.6921564340591431\n",
      "Accuracy: 0.642599880695343\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss: 0.6844379901885986\n",
      "Accuracy: 0.6431999206542969\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss: 0.6688171029090881\n",
      "Accuracy: 0.6317999362945557\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss: 0.7676407098770142\n",
      "Accuracy: 0.6379998922348022\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss: 0.7034196853637695\n",
      "Accuracy: 0.6357999444007874\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss: 0.739558756351471\n",
      "Accuracy: 0.644399881362915\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss: 0.7121968269348145\n",
      "Accuracy: 0.6425999402999878\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss: 0.6385878324508667\n",
      "Accuracy: 0.6317999362945557\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss: 0.7483888864517212\n",
      "Accuracy: 0.6405998468399048\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss: 0.7119874358177185\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss: 0.7257640361785889\n",
      "Accuracy: 0.6379998326301575\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss: 0.7107356786727905\n",
      "Accuracy: 0.6395999193191528\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss: 0.6730371713638306\n",
      "Accuracy: 0.6335999369621277\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss: 0.6684598922729492\n",
      "Accuracy: 0.6353999376296997\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss: 0.7349386811256409\n",
      "Accuracy: 0.6309999227523804\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss: 0.704664945602417\n",
      "Accuracy: 0.6379998326301575\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss: 0.6915484666824341\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss: 0.6546953916549683\n",
      "Accuracy: 0.6429998874664307\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss: 0.7280312776565552\n",
      "Accuracy: 0.6411998867988586\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss: 0.7115870714187622\n",
      "Accuracy: 0.626599907875061\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss: 0.7032100558280945\n",
      "Accuracy: 0.6363998651504517\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss: 0.71207594871521\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss: 0.7202403545379639\n",
      "Accuracy: 0.6235998868942261\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss: 0.7384326457977295\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss: 0.7113472819328308\n",
      "Accuracy: 0.6341999173164368\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss: 0.7047542929649353\n",
      "Accuracy: 0.6379998326301575\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss: 0.7003963589668274\n",
      "Accuracy: 0.644399881362915\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss: 0.650002121925354\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss: 0.7286529541015625\n",
      "Accuracy: 0.6391999125480652\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss: 0.7460025548934937\n",
      "Accuracy: 0.6355999708175659\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss: 0.6847870349884033\n",
      "Accuracy: 0.6461999416351318\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss: 0.7082831859588623\n",
      "Accuracy: 0.6443999409675598\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss: 0.6492624878883362\n",
      "Accuracy: 0.6391998529434204\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss: 0.7229568958282471\n",
      "Accuracy: 0.6431998610496521\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss: 0.729597806930542\n",
      "Accuracy: 0.6291999220848083\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss: 0.6976476311683655\n",
      "Accuracy: 0.640799880027771\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss: 0.7197757959365845\n",
      "Accuracy: 0.6399998664855957\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss: 0.6475902795791626\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss: 0.7213991284370422\n",
      "Accuracy: 0.6417999267578125\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss: 0.7703849077224731\n",
      "Accuracy: 0.6393999457359314\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss: 0.6786996126174927\n",
      "Accuracy: 0.6357999444007874\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss: 0.7015438079833984\n",
      "Accuracy: 0.6477999091148376\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss: 0.6472467184066772\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss: 0.7322832942008972\n",
      "Accuracy: 0.6405999064445496\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss: 0.7603587508201599\n",
      "Accuracy: 0.6347998976707458\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss: 0.7076590657234192\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss: 0.711104154586792\n",
      "Accuracy: 0.6501998901367188\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss: 0.6367195248603821\n",
      "Accuracy: 0.6367999315261841\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss: 0.7169976830482483\n",
      "Accuracy: 0.6423998475074768\n",
      "Epoch 387, CIFAR-10 Batch 2:  Loss: 0.734891414642334\n",
      "Accuracy: 0.6405999064445496\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss: 0.6833699345588684\n",
      "Accuracy: 0.6427999138832092\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss: 0.6905016303062439\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss: 0.6351315379142761\n",
      "Accuracy: 0.6401998996734619\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss: 0.7738438844680786\n",
      "Accuracy: 0.6383999586105347\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss: 0.7050168514251709\n",
      "Accuracy: 0.6319999098777771\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss: 0.6604194641113281\n",
      "Accuracy: 0.6429999470710754\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss: 0.6943752765655518\n",
      "Accuracy: 0.6487998962402344\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss: 0.6455604434013367\n",
      "Accuracy: 0.6351998448371887\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss: 0.7165733575820923\n",
      "Accuracy: 0.6423999071121216\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss: 0.7566866278648376\n",
      "Accuracy: 0.6391998529434204\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss: 0.6889819502830505\n",
      "Accuracy: 0.6433998942375183\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss: 0.6826006174087524\n",
      "Accuracy: 0.642599880695343\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss: 0.664784848690033\n",
      "Accuracy: 0.631199836730957\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss: 0.7258692979812622\n",
      "Accuracy: 0.6421999335289001\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss: 0.7417857050895691\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss: 0.665144145488739\n",
      "Accuracy: 0.6459998488426208\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss: 0.6746639609336853\n",
      "Accuracy: 0.6485999226570129\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss: 0.6455094814300537\n",
      "Accuracy: 0.6341999173164368\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss: 0.7725465297698975\n",
      "Accuracy: 0.6391998529434204\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss: 0.7173686027526855\n",
      "Accuracy: 0.6315998435020447\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss: 0.6706640124320984\n",
      "Accuracy: 0.6519998908042908\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss: 0.702203631401062\n",
      "Accuracy: 0.6383998990058899\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss: 0.6160983443260193\n",
      "Accuracy: 0.6359999179840088\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss: 0.7081236839294434\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss: 0.7483360767364502\n",
      "Accuracy: 0.6309999227523804\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss: 0.6977626085281372\n",
      "Accuracy: 0.6483998894691467\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss: 0.6895589232444763\n",
      "Accuracy: 0.6435998678207397\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss: 0.6186504364013672\n",
      "Accuracy: 0.6355998516082764\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss: 0.6965864896774292\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss: 0.6846885085105896\n",
      "Accuracy: 0.6401998996734619\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss: 0.6530719995498657\n",
      "Accuracy: 0.6467999219894409\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss: 0.6483726501464844\n",
      "Accuracy: 0.642599880695343\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss: 0.6404826641082764\n",
      "Accuracy: 0.6453998684883118\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss: 0.7053524255752563\n",
      "Accuracy: 0.6347999572753906\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss: 0.732422947883606\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss: 0.6708195805549622\n",
      "Accuracy: 0.6441999077796936\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss: 0.6912262439727783\n",
      "Accuracy: 0.6413998603820801\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss: 0.6425862312316895\n",
      "Accuracy: 0.6291999220848083\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss: 0.6960746049880981\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss: 0.7366856932640076\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss: 0.6762931942939758\n",
      "Accuracy: 0.6379998922348022\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss: 0.714083731174469\n",
      "Accuracy: 0.6371999382972717\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss: 0.6565806865692139\n",
      "Accuracy: 0.6349998116493225\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss: 0.7202525734901428\n",
      "Accuracy: 0.6421998739242554\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss: 0.744196355342865\n",
      "Accuracy: 0.6297999024391174\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss: 0.6904172897338867\n",
      "Accuracy: 0.6459999084472656\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss: 0.7006865739822388\n",
      "Accuracy: 0.6421999335289001\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss: 0.6449901461601257\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss: 0.737790584564209\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss: 0.7324582934379578\n",
      "Accuracy: 0.6405999660491943\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss: 0.6646885275840759\n",
      "Accuracy: 0.6445999145507812\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss: 0.6541228294372559\n",
      "Accuracy: 0.6497999429702759\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss: 0.6567626595497131\n",
      "Accuracy: 0.6405999064445496\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss: 0.7300309538841248\n",
      "Accuracy: 0.6375999450683594\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss: 0.7452077269554138\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss: 0.6914560794830322\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss: 0.7177667617797852\n",
      "Accuracy: 0.6401998996734619\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss: 0.624713659286499\n",
      "Accuracy: 0.6293998956680298\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss: 0.7326685786247253\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss: 0.7353096604347229\n",
      "Accuracy: 0.6281999349594116\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss: 0.6591333746910095\n",
      "Accuracy: 0.6421998739242554\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss: 0.7496277093887329\n",
      "Accuracy: 0.6405999064445496\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss: 0.6906883716583252\n",
      "Accuracy: 0.629599928855896\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss: 0.701185941696167\n",
      "Accuracy: 0.6409999132156372\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss: 0.7217360734939575\n",
      "Accuracy: 0.6343998908996582\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss: 0.6796005964279175\n",
      "Accuracy: 0.6445998549461365\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss: 0.7195215225219727\n",
      "Accuracy: 0.6479998826980591\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss: 0.6619521975517273\n",
      "Accuracy: 0.6371999382972717\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss: 0.7086375951766968\n",
      "Accuracy: 0.6411998867988586\n",
      "Epoch 401, CIFAR-10 Batch 2:  Loss: 0.716540515422821\n",
      "Accuracy: 0.6327998638153076\n",
      "Epoch 401, CIFAR-10 Batch 3:  Loss: 0.6575624346733093\n",
      "Accuracy: 0.6481999158859253\n",
      "Epoch 401, CIFAR-10 Batch 4:  Loss: 0.7071149945259094\n",
      "Accuracy: 0.6423999071121216\n",
      "Epoch 401, CIFAR-10 Batch 5:  Loss: 0.649229109287262\n",
      "Accuracy: 0.6405999064445496\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss: 0.7431229948997498\n",
      "Accuracy: 0.6433998942375183\n",
      "Epoch 402, CIFAR-10 Batch 2:  Loss: 0.7443285584449768\n",
      "Accuracy: 0.6405999064445496\n",
      "Epoch 402, CIFAR-10 Batch 3:  Loss: 0.6764023303985596\n",
      "Accuracy: 0.6379998922348022\n",
      "Epoch 402, CIFAR-10 Batch 4:  Loss: 0.6851285696029663\n",
      "Accuracy: 0.6397998929023743\n",
      "Epoch 402, CIFAR-10 Batch 5:  Loss: 0.6477231979370117\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss: 0.7496052980422974\n",
      "Accuracy: 0.6395999193191528\n",
      "Epoch 403, CIFAR-10 Batch 2:  Loss: 0.7263839840888977\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 403, CIFAR-10 Batch 3:  Loss: 0.6475738883018494\n",
      "Accuracy: 0.6471998691558838\n",
      "Epoch 403, CIFAR-10 Batch 4:  Loss: 0.7245588302612305\n",
      "Accuracy: 0.6297999024391174\n",
      "Epoch 403, CIFAR-10 Batch 5:  Loss: 0.6572750806808472\n",
      "Accuracy: 0.6307998895645142\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss: 0.716407835483551\n",
      "Accuracy: 0.6413998603820801\n",
      "Epoch 404, CIFAR-10 Batch 2:  Loss: 0.7484339475631714\n",
      "Accuracy: 0.6315999031066895\n",
      "Epoch 404, CIFAR-10 Batch 3:  Loss: 0.6761638522148132\n",
      "Accuracy: 0.6423998475074768\n",
      "Epoch 404, CIFAR-10 Batch 4:  Loss: 0.7281581163406372\n",
      "Accuracy: 0.6413999199867249\n",
      "Epoch 404, CIFAR-10 Batch 5:  Loss: 0.6271622180938721\n",
      "Accuracy: 0.6371998190879822\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss: 0.692168116569519\n",
      "Accuracy: 0.6333998441696167\n",
      "Epoch 405, CIFAR-10 Batch 2:  Loss: 0.7068127989768982\n",
      "Accuracy: 0.6377999782562256\n",
      "Epoch 405, CIFAR-10 Batch 3:  Loss: 0.6471765637397766\n",
      "Accuracy: 0.6483998894691467\n",
      "Epoch 405, CIFAR-10 Batch 4:  Loss: 0.7134559154510498\n",
      "Accuracy: 0.6425999402999878\n",
      "Epoch 405, CIFAR-10 Batch 5:  Loss: 0.6629704236984253\n",
      "Accuracy: 0.6411998867988586\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss: 0.7326942682266235\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 406, CIFAR-10 Batch 2:  Loss: 0.7215304374694824\n",
      "Accuracy: 0.634199857711792\n",
      "Epoch 406, CIFAR-10 Batch 3:  Loss: 0.661879301071167\n",
      "Accuracy: 0.6481998562812805\n",
      "Epoch 406, CIFAR-10 Batch 4:  Loss: 0.6625428199768066\n",
      "Accuracy: 0.6469999551773071\n",
      "Epoch 406, CIFAR-10 Batch 5:  Loss: 0.6487070322036743\n",
      "Accuracy: 0.6409999132156372\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss: 0.7150683403015137\n",
      "Accuracy: 0.6417999267578125\n",
      "Epoch 407, CIFAR-10 Batch 2:  Loss: 0.7443250417709351\n",
      "Accuracy: 0.6383998990058899\n",
      "Epoch 407, CIFAR-10 Batch 3:  Loss: 0.6765064001083374\n",
      "Accuracy: 0.640799880027771\n",
      "Epoch 407, CIFAR-10 Batch 4:  Loss: 0.6935402750968933\n",
      "Accuracy: 0.6405999660491943\n",
      "Epoch 407, CIFAR-10 Batch 5:  Loss: 0.6535860896110535\n",
      "Accuracy: 0.6271998882293701\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss: 0.7103841304779053\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 408, CIFAR-10 Batch 2:  Loss: 0.7309364676475525\n",
      "Accuracy: 0.6353998780250549\n",
      "Epoch 408, CIFAR-10 Batch 3:  Loss: 0.6576292514801025\n",
      "Accuracy: 0.6495998501777649\n",
      "Epoch 408, CIFAR-10 Batch 4:  Loss: 0.7112833857536316\n",
      "Accuracy: 0.6387999653816223\n",
      "Epoch 408, CIFAR-10 Batch 5:  Loss: 0.6508433818817139\n",
      "Accuracy: 0.6321998834609985\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss: 0.6929057836532593\n",
      "Accuracy: 0.6401998996734619\n",
      "Epoch 409, CIFAR-10 Batch 2:  Loss: 0.7445842623710632\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 409, CIFAR-10 Batch 3:  Loss: 0.6718276739120483\n",
      "Accuracy: 0.6477999091148376\n",
      "Epoch 409, CIFAR-10 Batch 4:  Loss: 0.6924725770950317\n",
      "Accuracy: 0.6463999152183533\n",
      "Epoch 409, CIFAR-10 Batch 5:  Loss: 0.6365430951118469\n",
      "Accuracy: 0.6439999341964722\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss: 0.7514166831970215\n",
      "Accuracy: 0.6367998719215393\n",
      "Epoch 410, CIFAR-10 Batch 2:  Loss: 0.7825493216514587\n",
      "Accuracy: 0.6353998184204102\n",
      "Epoch 410, CIFAR-10 Batch 3:  Loss: 0.696756899356842\n",
      "Accuracy: 0.6417998671531677\n",
      "Epoch 410, CIFAR-10 Batch 4:  Loss: 0.7176356315612793\n",
      "Accuracy: 0.6445999145507812\n",
      "Epoch 410, CIFAR-10 Batch 5:  Loss: 0.6606160402297974\n",
      "Accuracy: 0.6487998962402344\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss: 0.7919630408287048\n",
      "Accuracy: 0.6307998895645142\n",
      "Epoch 411, CIFAR-10 Batch 2:  Loss: 0.8204408884048462\n",
      "Accuracy: 0.6415998935699463\n",
      "Epoch 411, CIFAR-10 Batch 3:  Loss: 0.6789136528968811\n",
      "Accuracy: 0.6435998678207397\n",
      "Epoch 411, CIFAR-10 Batch 4:  Loss: 0.7158033847808838\n",
      "Accuracy: 0.6413998603820801\n",
      "Epoch 411, CIFAR-10 Batch 5:  Loss: 0.6766303777694702\n",
      "Accuracy: 0.6419998407363892\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss: 0.742418646812439\n",
      "Accuracy: 0.6441999077796936\n",
      "Epoch 412, CIFAR-10 Batch 2:  Loss: 0.748225748538971\n",
      "Accuracy: 0.6467998623847961\n",
      "Epoch 412, CIFAR-10 Batch 3:  Loss: 0.6823830604553223\n",
      "Accuracy: 0.6427999138832092\n",
      "Epoch 412, CIFAR-10 Batch 4:  Loss: 0.7148535251617432\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 412, CIFAR-10 Batch 5:  Loss: 0.6640782952308655\n",
      "Accuracy: 0.6427998542785645\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss: 0.7370314002037048\n",
      "Accuracy: 0.6415998935699463\n",
      "Epoch 413, CIFAR-10 Batch 2:  Loss: 0.7269576191902161\n",
      "Accuracy: 0.6407999396324158\n",
      "Epoch 413, CIFAR-10 Batch 3:  Loss: 0.6556929349899292\n",
      "Accuracy: 0.6483999490737915\n",
      "Epoch 413, CIFAR-10 Batch 4:  Loss: 0.7273653745651245\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 413, CIFAR-10 Batch 5:  Loss: 0.6530358791351318\n",
      "Accuracy: 0.6221998929977417\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss: 0.7152034044265747\n",
      "Accuracy: 0.6415998935699463\n",
      "Epoch 414, CIFAR-10 Batch 2:  Loss: 0.7442657351493835\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 414, CIFAR-10 Batch 3:  Loss: 0.690001368522644\n",
      "Accuracy: 0.644399881362915\n",
      "Epoch 414, CIFAR-10 Batch 4:  Loss: 0.7262358069419861\n",
      "Accuracy: 0.6381998658180237\n",
      "Epoch 414, CIFAR-10 Batch 5:  Loss: 0.6599714756011963\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss: 0.7015830278396606\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 415, CIFAR-10 Batch 2:  Loss: 0.7176573872566223\n",
      "Accuracy: 0.6399998664855957\n",
      "Epoch 415, CIFAR-10 Batch 3:  Loss: 0.6654348373413086\n",
      "Accuracy: 0.6469998955726624\n",
      "Epoch 415, CIFAR-10 Batch 4:  Loss: 0.7017812728881836\n",
      "Accuracy: 0.6457998752593994\n",
      "Epoch 415, CIFAR-10 Batch 5:  Loss: 0.6437134742736816\n",
      "Accuracy: 0.6283999085426331\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss: 0.6864818334579468\n",
      "Accuracy: 0.6391999125480652\n",
      "Epoch 416, CIFAR-10 Batch 2:  Loss: 0.7729409337043762\n",
      "Accuracy: 0.6367998719215393\n",
      "Epoch 416, CIFAR-10 Batch 3:  Loss: 0.7181804180145264\n",
      "Accuracy: 0.6449998617172241\n",
      "Epoch 416, CIFAR-10 Batch 4:  Loss: 0.704857587814331\n",
      "Accuracy: 0.6493998765945435\n",
      "Epoch 416, CIFAR-10 Batch 5:  Loss: 0.6511551141738892\n",
      "Accuracy: 0.6313998699188232\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss: 0.7412580847740173\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 417, CIFAR-10 Batch 2:  Loss: 0.7238924503326416\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 417, CIFAR-10 Batch 3:  Loss: 0.6895712018013\n",
      "Accuracy: 0.6465998888015747\n",
      "Epoch 417, CIFAR-10 Batch 4:  Loss: 0.725771963596344\n",
      "Accuracy: 0.6471998691558838\n",
      "Epoch 417, CIFAR-10 Batch 5:  Loss: 0.6942795515060425\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss: 0.6991881132125854\n",
      "Accuracy: 0.644399881362915\n",
      "Epoch 418, CIFAR-10 Batch 2:  Loss: 0.7599276304244995\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 418, CIFAR-10 Batch 3:  Loss: 0.6887097954750061\n",
      "Accuracy: 0.6443998217582703\n",
      "Epoch 418, CIFAR-10 Batch 4:  Loss: 0.6936367750167847\n",
      "Accuracy: 0.644399881362915\n",
      "Epoch 418, CIFAR-10 Batch 5:  Loss: 0.6459050178527832\n",
      "Accuracy: 0.6409999132156372\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss: 0.7145731449127197\n",
      "Accuracy: 0.6457998752593994\n",
      "Epoch 419, CIFAR-10 Batch 2:  Loss: 0.7308204174041748\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 419, CIFAR-10 Batch 3:  Loss: 0.6430923938751221\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 419, CIFAR-10 Batch 4:  Loss: 0.6904851198196411\n",
      "Accuracy: 0.648999810218811\n",
      "Epoch 419, CIFAR-10 Batch 5:  Loss: 0.6548262238502502\n",
      "Accuracy: 0.6485999226570129\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss: 0.7358458042144775\n",
      "Accuracy: 0.6449998617172241\n",
      "Epoch 420, CIFAR-10 Batch 2:  Loss: 0.7322996258735657\n",
      "Accuracy: 0.6371998190879822\n",
      "Epoch 420, CIFAR-10 Batch 3:  Loss: 0.6693642735481262\n",
      "Accuracy: 0.6505998373031616\n",
      "Epoch 420, CIFAR-10 Batch 4:  Loss: 0.7139031291007996\n",
      "Accuracy: 0.6417999267578125\n",
      "Epoch 420, CIFAR-10 Batch 5:  Loss: 0.655049204826355\n",
      "Accuracy: 0.6315998435020447\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss: 0.7653402090072632\n",
      "Accuracy: 0.6377999186515808\n",
      "Epoch 421, CIFAR-10 Batch 2:  Loss: 0.7171851396560669\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 421, CIFAR-10 Batch 3:  Loss: 0.7178512215614319\n",
      "Accuracy: 0.6391999125480652\n",
      "Epoch 421, CIFAR-10 Batch 4:  Loss: 0.7198373675346375\n",
      "Accuracy: 0.6487998962402344\n",
      "Epoch 421, CIFAR-10 Batch 5:  Loss: 0.6780106425285339\n",
      "Accuracy: 0.6419999003410339\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss: 0.7202644348144531\n",
      "Accuracy: 0.6409998536109924\n",
      "Epoch 422, CIFAR-10 Batch 2:  Loss: 0.7450428009033203\n",
      "Accuracy: 0.6249998807907104\n",
      "Epoch 422, CIFAR-10 Batch 3:  Loss: 0.645988941192627\n",
      "Accuracy: 0.6485999226570129\n",
      "Epoch 422, CIFAR-10 Batch 4:  Loss: 0.7252860069274902\n",
      "Accuracy: 0.6417999267578125\n",
      "Epoch 422, CIFAR-10 Batch 5:  Loss: 0.6675825119018555\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss: 0.706152081489563\n",
      "Accuracy: 0.6427999138832092\n",
      "Epoch 423, CIFAR-10 Batch 2:  Loss: 0.7461904287338257\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 423, CIFAR-10 Batch 3:  Loss: 0.7069704532623291\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 423, CIFAR-10 Batch 4:  Loss: 0.7182927131652832\n",
      "Accuracy: 0.6441999673843384\n",
      "Epoch 423, CIFAR-10 Batch 5:  Loss: 0.6526671648025513\n",
      "Accuracy: 0.6349998712539673\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss: 0.7097253203392029\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 424, CIFAR-10 Batch 2:  Loss: 0.756639301776886\n",
      "Accuracy: 0.6357998847961426\n",
      "Epoch 424, CIFAR-10 Batch 3:  Loss: 0.6578842997550964\n",
      "Accuracy: 0.6471998691558838\n",
      "Epoch 424, CIFAR-10 Batch 4:  Loss: 0.7188773155212402\n",
      "Accuracy: 0.6459999084472656\n",
      "Epoch 424, CIFAR-10 Batch 5:  Loss: 0.6598770618438721\n",
      "Accuracy: 0.6391998529434204\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss: 0.695800244808197\n",
      "Accuracy: 0.6355999112129211\n",
      "Epoch 425, CIFAR-10 Batch 2:  Loss: 0.7549161911010742\n",
      "Accuracy: 0.648399829864502\n",
      "Epoch 425, CIFAR-10 Batch 3:  Loss: 0.6674414873123169\n",
      "Accuracy: 0.6397998929023743\n",
      "Epoch 425, CIFAR-10 Batch 4:  Loss: 0.7455830574035645\n",
      "Accuracy: 0.6369999051094055\n",
      "Epoch 425, CIFAR-10 Batch 5:  Loss: 0.6586173176765442\n",
      "Accuracy: 0.6303998827934265\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss: 0.7065120935440063\n",
      "Accuracy: 0.6383998394012451\n",
      "Epoch 426, CIFAR-10 Batch 2:  Loss: 0.7768512964248657\n",
      "Accuracy: 0.6395999193191528\n",
      "Epoch 426, CIFAR-10 Batch 3:  Loss: 0.6923643946647644\n",
      "Accuracy: 0.6447999477386475\n",
      "Epoch 426, CIFAR-10 Batch 4:  Loss: 0.7006602883338928\n",
      "Accuracy: 0.6409999132156372\n",
      "Epoch 426, CIFAR-10 Batch 5:  Loss: 0.6507395505905151\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss: 0.7300055027008057\n",
      "Accuracy: 0.6345999240875244\n",
      "Epoch 427, CIFAR-10 Batch 2:  Loss: 0.7208998799324036\n",
      "Accuracy: 0.6347998976707458\n",
      "Epoch 427, CIFAR-10 Batch 3:  Loss: 0.6767144203186035\n",
      "Accuracy: 0.6463999152183533\n",
      "Epoch 427, CIFAR-10 Batch 4:  Loss: 0.6883190870285034\n",
      "Accuracy: 0.6391999125480652\n",
      "Epoch 427, CIFAR-10 Batch 5:  Loss: 0.6333155632019043\n",
      "Accuracy: 0.6483998894691467\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss: 0.747761607170105\n",
      "Accuracy: 0.6387998461723328\n",
      "Epoch 428, CIFAR-10 Batch 2:  Loss: 0.7331764698028564\n",
      "Accuracy: 0.6323999166488647\n",
      "Epoch 428, CIFAR-10 Batch 3:  Loss: 0.6769764423370361\n",
      "Accuracy: 0.6415999531745911\n",
      "Epoch 428, CIFAR-10 Batch 4:  Loss: 0.6978714466094971\n",
      "Accuracy: 0.6443999409675598\n",
      "Epoch 428, CIFAR-10 Batch 5:  Loss: 0.6224861741065979\n",
      "Accuracy: 0.6421998739242554\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss: 0.7379636764526367\n",
      "Accuracy: 0.640799880027771\n",
      "Epoch 429, CIFAR-10 Batch 2:  Loss: 0.7123377919197083\n",
      "Accuracy: 0.6375998854637146\n",
      "Epoch 429, CIFAR-10 Batch 3:  Loss: 0.7086535692214966\n",
      "Accuracy: 0.6499999165534973\n",
      "Epoch 429, CIFAR-10 Batch 4:  Loss: 0.673812747001648\n",
      "Accuracy: 0.6453999280929565\n",
      "Epoch 429, CIFAR-10 Batch 5:  Loss: 0.6464204788208008\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss: 0.7538809776306152\n",
      "Accuracy: 0.6411998867988586\n",
      "Epoch 430, CIFAR-10 Batch 2:  Loss: 0.7020309567451477\n",
      "Accuracy: 0.6315998435020447\n",
      "Epoch 430, CIFAR-10 Batch 3:  Loss: 0.6718831062316895\n",
      "Accuracy: 0.6493998765945435\n",
      "Epoch 430, CIFAR-10 Batch 4:  Loss: 0.6932915449142456\n",
      "Accuracy: 0.6469998955726624\n",
      "Epoch 430, CIFAR-10 Batch 5:  Loss: 0.6560267806053162\n",
      "Accuracy: 0.6441999077796936\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss: 0.7849317193031311\n",
      "Accuracy: 0.6269999146461487\n",
      "Epoch 431, CIFAR-10 Batch 2:  Loss: 0.7366756200790405\n",
      "Accuracy: 0.6367999315261841\n",
      "Epoch 431, CIFAR-10 Batch 3:  Loss: 0.6819781064987183\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 431, CIFAR-10 Batch 4:  Loss: 0.709351122379303\n",
      "Accuracy: 0.637999951839447\n",
      "Epoch 431, CIFAR-10 Batch 5:  Loss: 0.6308647394180298\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss: 0.7458809614181519\n",
      "Accuracy: 0.6449999213218689\n",
      "Epoch 432, CIFAR-10 Batch 2:  Loss: 0.7498307228088379\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 432, CIFAR-10 Batch 3:  Loss: 0.6517018675804138\n",
      "Accuracy: 0.6431999206542969\n",
      "Epoch 432, CIFAR-10 Batch 4:  Loss: 0.7012618184089661\n",
      "Accuracy: 0.6483998894691467\n",
      "Epoch 432, CIFAR-10 Batch 5:  Loss: 0.658018946647644\n",
      "Accuracy: 0.6435998678207397\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss: 0.7215484380722046\n",
      "Accuracy: 0.639799952507019\n",
      "Epoch 433, CIFAR-10 Batch 2:  Loss: 0.7603961229324341\n",
      "Accuracy: 0.6381998658180237\n",
      "Epoch 433, CIFAR-10 Batch 3:  Loss: 0.6718484163284302\n",
      "Accuracy: 0.6457998752593994\n",
      "Epoch 433, CIFAR-10 Batch 4:  Loss: 0.7136970162391663\n",
      "Accuracy: 0.6447998881340027\n",
      "Epoch 433, CIFAR-10 Batch 5:  Loss: 0.6359463930130005\n",
      "Accuracy: 0.6449999213218689\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss: 0.7607245445251465\n",
      "Accuracy: 0.6377999186515808\n",
      "Epoch 434, CIFAR-10 Batch 2:  Loss: 0.7039880752563477\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 434, CIFAR-10 Batch 3:  Loss: 0.6454744338989258\n",
      "Accuracy: 0.644399881362915\n",
      "Epoch 434, CIFAR-10 Batch 4:  Loss: 0.6955728530883789\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 434, CIFAR-10 Batch 5:  Loss: 0.6390220522880554\n",
      "Accuracy: 0.6439998745918274\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss: 0.7311546802520752\n",
      "Accuracy: 0.6413999199867249\n",
      "Epoch 435, CIFAR-10 Batch 2:  Loss: 0.718153178691864\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 435, CIFAR-10 Batch 3:  Loss: 0.6746222376823425\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 435, CIFAR-10 Batch 4:  Loss: 0.6935948729515076\n",
      "Accuracy: 0.649199903011322\n",
      "Epoch 435, CIFAR-10 Batch 5:  Loss: 0.7059667110443115\n",
      "Accuracy: 0.6419999003410339\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss: 0.7211337685585022\n",
      "Accuracy: 0.6423999071121216\n",
      "Epoch 436, CIFAR-10 Batch 2:  Loss: 0.6875644326210022\n",
      "Accuracy: 0.6395998597145081\n",
      "Epoch 436, CIFAR-10 Batch 3:  Loss: 0.6851918697357178\n",
      "Accuracy: 0.6493998765945435\n",
      "Epoch 436, CIFAR-10 Batch 4:  Loss: 0.7222968935966492\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 436, CIFAR-10 Batch 5:  Loss: 0.6450944542884827\n",
      "Accuracy: 0.625999927520752\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss: 0.7975210547447205\n",
      "Accuracy: 0.6445999145507812\n",
      "Epoch 437, CIFAR-10 Batch 2:  Loss: 0.7024975419044495\n",
      "Accuracy: 0.6327998638153076\n",
      "Epoch 437, CIFAR-10 Batch 3:  Loss: 0.6447221040725708\n",
      "Accuracy: 0.64739990234375\n",
      "Epoch 437, CIFAR-10 Batch 4:  Loss: 0.6642059087753296\n",
      "Accuracy: 0.6461998820304871\n",
      "Epoch 437, CIFAR-10 Batch 5:  Loss: 0.6393296122550964\n",
      "Accuracy: 0.6407999396324158\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss: 0.7462644577026367\n",
      "Accuracy: 0.6411998867988586\n",
      "Epoch 438, CIFAR-10 Batch 2:  Loss: 0.7168688774108887\n",
      "Accuracy: 0.6447999477386475\n",
      "Epoch 438, CIFAR-10 Batch 3:  Loss: 0.6735411286354065\n",
      "Accuracy: 0.6467999219894409\n",
      "Epoch 438, CIFAR-10 Batch 4:  Loss: 0.6652767658233643\n",
      "Accuracy: 0.6435998678207397\n",
      "Epoch 438, CIFAR-10 Batch 5:  Loss: 0.6333447694778442\n",
      "Accuracy: 0.6415998935699463\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss: 0.7099565267562866\n",
      "Accuracy: 0.6435998678207397\n",
      "Epoch 439, CIFAR-10 Batch 2:  Loss: 0.7180067300796509\n",
      "Accuracy: 0.6437997817993164\n",
      "Epoch 439, CIFAR-10 Batch 3:  Loss: 0.6600321531295776\n",
      "Accuracy: 0.6449999213218689\n",
      "Epoch 439, CIFAR-10 Batch 4:  Loss: 0.67823326587677\n",
      "Accuracy: 0.6465999484062195\n",
      "Epoch 439, CIFAR-10 Batch 5:  Loss: 0.6693463325500488\n",
      "Accuracy: 0.6329998970031738\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss: 0.738816499710083\n",
      "Accuracy: 0.6415998935699463\n",
      "Epoch 440, CIFAR-10 Batch 2:  Loss: 0.7187307476997375\n",
      "Accuracy: 0.6391998529434204\n",
      "Epoch 440, CIFAR-10 Batch 3:  Loss: 0.66157466173172\n",
      "Accuracy: 0.6501998901367188\n",
      "Epoch 440, CIFAR-10 Batch 4:  Loss: 0.6876701712608337\n",
      "Accuracy: 0.6475998759269714\n",
      "Epoch 440, CIFAR-10 Batch 5:  Loss: 0.6730273962020874\n",
      "Accuracy: 0.6357998847961426\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss: 0.7493926286697388\n",
      "Accuracy: 0.6433998942375183\n",
      "Epoch 441, CIFAR-10 Batch 2:  Loss: 0.713202178478241\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 441, CIFAR-10 Batch 3:  Loss: 0.6533788442611694\n",
      "Accuracy: 0.650999903678894\n",
      "Epoch 441, CIFAR-10 Batch 4:  Loss: 0.732309103012085\n",
      "Accuracy: 0.6439998745918274\n",
      "Epoch 441, CIFAR-10 Batch 5:  Loss: 0.6702464818954468\n",
      "Accuracy: 0.6425998210906982\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss: 0.7350603342056274\n",
      "Accuracy: 0.6467999219894409\n",
      "Epoch 442, CIFAR-10 Batch 2:  Loss: 0.6953403949737549\n",
      "Accuracy: 0.6391999125480652\n",
      "Epoch 442, CIFAR-10 Batch 3:  Loss: 0.652865469455719\n",
      "Accuracy: 0.6457999348640442\n",
      "Epoch 442, CIFAR-10 Batch 4:  Loss: 0.6803251504898071\n",
      "Accuracy: 0.6437999606132507\n",
      "Epoch 442, CIFAR-10 Batch 5:  Loss: 0.6758623719215393\n",
      "Accuracy: 0.6405998468399048\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss: 0.7011498808860779\n",
      "Accuracy: 0.6417998671531677\n",
      "Epoch 443, CIFAR-10 Batch 2:  Loss: 0.7172753214836121\n",
      "Accuracy: 0.6449998617172241\n",
      "Epoch 443, CIFAR-10 Batch 3:  Loss: 0.6389855146408081\n",
      "Accuracy: 0.6481999158859253\n",
      "Epoch 443, CIFAR-10 Batch 4:  Loss: 0.6887896060943604\n",
      "Accuracy: 0.6453998684883118\n",
      "Epoch 443, CIFAR-10 Batch 5:  Loss: 0.6660091876983643\n",
      "Accuracy: 0.6429998874664307\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss: 0.7487926483154297\n",
      "Accuracy: 0.6369999647140503\n",
      "Epoch 444, CIFAR-10 Batch 2:  Loss: 0.7057875990867615\n",
      "Accuracy: 0.6433998942375183\n",
      "Epoch 444, CIFAR-10 Batch 3:  Loss: 0.6663739681243896\n",
      "Accuracy: 0.6513999104499817\n",
      "Epoch 444, CIFAR-10 Batch 4:  Loss: 0.7257764339447021\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 444, CIFAR-10 Batch 5:  Loss: 0.6416856050491333\n",
      "Accuracy: 0.6395998597145081\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss: 0.72598797082901\n",
      "Accuracy: 0.6381999850273132\n",
      "Epoch 445, CIFAR-10 Batch 2:  Loss: 0.7256631255149841\n",
      "Accuracy: 0.6425999402999878\n",
      "Epoch 445, CIFAR-10 Batch 3:  Loss: 0.694694995880127\n",
      "Accuracy: 0.6487998962402344\n",
      "Epoch 445, CIFAR-10 Batch 4:  Loss: 0.6931369304656982\n",
      "Accuracy: 0.6429998874664307\n",
      "Epoch 445, CIFAR-10 Batch 5:  Loss: 0.6204454302787781\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss: 0.8111530542373657\n",
      "Accuracy: 0.6347999572753906\n",
      "Epoch 446, CIFAR-10 Batch 2:  Loss: 0.7186723351478577\n",
      "Accuracy: 0.6399998664855957\n",
      "Epoch 446, CIFAR-10 Batch 3:  Loss: 0.6970848441123962\n",
      "Accuracy: 0.6463998556137085\n",
      "Epoch 446, CIFAR-10 Batch 4:  Loss: 0.6877938508987427\n",
      "Accuracy: 0.6447998881340027\n",
      "Epoch 446, CIFAR-10 Batch 5:  Loss: 0.6559407711029053\n",
      "Accuracy: 0.6429998874664307\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss: 0.7150005102157593\n",
      "Accuracy: 0.6363999247550964\n",
      "Epoch 447, CIFAR-10 Batch 2:  Loss: 0.7061835527420044\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 447, CIFAR-10 Batch 3:  Loss: 0.6785199642181396\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 447, CIFAR-10 Batch 4:  Loss: 0.6952899098396301\n",
      "Accuracy: 0.6481999158859253\n",
      "Epoch 447, CIFAR-10 Batch 5:  Loss: 0.6492933034896851\n",
      "Accuracy: 0.6435998678207397\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss: 0.7246571779251099\n",
      "Accuracy: 0.6361998319625854\n",
      "Epoch 448, CIFAR-10 Batch 2:  Loss: 0.696372389793396\n",
      "Accuracy: 0.6419998407363892\n",
      "Epoch 448, CIFAR-10 Batch 3:  Loss: 0.681247353553772\n",
      "Accuracy: 0.6437998414039612\n",
      "Epoch 448, CIFAR-10 Batch 4:  Loss: 0.6528337001800537\n",
      "Accuracy: 0.6397998929023743\n",
      "Epoch 448, CIFAR-10 Batch 5:  Loss: 0.6238049268722534\n",
      "Accuracy: 0.6441999077796936\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss: 0.7226154208183289\n",
      "Accuracy: 0.6481998562812805\n",
      "Epoch 449, CIFAR-10 Batch 2:  Loss: 0.7239564061164856\n",
      "Accuracy: 0.6433998942375183\n",
      "Epoch 449, CIFAR-10 Batch 3:  Loss: 0.7150144577026367\n",
      "Accuracy: 0.6415998935699463\n",
      "Epoch 449, CIFAR-10 Batch 4:  Loss: 0.6757786273956299\n",
      "Accuracy: 0.6497998833656311\n",
      "Epoch 449, CIFAR-10 Batch 5:  Loss: 0.6375446319580078\n",
      "Accuracy: 0.6427998542785645\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss: 0.7610069513320923\n",
      "Accuracy: 0.6445999145507812\n",
      "Epoch 450, CIFAR-10 Batch 2:  Loss: 0.7263532280921936\n",
      "Accuracy: 0.6459999084472656\n",
      "Epoch 450, CIFAR-10 Batch 3:  Loss: 0.7075570821762085\n",
      "Accuracy: 0.6465998888015747\n",
      "Epoch 450, CIFAR-10 Batch 4:  Loss: 0.7317503690719604\n",
      "Accuracy: 0.6357998847961426\n",
      "Epoch 450, CIFAR-10 Batch 5:  Loss: 0.6627744436264038\n",
      "Accuracy: 0.6479998826980591\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss: 0.7184854745864868\n",
      "Accuracy: 0.6433999538421631\n",
      "Epoch 451, CIFAR-10 Batch 2:  Loss: 0.7147692441940308\n",
      "Accuracy: 0.6421999335289001\n",
      "Epoch 451, CIFAR-10 Batch 3:  Loss: 0.7350139021873474\n",
      "Accuracy: 0.6433998942375183\n",
      "Epoch 451, CIFAR-10 Batch 4:  Loss: 0.6948456168174744\n",
      "Accuracy: 0.6465998888015747\n",
      "Epoch 451, CIFAR-10 Batch 5:  Loss: 0.6334903836250305\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss: 0.6935425996780396\n",
      "Accuracy: 0.6435998678207397\n",
      "Epoch 452, CIFAR-10 Batch 2:  Loss: 0.7435193657875061\n",
      "Accuracy: 0.6353998780250549\n",
      "Epoch 452, CIFAR-10 Batch 3:  Loss: 0.681148886680603\n",
      "Accuracy: 0.6475998759269714\n",
      "Epoch 452, CIFAR-10 Batch 4:  Loss: 0.6434371471405029\n",
      "Accuracy: 0.6427999138832092\n",
      "Epoch 452, CIFAR-10 Batch 5:  Loss: 0.6539194583892822\n",
      "Accuracy: 0.6467999219894409\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss: 0.7484413385391235\n",
      "Accuracy: 0.6397998929023743\n",
      "Epoch 453, CIFAR-10 Batch 2:  Loss: 0.7492393255233765\n",
      "Accuracy: 0.6357999444007874\n",
      "Epoch 453, CIFAR-10 Batch 3:  Loss: 0.7276783585548401\n",
      "Accuracy: 0.6479998826980591\n",
      "Epoch 453, CIFAR-10 Batch 4:  Loss: 0.6956696510314941\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 453, CIFAR-10 Batch 5:  Loss: 0.6748635172843933\n",
      "Accuracy: 0.6409999132156372\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss: 0.7509457468986511\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 454, CIFAR-10 Batch 2:  Loss: 0.7262127995491028\n",
      "Accuracy: 0.6413998603820801\n",
      "Epoch 454, CIFAR-10 Batch 3:  Loss: 0.7550798654556274\n",
      "Accuracy: 0.6439998745918274\n",
      "Epoch 454, CIFAR-10 Batch 4:  Loss: 0.6758216619491577\n",
      "Accuracy: 0.6473999619483948\n",
      "Epoch 454, CIFAR-10 Batch 5:  Loss: 0.642768144607544\n",
      "Accuracy: 0.6481998562812805\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss: 0.729779839515686\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 455, CIFAR-10 Batch 2:  Loss: 0.7439295649528503\n",
      "Accuracy: 0.6427998542785645\n",
      "Epoch 455, CIFAR-10 Batch 3:  Loss: 0.687514066696167\n",
      "Accuracy: 0.6501998901367188\n",
      "Epoch 455, CIFAR-10 Batch 4:  Loss: 0.6843054890632629\n",
      "Accuracy: 0.6397998929023743\n",
      "Epoch 455, CIFAR-10 Batch 5:  Loss: 0.689201831817627\n",
      "Accuracy: 0.632599949836731\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss: 0.7446877360343933\n",
      "Accuracy: 0.6431999206542969\n",
      "Epoch 456, CIFAR-10 Batch 2:  Loss: 0.7363764047622681\n",
      "Accuracy: 0.6333999037742615\n",
      "Epoch 456, CIFAR-10 Batch 3:  Loss: 0.6795318722724915\n",
      "Accuracy: 0.649199903011322\n",
      "Epoch 456, CIFAR-10 Batch 4:  Loss: 0.6953338384628296\n",
      "Accuracy: 0.6439998149871826\n",
      "Epoch 456, CIFAR-10 Batch 5:  Loss: 0.6595659852027893\n",
      "Accuracy: 0.6465998888015747\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss: 0.7703813314437866\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 457, CIFAR-10 Batch 2:  Loss: 0.7732880115509033\n",
      "Accuracy: 0.6409999132156372\n",
      "Epoch 457, CIFAR-10 Batch 3:  Loss: 0.6816152334213257\n",
      "Accuracy: 0.6515998840332031\n",
      "Epoch 457, CIFAR-10 Batch 4:  Loss: 0.688694953918457\n",
      "Accuracy: 0.6477999091148376\n",
      "Epoch 457, CIFAR-10 Batch 5:  Loss: 0.658766508102417\n",
      "Accuracy: 0.6425999402999878\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss: 0.7339386940002441\n",
      "Accuracy: 0.6355998516082764\n",
      "Epoch 458, CIFAR-10 Batch 2:  Loss: 0.7444320321083069\n",
      "Accuracy: 0.6419999003410339\n",
      "Epoch 458, CIFAR-10 Batch 3:  Loss: 0.7069365978240967\n",
      "Accuracy: 0.6409998536109924\n",
      "Epoch 458, CIFAR-10 Batch 4:  Loss: 0.718643307685852\n",
      "Accuracy: 0.6467999219894409\n",
      "Epoch 458, CIFAR-10 Batch 5:  Loss: 0.6338098645210266\n",
      "Accuracy: 0.6449998617172241\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss: 0.7161273956298828\n",
      "Accuracy: 0.6409999132156372\n",
      "Epoch 459, CIFAR-10 Batch 2:  Loss: 0.7196522355079651\n",
      "Accuracy: 0.6417998671531677\n",
      "Epoch 459, CIFAR-10 Batch 3:  Loss: 0.7045639753341675\n",
      "Accuracy: 0.6511999368667603\n",
      "Epoch 459, CIFAR-10 Batch 4:  Loss: 0.7082045078277588\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 459, CIFAR-10 Batch 5:  Loss: 0.66066575050354\n",
      "Accuracy: 0.642599880695343\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss: 0.7155535221099854\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 460, CIFAR-10 Batch 2:  Loss: 0.7029352784156799\n",
      "Accuracy: 0.6431999206542969\n",
      "Epoch 460, CIFAR-10 Batch 3:  Loss: 0.7113713622093201\n",
      "Accuracy: 0.6405998468399048\n",
      "Epoch 460, CIFAR-10 Batch 4:  Loss: 0.7081745266914368\n",
      "Accuracy: 0.6471999287605286\n",
      "Epoch 460, CIFAR-10 Batch 5:  Loss: 0.6604651808738708\n",
      "Accuracy: 0.631399929523468\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss: 0.7449173927307129\n",
      "Accuracy: 0.6391999125480652\n",
      "Epoch 461, CIFAR-10 Batch 2:  Loss: 0.7248176336288452\n",
      "Accuracy: 0.6383999586105347\n",
      "Epoch 461, CIFAR-10 Batch 3:  Loss: 0.6762071847915649\n",
      "Accuracy: 0.6451998353004456\n",
      "Epoch 461, CIFAR-10 Batch 4:  Loss: 0.690148115158081\n",
      "Accuracy: 0.6439999341964722\n",
      "Epoch 461, CIFAR-10 Batch 5:  Loss: 0.6303489208221436\n",
      "Accuracy: 0.6467999219894409\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss: 0.7512040734291077\n",
      "Accuracy: 0.6441999077796936\n",
      "Epoch 462, CIFAR-10 Batch 2:  Loss: 0.7356290817260742\n",
      "Accuracy: 0.6435998678207397\n",
      "Epoch 462, CIFAR-10 Batch 3:  Loss: 0.6691324710845947\n",
      "Accuracy: 0.6483998894691467\n",
      "Epoch 462, CIFAR-10 Batch 4:  Loss: 0.7062884569168091\n",
      "Accuracy: 0.6429998874664307\n",
      "Epoch 462, CIFAR-10 Batch 5:  Loss: 0.6257487535476685\n",
      "Accuracy: 0.6441999077796936\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss: 0.7489319443702698\n",
      "Accuracy: 0.6429998874664307\n",
      "Epoch 463, CIFAR-10 Batch 2:  Loss: 0.7119190692901611\n",
      "Accuracy: 0.6297999620437622\n",
      "Epoch 463, CIFAR-10 Batch 3:  Loss: 0.6606184840202332\n",
      "Accuracy: 0.6497999429702759\n",
      "Epoch 463, CIFAR-10 Batch 4:  Loss: 0.7182939052581787\n",
      "Accuracy: 0.6397998332977295\n",
      "Epoch 463, CIFAR-10 Batch 5:  Loss: 0.6403732299804688\n",
      "Accuracy: 0.6389999389648438\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss: 0.7226316928863525\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 464, CIFAR-10 Batch 2:  Loss: 0.7222087383270264\n",
      "Accuracy: 0.6453998684883118\n",
      "Epoch 464, CIFAR-10 Batch 3:  Loss: 0.7012001276016235\n",
      "Accuracy: 0.6447999477386475\n",
      "Epoch 464, CIFAR-10 Batch 4:  Loss: 0.7073730230331421\n",
      "Accuracy: 0.6499999165534973\n",
      "Epoch 464, CIFAR-10 Batch 5:  Loss: 0.6573562026023865\n",
      "Accuracy: 0.6339999437332153\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss: 0.7427738308906555\n",
      "Accuracy: 0.6423999071121216\n",
      "Epoch 465, CIFAR-10 Batch 2:  Loss: 0.696933388710022\n",
      "Accuracy: 0.6365998983383179\n",
      "Epoch 465, CIFAR-10 Batch 3:  Loss: 0.6687088012695312\n",
      "Accuracy: 0.6431999206542969\n",
      "Epoch 465, CIFAR-10 Batch 4:  Loss: 0.705157458782196\n",
      "Accuracy: 0.6453998684883118\n",
      "Epoch 465, CIFAR-10 Batch 5:  Loss: 0.63826584815979\n",
      "Accuracy: 0.6383999586105347\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss: 0.7272250652313232\n",
      "Accuracy: 0.6449998617172241\n",
      "Epoch 466, CIFAR-10 Batch 2:  Loss: 0.7221204042434692\n",
      "Accuracy: 0.6401998996734619\n",
      "Epoch 466, CIFAR-10 Batch 3:  Loss: 0.6543939113616943\n",
      "Accuracy: 0.6449999213218689\n",
      "Epoch 466, CIFAR-10 Batch 4:  Loss: 0.715290904045105\n",
      "Accuracy: 0.6499998569488525\n",
      "Epoch 466, CIFAR-10 Batch 5:  Loss: 0.6543334722518921\n",
      "Accuracy: 0.6475998759269714\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss: 0.7092819213867188\n",
      "Accuracy: 0.6481999158859253\n",
      "Epoch 467, CIFAR-10 Batch 2:  Loss: 0.7038452625274658\n",
      "Accuracy: 0.6453999280929565\n",
      "Epoch 467, CIFAR-10 Batch 3:  Loss: 0.6518499851226807\n",
      "Accuracy: 0.6501998901367188\n",
      "Epoch 467, CIFAR-10 Batch 4:  Loss: 0.7251966595649719\n",
      "Accuracy: 0.6461998224258423\n",
      "Epoch 467, CIFAR-10 Batch 5:  Loss: 0.6254792213439941\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss: 0.7386412620544434\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 468, CIFAR-10 Batch 2:  Loss: 0.7017887830734253\n",
      "Accuracy: 0.6387998461723328\n",
      "Epoch 468, CIFAR-10 Batch 3:  Loss: 0.6457231044769287\n",
      "Accuracy: 0.6499999165534973\n",
      "Epoch 468, CIFAR-10 Batch 4:  Loss: 0.7270381450653076\n",
      "Accuracy: 0.6453998684883118\n",
      "Epoch 468, CIFAR-10 Batch 5:  Loss: 0.6544804573059082\n",
      "Accuracy: 0.6441999077796936\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss: 0.7044277191162109\n",
      "Accuracy: 0.6433998346328735\n",
      "Epoch 469, CIFAR-10 Batch 2:  Loss: 0.734647274017334\n",
      "Accuracy: 0.6527999043464661\n",
      "Epoch 469, CIFAR-10 Batch 3:  Loss: 0.6799846291542053\n",
      "Accuracy: 0.6515998840332031\n",
      "Epoch 469, CIFAR-10 Batch 4:  Loss: 0.6946892142295837\n",
      "Accuracy: 0.6507998704910278\n",
      "Epoch 469, CIFAR-10 Batch 5:  Loss: 0.6634583473205566\n",
      "Accuracy: 0.6397998332977295\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss: 0.7328127026557922\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 470, CIFAR-10 Batch 2:  Loss: 0.7681054472923279\n",
      "Accuracy: 0.642599880695343\n",
      "Epoch 470, CIFAR-10 Batch 3:  Loss: 0.7090053558349609\n",
      "Accuracy: 0.6535998582839966\n",
      "Epoch 470, CIFAR-10 Batch 4:  Loss: 0.7284099459648132\n",
      "Accuracy: 0.6401998996734619\n",
      "Epoch 470, CIFAR-10 Batch 5:  Loss: 0.6463175415992737\n",
      "Accuracy: 0.6395999193191528\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss: 0.7301757335662842\n",
      "Accuracy: 0.6393999457359314\n",
      "Epoch 471, CIFAR-10 Batch 2:  Loss: 0.7075139880180359\n",
      "Accuracy: 0.6375998258590698\n",
      "Epoch 471, CIFAR-10 Batch 3:  Loss: 0.659589946269989\n",
      "Accuracy: 0.6471998691558838\n",
      "Epoch 471, CIFAR-10 Batch 4:  Loss: 0.715401828289032\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 471, CIFAR-10 Batch 5:  Loss: 0.6206291913986206\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss: 0.7236901521682739\n",
      "Accuracy: 0.6405998468399048\n",
      "Epoch 472, CIFAR-10 Batch 2:  Loss: 0.728947103023529\n",
      "Accuracy: 0.6423998475074768\n",
      "Epoch 472, CIFAR-10 Batch 3:  Loss: 0.7058408856391907\n",
      "Accuracy: 0.6499998569488525\n",
      "Epoch 472, CIFAR-10 Batch 4:  Loss: 0.6790480017662048\n",
      "Accuracy: 0.6441999077796936\n",
      "Epoch 472, CIFAR-10 Batch 5:  Loss: 0.6392614841461182\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss: 0.7262789011001587\n",
      "Accuracy: 0.6481999158859253\n",
      "Epoch 473, CIFAR-10 Batch 2:  Loss: 0.7134256958961487\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 473, CIFAR-10 Batch 3:  Loss: 0.6733850240707397\n",
      "Accuracy: 0.6483998894691467\n",
      "Epoch 473, CIFAR-10 Batch 4:  Loss: 0.6912347674369812\n",
      "Accuracy: 0.6467998623847961\n",
      "Epoch 473, CIFAR-10 Batch 5:  Loss: 0.6668421030044556\n",
      "Accuracy: 0.6477998495101929\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss: 0.7361254692077637\n",
      "Accuracy: 0.6487998962402344\n",
      "Epoch 474, CIFAR-10 Batch 2:  Loss: 0.7223948240280151\n",
      "Accuracy: 0.6473998427391052\n",
      "Epoch 474, CIFAR-10 Batch 3:  Loss: 0.6461241245269775\n",
      "Accuracy: 0.6537998914718628\n",
      "Epoch 474, CIFAR-10 Batch 4:  Loss: 0.6630927324295044\n",
      "Accuracy: 0.649199903011322\n",
      "Epoch 474, CIFAR-10 Batch 5:  Loss: 0.6412017345428467\n",
      "Accuracy: 0.6439999341964722\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss: 0.7407913208007812\n",
      "Accuracy: 0.6443999409675598\n",
      "Epoch 475, CIFAR-10 Batch 2:  Loss: 0.7132822275161743\n",
      "Accuracy: 0.6333998441696167\n",
      "Epoch 475, CIFAR-10 Batch 3:  Loss: 0.6637119054794312\n",
      "Accuracy: 0.6493999361991882\n",
      "Epoch 475, CIFAR-10 Batch 4:  Loss: 0.6785304546356201\n",
      "Accuracy: 0.6493998765945435\n",
      "Epoch 475, CIFAR-10 Batch 5:  Loss: 0.6334429383277893\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss: 0.7664086818695068\n",
      "Accuracy: 0.6465999484062195\n",
      "Epoch 476, CIFAR-10 Batch 2:  Loss: 0.688034176826477\n",
      "Accuracy: 0.6391999125480652\n",
      "Epoch 476, CIFAR-10 Batch 3:  Loss: 0.651175856590271\n",
      "Accuracy: 0.6511998772621155\n",
      "Epoch 476, CIFAR-10 Batch 4:  Loss: 0.6825827360153198\n",
      "Accuracy: 0.6447998881340027\n",
      "Epoch 476, CIFAR-10 Batch 5:  Loss: 0.6336920857429504\n",
      "Accuracy: 0.6487998962402344\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss: 0.7257866859436035\n",
      "Accuracy: 0.6503998637199402\n",
      "Epoch 477, CIFAR-10 Batch 2:  Loss: 0.6846828460693359\n",
      "Accuracy: 0.6459999084472656\n",
      "Epoch 477, CIFAR-10 Batch 3:  Loss: 0.6635764241218567\n",
      "Accuracy: 0.6497998237609863\n",
      "Epoch 477, CIFAR-10 Batch 4:  Loss: 0.6505675911903381\n",
      "Accuracy: 0.6487998962402344\n",
      "Epoch 477, CIFAR-10 Batch 5:  Loss: 0.6703715324401855\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss: 0.749388575553894\n",
      "Accuracy: 0.6465999484062195\n",
      "Epoch 478, CIFAR-10 Batch 2:  Loss: 0.7067087888717651\n",
      "Accuracy: 0.6335998773574829\n",
      "Epoch 478, CIFAR-10 Batch 3:  Loss: 0.695831835269928\n",
      "Accuracy: 0.6505998373031616\n",
      "Epoch 478, CIFAR-10 Batch 4:  Loss: 0.6703296899795532\n",
      "Accuracy: 0.6527999043464661\n",
      "Epoch 478, CIFAR-10 Batch 5:  Loss: 0.6392290592193604\n",
      "Accuracy: 0.6379998922348022\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss: 0.7511756420135498\n",
      "Accuracy: 0.6411999464035034\n",
      "Epoch 479, CIFAR-10 Batch 2:  Loss: 0.7064281702041626\n",
      "Accuracy: 0.6413999199867249\n",
      "Epoch 479, CIFAR-10 Batch 3:  Loss: 0.705655574798584\n",
      "Accuracy: 0.6481999158859253\n",
      "Epoch 479, CIFAR-10 Batch 4:  Loss: 0.6581957340240479\n",
      "Accuracy: 0.6545999050140381\n",
      "Epoch 479, CIFAR-10 Batch 5:  Loss: 0.632220983505249\n",
      "Accuracy: 0.6421998739242554\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss: 0.7165266871452332\n",
      "Accuracy: 0.6469998359680176\n",
      "Epoch 480, CIFAR-10 Batch 2:  Loss: 0.6982032060623169\n",
      "Accuracy: 0.6447998881340027\n",
      "Epoch 480, CIFAR-10 Batch 3:  Loss: 0.7206432819366455\n",
      "Accuracy: 0.6391998529434204\n",
      "Epoch 480, CIFAR-10 Batch 4:  Loss: 0.6977295279502869\n",
      "Accuracy: 0.6415998935699463\n",
      "Epoch 480, CIFAR-10 Batch 5:  Loss: 0.651425302028656\n",
      "Accuracy: 0.6379998922348022\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss: 0.7052655220031738\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 481, CIFAR-10 Batch 2:  Loss: 0.7133984565734863\n",
      "Accuracy: 0.6445999145507812\n",
      "Epoch 481, CIFAR-10 Batch 3:  Loss: 0.677681565284729\n",
      "Accuracy: 0.6475998759269714\n",
      "Epoch 481, CIFAR-10 Batch 4:  Loss: 0.6959474086761475\n",
      "Accuracy: 0.645599901676178\n",
      "Epoch 481, CIFAR-10 Batch 5:  Loss: 0.6226673126220703\n",
      "Accuracy: 0.644399881362915\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss: 0.7211843132972717\n",
      "Accuracy: 0.6395999193191528\n",
      "Epoch 482, CIFAR-10 Batch 2:  Loss: 0.6973101496696472\n",
      "Accuracy: 0.6361998915672302\n",
      "Epoch 482, CIFAR-10 Batch 3:  Loss: 0.6526381969451904\n",
      "Accuracy: 0.6489998698234558\n",
      "Epoch 482, CIFAR-10 Batch 4:  Loss: 0.67902010679245\n",
      "Accuracy: 0.6511999368667603\n",
      "Epoch 482, CIFAR-10 Batch 5:  Loss: 0.6691325902938843\n",
      "Accuracy: 0.6461999416351318\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss: 0.7161857485771179\n",
      "Accuracy: 0.6405998468399048\n",
      "Epoch 483, CIFAR-10 Batch 2:  Loss: 0.7306655645370483\n",
      "Accuracy: 0.6409999132156372\n",
      "Epoch 483, CIFAR-10 Batch 3:  Loss: 0.6578365564346313\n",
      "Accuracy: 0.651999831199646\n",
      "Epoch 483, CIFAR-10 Batch 4:  Loss: 0.6770533323287964\n",
      "Accuracy: 0.6485998630523682\n",
      "Epoch 483, CIFAR-10 Batch 5:  Loss: 0.6582784652709961\n",
      "Accuracy: 0.6439999341964722\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss: 0.7117507457733154\n",
      "Accuracy: 0.6449999213218689\n",
      "Epoch 484, CIFAR-10 Batch 2:  Loss: 0.7105757594108582\n",
      "Accuracy: 0.6397998929023743\n",
      "Epoch 484, CIFAR-10 Batch 3:  Loss: 0.6846339702606201\n",
      "Accuracy: 0.6471998691558838\n",
      "Epoch 484, CIFAR-10 Batch 4:  Loss: 0.6999842524528503\n",
      "Accuracy: 0.6467998623847961\n",
      "Epoch 484, CIFAR-10 Batch 5:  Loss: 0.6613446474075317\n",
      "Accuracy: 0.6415998935699463\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss: 0.724368691444397\n",
      "Accuracy: 0.6535999178886414\n",
      "Epoch 485, CIFAR-10 Batch 2:  Loss: 0.7335195541381836\n",
      "Accuracy: 0.6389999389648438\n",
      "Epoch 485, CIFAR-10 Batch 3:  Loss: 0.650151789188385\n",
      "Accuracy: 0.64739990234375\n",
      "Epoch 485, CIFAR-10 Batch 4:  Loss: 0.6926008462905884\n",
      "Accuracy: 0.6425999402999878\n",
      "Epoch 485, CIFAR-10 Batch 5:  Loss: 0.6448010206222534\n",
      "Accuracy: 0.6447998881340027\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss: 0.7756394147872925\n",
      "Accuracy: 0.6423999071121216\n",
      "Epoch 486, CIFAR-10 Batch 2:  Loss: 0.7236505150794983\n",
      "Accuracy: 0.650999903678894\n",
      "Epoch 486, CIFAR-10 Batch 3:  Loss: 0.6551117897033691\n",
      "Accuracy: 0.6511998772621155\n",
      "Epoch 486, CIFAR-10 Batch 4:  Loss: 0.6813618540763855\n",
      "Accuracy: 0.6457998752593994\n",
      "Epoch 486, CIFAR-10 Batch 5:  Loss: 0.6442598700523376\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss: 0.7323569655418396\n",
      "Accuracy: 0.637199878692627\n",
      "Epoch 487, CIFAR-10 Batch 2:  Loss: 0.7037266492843628\n",
      "Accuracy: 0.6451998949050903\n",
      "Epoch 487, CIFAR-10 Batch 3:  Loss: 0.6962388157844543\n",
      "Accuracy: 0.6477998495101929\n",
      "Epoch 487, CIFAR-10 Batch 4:  Loss: 0.6885939836502075\n",
      "Accuracy: 0.6489998698234558\n",
      "Epoch 487, CIFAR-10 Batch 5:  Loss: 0.6545791625976562\n",
      "Accuracy: 0.6367998719215393\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss: 0.7692192792892456\n",
      "Accuracy: 0.6425999402999878\n",
      "Epoch 488, CIFAR-10 Batch 2:  Loss: 0.6976677179336548\n",
      "Accuracy: 0.644399881362915\n",
      "Epoch 488, CIFAR-10 Batch 3:  Loss: 0.6866065263748169\n",
      "Accuracy: 0.6483998894691467\n",
      "Epoch 488, CIFAR-10 Batch 4:  Loss: 0.6953239440917969\n",
      "Accuracy: 0.6517998576164246\n",
      "Epoch 488, CIFAR-10 Batch 5:  Loss: 0.6504613161087036\n",
      "Accuracy: 0.6467999815940857\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss: 0.7263906598091125\n",
      "Accuracy: 0.6439998745918274\n",
      "Epoch 489, CIFAR-10 Batch 2:  Loss: 0.7186065912246704\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 489, CIFAR-10 Batch 3:  Loss: 0.7220305800437927\n",
      "Accuracy: 0.6467999219894409\n",
      "Epoch 489, CIFAR-10 Batch 4:  Loss: 0.6688657999038696\n",
      "Accuracy: 0.6459998488426208\n",
      "Epoch 489, CIFAR-10 Batch 5:  Loss: 0.6497476100921631\n",
      "Accuracy: 0.6367998719215393\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss: 0.7624512910842896\n",
      "Accuracy: 0.6421999335289001\n",
      "Epoch 490, CIFAR-10 Batch 2:  Loss: 0.7251625061035156\n",
      "Accuracy: 0.6413998603820801\n",
      "Epoch 490, CIFAR-10 Batch 3:  Loss: 0.7072287201881409\n",
      "Accuracy: 0.6497999429702759\n",
      "Epoch 490, CIFAR-10 Batch 4:  Loss: 0.6659677624702454\n",
      "Accuracy: 0.6493998765945435\n",
      "Epoch 490, CIFAR-10 Batch 5:  Loss: 0.6564555168151855\n",
      "Accuracy: 0.6325998902320862\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss: 0.7561283707618713\n",
      "Accuracy: 0.6389999389648438\n",
      "Epoch 491, CIFAR-10 Batch 2:  Loss: 0.7035836577415466\n",
      "Accuracy: 0.6387999057769775\n",
      "Epoch 491, CIFAR-10 Batch 3:  Loss: 0.6729605793952942\n",
      "Accuracy: 0.6401998996734619\n",
      "Epoch 491, CIFAR-10 Batch 4:  Loss: 0.6822678446769714\n",
      "Accuracy: 0.6437998414039612\n",
      "Epoch 491, CIFAR-10 Batch 5:  Loss: 0.6343852281570435\n",
      "Accuracy: 0.6403998732566833\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss: 0.7328904867172241\n",
      "Accuracy: 0.6433999538421631\n",
      "Epoch 492, CIFAR-10 Batch 2:  Loss: 0.6970251202583313\n",
      "Accuracy: 0.638999879360199\n",
      "Epoch 492, CIFAR-10 Batch 3:  Loss: 0.6535462141036987\n",
      "Accuracy: 0.6441999077796936\n",
      "Epoch 492, CIFAR-10 Batch 4:  Loss: 0.6728736162185669\n",
      "Accuracy: 0.6445999145507812\n",
      "Epoch 492, CIFAR-10 Batch 5:  Loss: 0.6526495218276978\n",
      "Accuracy: 0.6465998888015747\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss: 0.7288837432861328\n",
      "Accuracy: 0.6415998935699463\n",
      "Epoch 493, CIFAR-10 Batch 2:  Loss: 0.7361957430839539\n",
      "Accuracy: 0.6419999003410339\n",
      "Epoch 493, CIFAR-10 Batch 3:  Loss: 0.6609337329864502\n",
      "Accuracy: 0.6495999097824097\n",
      "Epoch 493, CIFAR-10 Batch 4:  Loss: 0.6802693605422974\n",
      "Accuracy: 0.6503998637199402\n",
      "Epoch 493, CIFAR-10 Batch 5:  Loss: 0.6529166102409363\n",
      "Accuracy: 0.6381999254226685\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss: 0.7399863004684448\n",
      "Accuracy: 0.6533999443054199\n",
      "Epoch 494, CIFAR-10 Batch 2:  Loss: 0.7222719788551331\n",
      "Accuracy: 0.6393998861312866\n",
      "Epoch 494, CIFAR-10 Batch 3:  Loss: 0.7135263681411743\n",
      "Accuracy: 0.6481999158859253\n",
      "Epoch 494, CIFAR-10 Batch 4:  Loss: 0.6673179864883423\n",
      "Accuracy: 0.6463999152183533\n",
      "Epoch 494, CIFAR-10 Batch 5:  Loss: 0.660016655921936\n",
      "Accuracy: 0.6449999213218689\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss: 0.7432134747505188\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 495, CIFAR-10 Batch 2:  Loss: 0.7079145312309265\n",
      "Accuracy: 0.6411998867988586\n",
      "Epoch 495, CIFAR-10 Batch 3:  Loss: 0.6703284382820129\n",
      "Accuracy: 0.6489999294281006\n",
      "Epoch 495, CIFAR-10 Batch 4:  Loss: 0.6739731431007385\n",
      "Accuracy: 0.6481998562812805\n",
      "Epoch 495, CIFAR-10 Batch 5:  Loss: 0.6578773856163025\n",
      "Accuracy: 0.6363999247550964\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss: 0.7465478777885437\n",
      "Accuracy: 0.6475998759269714\n",
      "Epoch 496, CIFAR-10 Batch 2:  Loss: 0.7117854356765747\n",
      "Accuracy: 0.6453999280929565\n",
      "Epoch 496, CIFAR-10 Batch 3:  Loss: 0.6643059253692627\n",
      "Accuracy: 0.6497999429702759\n",
      "Epoch 496, CIFAR-10 Batch 4:  Loss: 0.6663154363632202\n",
      "Accuracy: 0.6459999084472656\n",
      "Epoch 496, CIFAR-10 Batch 5:  Loss: 0.6411150693893433\n",
      "Accuracy: 0.6405999660491943\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss: 0.706516683101654\n",
      "Accuracy: 0.643799901008606\n",
      "Epoch 497, CIFAR-10 Batch 2:  Loss: 0.7291120290756226\n",
      "Accuracy: 0.6385998725891113\n",
      "Epoch 497, CIFAR-10 Batch 3:  Loss: 0.7061475515365601\n",
      "Accuracy: 0.6477998495101929\n",
      "Epoch 497, CIFAR-10 Batch 4:  Loss: 0.6396181583404541\n",
      "Accuracy: 0.6483998894691467\n",
      "Epoch 497, CIFAR-10 Batch 5:  Loss: 0.6589006185531616\n",
      "Accuracy: 0.6337999105453491\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss: 0.758299708366394\n",
      "Accuracy: 0.6373999118804932\n",
      "Epoch 498, CIFAR-10 Batch 2:  Loss: 0.7123306393623352\n",
      "Accuracy: 0.6425999402999878\n",
      "Epoch 498, CIFAR-10 Batch 3:  Loss: 0.6687366962432861\n",
      "Accuracy: 0.6471999287605286\n",
      "Epoch 498, CIFAR-10 Batch 4:  Loss: 0.6702829599380493\n",
      "Accuracy: 0.649199903011322\n",
      "Epoch 498, CIFAR-10 Batch 5:  Loss: 0.6783987283706665\n",
      "Accuracy: 0.645599901676178\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss: 0.7434476613998413\n",
      "Accuracy: 0.6419999599456787\n",
      "Epoch 499, CIFAR-10 Batch 2:  Loss: 0.6919686198234558\n",
      "Accuracy: 0.6399998664855957\n",
      "Epoch 499, CIFAR-10 Batch 3:  Loss: 0.6741176843643188\n",
      "Accuracy: 0.6469999551773071\n",
      "Epoch 499, CIFAR-10 Batch 4:  Loss: 0.6734442114830017\n",
      "Accuracy: 0.6479998826980591\n",
      "Epoch 499, CIFAR-10 Batch 5:  Loss: 0.6373318433761597\n",
      "Accuracy: 0.6363999247550964\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss: 0.7569066286087036\n",
      "Accuracy: 0.6465998888015747\n",
      "Epoch 500, CIFAR-10 Batch 2:  Loss: 0.7282881736755371\n",
      "Accuracy: 0.6399999260902405\n",
      "Epoch 500, CIFAR-10 Batch 3:  Loss: 0.6947410702705383\n",
      "Accuracy: 0.6387999653816223\n",
      "Epoch 500, CIFAR-10 Batch 4:  Loss: 0.6766071319580078\n",
      "Accuracy: 0.6487998366355896\n",
      "Epoch 500, CIFAR-10 Batch 5:  Loss: 0.6169500350952148\n",
      "Accuracy: 0.6347998976707458\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6271484375\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU130VQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1411bf6ec50>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
